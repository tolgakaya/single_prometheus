{
  "name": "Single Prometheus New Cluster",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// Prometheus Query Builder - D√úZELTME\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// T√úM Gƒ∞REN VERƒ∞Yƒ∞ KORU\nlet output = { ...inputData };\n\n// Alert bilgilerini DOƒûRU yerden al\nconst alertName = inputData.context?.alertName || \n                  inputData.alertContext?.alertName || \n                  'unknown';\n\nconst namespace = inputData.namespaces?.[0] || \n                 inputData.kubernetesFilters?.namespace || \n                 'etiyamobile-production';\n\n// Kubernetes filters'ƒ± DOƒûRU yerden al\nconst filters = inputData.kubernetesFilters || {};\n\n// Query'leri DOƒûRU bilgilerle olu≈ütur\nconst queries = [\n  {\n    type: \"container_cpu\",\n    query: 'rate(container_cpu_usage_seconds_total{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\", container=\"' + filters.container + '\"}[5m]) * 100',\n    description: 'CPU usage for ' + filters.container\n  },\n  {\n    type: \"container_memory\",\n    query: 'container_memory_working_set_bytes{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\", container=\"' + filters.container + '\"}',\n    description: 'Memory usage for ' + filters.container\n  },\n  {\n    type: \"container_memory_limit\",\n    query: 'container_spec_memory_limit_bytes{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\", container=\"' + filters.container + '\"}',\n    description: 'Memory limit for ' + filters.container\n  },\n  {\n    type: \"container_restarts\",\n    query: 'kube_pod_container_status_restarts_total{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\", container=\"' + filters.container + '\"}',\n    description: 'Restart count for ' + filters.container\n  },\n  {\n    type: \"pod_status\",\n    query: 'kube_pod_status_phase{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\"}',\n    description: 'Pod phase for ' + filters.pod\n  },\n  {\n    type: \"pod_ready\",\n    query: 'kube_pod_status_ready{namespace=\"' + namespace + '\", pod=\"' + filters.pod + '\"}',\n    description: 'Pod ready status for ' + filters.pod\n  },\n  {\n    type: \"service_cpu\",\n    query: 'sum(rate(container_cpu_usage_seconds_total{namespace=\"' + namespace + '\", pod=~\"' + (filters.service || 'unknown') + '.*\"}[5m])) by (pod) * 100',\n    description: 'CPU usage for service ' + filters.service\n  },\n  {\n    type: \"service_memory\",\n    query: 'sum(container_memory_working_set_bytes{namespace=\"' + namespace + '\", pod=~\"' + (filters.service || 'unknown') + '.*\"}) by (pod)',\n    description: 'Memory usage for service ' + filters.service\n  },\n  {\n    type: \"service_replicas\",\n    query: 'kube_deployment_status_replicas{namespace=\"' + namespace + '\", deployment=\"' + (filters.deployment || filters.service || 'unknown') + '\"}',\n    description: 'Replica count for ' + (filters.deployment || filters.service)\n  },\n  {\n    type: \"crashloop_restarts\",\n    query: 'rate(kube_pod_container_status_restarts_total{namespace=\"' + namespace + '\"}[15m]) > 0',\n    description: 'Pods with recent restarts in namespace'\n  }\n];\n\n// Output'a DOƒûRU bilgileri ekle\noutput.namespace = namespace;\noutput.alertName = alertName;\noutput.useSpecificFilters = true;\noutput.filters = filters;\noutput.queries = queries;\noutput.queryCount = queries.length;\noutput.mode = 'TARGETED';\noutput.timestamp = new Date().toISOString();\n\n// Debug log\nconsole.log('Prometheus Query Builder:', {\n  alertName: alertName,\n  namespace: namespace,\n  pod: filters.pod,\n  container: filters.container,\n  queryCount: queries.length\n});\n\nreturn [output];"
      },
      "id": "583a30ea-59ed-4f6b-8edf-c03e13e323c1",
      "name": "Prometheus Query Builder",
      "type": "n8n-nodes-base.code",
      "position": [
        -4272,
        288
      ],
      "typeVersion": 2
    },
    {
      "parameters": {},
      "id": "6aea3d68-2d7e-4ffc-8131-b17cd38d4404",
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualTrigger",
      "position": [
        -4592,
        80
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "rule": {
          "interval": [
            {
              "field": "minutes"
            }
          ]
        }
      },
      "id": "9736ea7b-2691-4d0d-a1c6-eb842bc1a6a2",
      "name": "Scheduled Trigger",
      "type": "n8n-nodes-base.scheduleTrigger",
      "position": [
        -4576,
        528
      ],
      "typeVersion": 1.1,
      "disabled": true
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "typeVersion": 1.1,
      "position": [
        -4592,
        272
      ],
      "id": "501b5128-0e4a-460b-80d1-a2e719621e4f",
      "name": "When chat message received",
      "webhookId": "270ffc15-d1ca-4356-b199-f3f8d50fbbd8"
    },
    {
      "parameters": {
        "path": "9a9d48b2-98eb-442b-8af0-2be4053d96e0",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "96136382-03c5-48c1-be37-6bb88930080a",
      "name": "AlertManager Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [
        -4576,
        800
      ],
      "typeVersion": 2,
      "webhookId": "9a9d48b2-98eb-442b-8af0-2be4053d96e0",
      "disabled": true
    },
    {
      "parameters": {
        "jsCode": "// Unified Entry Point - Alert Only Mode (Fixed)\n// \"error\" key yerine \"hasError\" kullanƒ±yoruz\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// Timestamp ve metadata\nconst timestamp = new Date().toISOString();\nconst executionId = $execution.id;\nconst workflowId = $workflow.id;\nconst contextId = 'ctx-' + Date.now() + '-' + Math.random().toString(36).substring(7);\nconst requestId = inputData.requestId || ('req-' + Date.now());\n\n// Alert bilgilerini √ßƒ±kar - ZORUNLU\nlet alertContext = {};\nlet kubernetesFilters = {};\nlet priority = 'normal';\nlet namespaces = [];\n\n// Alert Listener'dan gelen veriyi kontrol et\nif (inputData.source === 'alert-listener' && inputData.context) {\n  alertContext = inputData.context;\n  kubernetesFilters = inputData.kubernetesFilters || {};\n  priority = inputData.priority || alertContext.alertPriority || 'normal';\n  namespaces = inputData.namespaces || [];\n  \n  // Eƒüer namespace bo≈üsa kubernetes filter'dan al\n  if (namespaces.length === 0 && kubernetesFilters.namespace) {\n    namespaces = [kubernetesFilters.namespace];\n  }\n  \n  console.log('Alert received:', {\n    alertName: alertContext.alertName,\n    priority: priority,\n    pod: kubernetesFilters.pod,\n    namespace: kubernetesFilters.namespace\n  });\n} else {\n  // Alert yoksa hata mesajƒ± d√∂nd√ºr (error yerine hasError kullan)\n  console.error('No alert context found. This workflow requires an alert.');\n  return [{\n    hasError: true,\n    errorMessage: 'This workflow requires an alert context from Alert Listener',\n    errorType: 'MISSING_ALERT_CONTEXT',\n    timestamp: timestamp,\n    source: inputData.source || 'unknown'\n  }];\n}\n\n// Stage configuration - alert priority'ye g√∂re\nconst stageConfig = {\n  maxStages: priority === 'critical' ? 6 : priority === 'high' ? 4 : 2,\n  enablePatternAnalysis: true,\n  enableAnomalyDetection: true,\n  enablePredictiveAnalysis: priority === 'critical',\n  forceDeepAnalysis: priority === 'critical' || priority === 'high'\n};\n\n// Ana output objesi\nconst output = {\n  timestamp: timestamp,\n  source: {\n    type: 'alert-listener',\n    priority: priority\n  },\n  analysisParams: {\n    startTime: inputData.startTime || (Date.now() - 3600000),\n    endTime: inputData.endTime || Date.now(),\n    namespaces: namespaces,\n    services: alertContext.affectedServices || [],\n    focusAreas: alertContext.errorPatterns || [],\n    analysisType: 'alert-driven',\n    context: alertContext\n  },\n  kubernetesFilters: kubernetesFilters,\n  stageConfig: stageConfig,\n  priority: priority,\n  forceDeepAnalysis: stageConfig.forceDeepAnalysis,\n  metadata: {\n    workflowId: workflowId,\n    executionId: executionId,\n    requestId: requestId,\n    orchestratorId: inputData.orchestratorId || null,\n    alertId: alertContext.alertId || null,\n    alertName: alertContext.alertName || null\n  },\n  prometheusQueries: inputData.queries || [],\n  _context: {\n    contextId: contextId,\n    createdAt: timestamp,\n    source: {\n      type: 'alert-listener',\n      priority: priority\n    },\n    initialParams: {\n      startTime: inputData.startTime || (Date.now() - 3600000),\n      endTime: inputData.endTime || Date.now(),\n      namespaces: namespaces,\n      services: alertContext.affectedServices || [],\n      focusAreas: alertContext.errorPatterns || [],\n      analysisType: 'alert-driven',\n      context: alertContext\n    },\n    kubernetesFilters: kubernetesFilters,\n    alertContext: alertContext,\n    stageConfig: stageConfig,\n    priority: priority,\n    forceDeepAnalysis: stageConfig.forceDeepAnalysis,\n    workflowMetadata: {\n      workflowId: workflowId,\n      executionId: executionId,\n      requestId: requestId,\n      orchestratorId: inputData.orchestratorId || null\n    },\n    stageResults: {},\n    decisions: {},\n    debug: {\n      contextVersion: '1.0',\n      createdBy: 'Unified Entry Point',\n      sourceType: 'alert-listener',\n      alertName: alertContext.alertName || 'unknown',\n      priority: priority\n    }\n  }\n};\n\nreturn [output];"
      },
      "id": "e01de058-0256-4e62-8e5b-2ef67ab76af6",
      "name": "Unified Entry Point",
      "type": "n8n-nodes-base.code",
      "position": [
        -4080,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.userMessage }}",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "={{ $json.systemPrompt }}"
        }
      },
      "id": "b752599b-f64c-4bf2-af13-533542e70aa4",
      "name": "Stage 1: Health Snapshot",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -3040,
        496
      ],
      "typeVersion": 1.9,
      "retryOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Stage 2 Decision - Alert ve cascading etkilerine g√∂re karar\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// T√ºm veriyi koru\nlet output = { ...inputData };\n\n// Stage 1 sonu√ßlarƒ±nƒ± al\nconst stage1Results = inputData.output || inputData.stage1Results || {};\n\n// ‚úÖ D√úZELTƒ∞LMƒ∞≈û: Context ve priority'yi doƒüru yerden al\nconst alertContext = inputData._context?.alertContext || \n                     inputData.alertContext || \n                     inputData.stageContext?.alertContext || {};\n\nconst priority = inputData._context?.priority || \n                 inputData.priority || \n                 alertContext.alertPriority || \n                 'normal';\n\n// Karar deƒüi≈ükenleri\nlet requiresDeepAnalysis = false;\nlet decisionReasons = [];\nlet suggestedStages = [];\n\n// Alert priority'sine g√∂re otomatik derinle≈ütirme\nif (priority === 'critical') {\n  requiresDeepAnalysis = true;\n  suggestedStages = [2, 3, 4, 5, 6];\n  decisionReasons.push('Critical alert requires full analysis pipeline');\n} else if (priority === 'high') {\n  requiresDeepAnalysis = true;\n  suggestedStages = [2, 3, 4];\n  decisionReasons.push('High priority alert requires deep analysis');\n} else if (priority === 'medium') {\n  // Medium priority - Stage 1 sonu√ßlarƒ±na g√∂re karar ver\n  if (stage1Results.cascadingEffects?.hasCascadingFailures) {\n    requiresDeepAnalysis = true;\n    suggestedStages = [2, 3];\n    decisionReasons.push('Cascading failures detected');\n  }\n}\n\n// Stage 1'den gelen √∂neriler\nif (stage1Results.proceed_to_stage2 === true) {\n  if (!requiresDeepAnalysis) {\n    requiresDeepAnalysis = true;\n    if (suggestedStages.length === 0) {\n      suggestedStages = [2, 3];\n    }\n    decisionReasons.push(stage1Results.reason || 'Stage 1 recommends deep analysis');\n  }\n}\n\n// ‚úÖ EKLENEN: forceDeepAnalysis kontrol√º\nif (inputData._context?.forceDeepAnalysis === true || \n    inputData.forceDeepAnalysis === true ||\n    stage1Results.forceDeepAnalysis === true) {\n  requiresDeepAnalysis = true;\n  if (suggestedStages.length === 0) {\n    suggestedStages = [2, 3, 4, 5, 6];\n  }\n  if (!decisionReasons.includes('Force deep analysis flag is set')) {\n    decisionReasons.push('Force deep analysis flag is set');\n  }\n}\n\n// Cascading etkileri kontrol et\nif (stage1Results.cascadingEffects) {\n  const cascading = stage1Results.cascadingEffects;\n  \n  if (cascading.affectedComponents && cascading.affectedComponents.length > 3) {\n    requiresDeepAnalysis = true;\n    if (!suggestedStages.includes(4)) suggestedStages.push(4);\n    decisionReasons.push(`Multiple components affected: ${cascading.affectedComponents.length}`);\n  }\n  \n  if (cascading.spreadPattern === 'escalating' || cascading.spreadPattern === 'spreading') {\n    requiresDeepAnalysis = true;\n    if (!suggestedStages.includes(5)) suggestedStages.push(5);\n    if (!suggestedStages.includes(6)) suggestedStages.push(6);\n    decisionReasons.push('Issue is spreading - prevention needed');\n  }\n}\n\n// Restart sayƒ±sƒ± kontrol√º\nif (stage1Results.metrics?.restarts > 5) {\n  requiresDeepAnalysis = true;\n  decisionReasons.push(`High restart count: ${stage1Results.metrics.restarts}`);\n}\n\n// ‚úÖ EKLENEN: Critical status kontrol√º\nif (stage1Results.overall_status === 'critical' || stage1Results.urgency === 'critical') {\n  if (!requiresDeepAnalysis) {\n    requiresDeepAnalysis = true;\n    suggestedStages = [2, 3, 4, 5, 6];\n    decisionReasons.push('Critical status detected in Stage 1');\n  }\n}\n\n// Stage'leri sƒ±rala ve unique yap\nsuggestedStages = [...new Set(suggestedStages)].sort((a, b) => a - b);\n\n// Karar objesi\nconst decision = {\n  requiresDeepAnalysis: requiresDeepAnalysis,\n  timestamp: new Date().toISOString(),\n  reasons: decisionReasons,\n  suggestedStages: suggestedStages,\n  alertInfo: {\n    name: alertContext.alertName || 'Unknown',\n    priority: priority,  // ‚úÖ Artƒ±k doƒüru priority kullanƒ±lƒ±yor\n    hasCascading: stage1Results.cascadingEffects?.hasCascadingFailures || false\n  },\n  estimatedTime: `${suggestedStages.length * 5}-${suggestedStages.length * 10} seconds`\n};\n\n// Output'a ekle\noutput.stage1Results = stage1Results;\noutput.decision = decision;\noutput.proceedToDeepAnalysis = requiresDeepAnalysis;\n\n// Context g√ºncelle\noutput._context = {\n  ...output._context,\n  stage1Complete: true,\n  stage2Decision: decision,\n  stageResults: {\n    ...output._context?.stageResults,\n    stage1: stage1Results\n  }\n};\n\nconsole.log('Stage 2 Decision:', {\n  alertName: alertContext.alertName,\n  priority: priority,\n  willProceed: requiresDeepAnalysis,\n  stages: suggestedStages,\n  reasons: decisionReasons\n});\n\nreturn [output];"
      },
      "id": "594eee1f-7009-4176-a27a-ae3056d21f7e",
      "name": "Stage 2 Decision",
      "type": "n8n-nodes-base.code",
      "position": [
        -2496,
        448
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "leftValue": "={{ $json.proceedToDeepAnalysis || $json.decision.requiresDeepAnalysis }}",
              "rightValue": "=true",
              "operator": {
                "type": "boolean",
                "operation": "true",
                "singleValue": true
              },
              "id": "4a8f54c8-a3d2-4eb3-b133-085ad6a72a40"
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "ce5a3577-dc0c-4590-85f2-eb7b032cc61a",
      "name": "Route After Decision",
      "type": "n8n-nodes-base.if",
      "position": [
        -2320,
        448
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# Stage 2: Deep Analysis\n\n## TIME:\nStart: {{ $json._context.initialParams.startTime }}\nEnd: {{ $json._context.initialParams.endTime }}\n\n## CONTEXT:\nID: {{ $json._context.contextId }}\nAlert: {{ $json._context.alertContext.alertName }}\nPod: {{ $json._context.kubernetesFilters.pod }}\nNamespace: {{ $json._context.initialParams.namespaces[0] }}\nPriority: {{ $json._context.priority }}\n\n## STAGE 1 KEY FINDINGS:\nStatus: {{ $json.stage1Results.overall_status }}\nAlerts: {{ $json.stage1Results.alerts.critical }} critical\nIssue: {{ $json.stage1Results.quick_findings[0] }}\n\n## EXECUTE ANALYSIS:\n\nPhase 1 (Pod Analysis):\n- Pod Status Check\n- Container Restarts  \n- Pod Resource Usage\n\nPhase 2 (Trends):\n- Historical Comparison 24h\n\nPhase 3 (Anomaly):\n- Resource Exhaustion Prediction\n- Anomaly Patterns\n\n## OUTPUT JSON (NO MARKDOWN):\n{\n  \"stage\": \"deep_analysis\",\n  \"investigation_id\": \"{{ $json._context.contextId }}-s2\",\n  \"execution_phases\": {\n    \"instant\": {\n      \"tools_used\": [],\n      \"findings\": {\n        \"critical_pods\": [],\n        \"resource_pressure\": []\n      }\n    },\n    \"trend\": {\n      \"tools_used\": [],\n      \"findings\": {\n        \"memory_growth\": \"\",\n        \"restart_pattern\": \"\"\n      }\n    },\n    \"anomaly\": {\n      \"tools_used\": [],\n      \"findings\": {\n        \"predictions\": [],\n        \"anomalies\": []\n      }\n    }\n  },\n  \"correlation_matrix\": {\n    \"primary_chain\": \"\",\n    \"affected_services\": [],\n    \"blast_radius\": \"\",\n    \"kubernetes_impact\": {\n      \"evicted_pods\": 0,\n      \"pending_pods\": 0\n    }\n  },\n  \"root_cause\": {\n    \"identified\": false,\n    \"component\": \"\",\n    \"issue\": \"\",\n    \"evidence\": [],\n    \"confidence\": 0.0\n  },\n  \"proceed_to_stage3\": false,\n  \"_context\": {\n    \"contextId\": \"{{ $json._context.contextId }}\",\n    \"priority\": \"{{ $json._context.priority }}\"\n  }\n}\n\nReturn ONLY JSON, no text before/after.",
        "options": {
          "systemMessage": "You are a Kubernetes cluster analyzer. You MUST return ONLY raw JSON without any formatting, markdown, TEXT or code blocks. Do not use triple backticks or any other wrapper around your response. Your entire response must be valid JSON that starts with { and ends with }. Never include explanatory text before or after the JSON."
        }
      },
      "id": "c5ffc5f5-258a-4459-99e9-1dbc84c9b02b",
      "name": "Stage 2: Deep Analysis",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -1648,
        576
      ],
      "typeVersion": 1.9
    },
    {
      "parameters": {},
      "id": "5c397ee9-88a4-41fa-811b-f53de9f69498",
      "name": "Wait 3s",
      "type": "n8n-nodes-base.wait",
      "position": [
        -1952,
        416
      ],
      "typeVersion": 1.1,
      "webhookId": "bbd2b00f-68fd-4e67-a38a-074775da1ac4"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "==# Stage 3: Alert Intelligence & Correlation - OPTIMIZED\n\n## ‚ö° EFFICIENCY RULES:\n- Alert History 24h = 1 call for ALL alerts (NOT per alert!)\n- Active Alerts = 1 call for ALL alerts  \n- Each SLO = Maximum 1 call\n- Total calls must be ‚â§ 7\n\n## üéØ TOOL EXECUTION STRATEGY (CRITICAL - MAX 7 TOOL CALLS):\n\n### Phase 1: Alert Discovery (2 tools ONLY)\n1. **Active Alerts Details** - Call ONCE to get ALL current alerts\n2. **Alert History 24h** - Call ONCE ONLY for overall pattern analysis\n   ‚ö†Ô∏è IMPORTANT: This returns aggregated data for ALL alerts, DO NOT call multiple times!\n\n### Phase 2: SLO Assessment (Max 5 tools - CONDITIONAL)\nOnly call these IF active alerts exist:\n- IF pod-related alerts ‚Üí Pod Ready SLO (1 call)\n- IF node issues ‚Üí Node Ready SLO (1 call)  \n- IF restart alerts ‚Üí Pod Restart Rate SLO (1 call)\n- IF deployment issues ‚Üí Deployment Replica Health (1 call)\n- Skip Container Running SLO if Pod Ready is healthy\n\n## ‚ö†Ô∏è CRITICAL RULES:\n1. **Alert History 24h** must be called EXACTLY ONCE - it returns data for ALL alerts\n2. NEVER call the same tool twice\n3. STOP after 7 total tool calls\n4. If first 2 tools show no alerts, SKIP all SLO tools\n\n## üîÑ EXECUTION FLOW:\nCall Active Alerts Details\n‚Üì\nIF (alerts.length > 0):\nCall Alert History 24h ONCE\nELSE:\nSkip Alert History, proceed with empty patterns\n‚Üì\nBased on alert types from step 1:\n\nPod alerts? ‚Üí Pod Ready SLO\nNode alerts? ‚Üí Node Ready SLO\nContinue conditionally...\n\n## üìä TOOL CALL TRACKER:\n‚òê Active Alerts Details (1/1)\n‚òê Alert History 24h (0/1) - ONE CALL ONLY!\n‚òê Pod Ready SLO (0/1 if needed)\n‚òê Node Ready SLO (0/1 if needed)\n‚òê Pod Restart Rate SLO (0/1 if needed)\n‚òê Deployment Health (0/1 if needed)\nTotal: 0/7 maximum\n\n## üïê TIME PARAMETERS:\nUse these EXACT timestamps from context:\n- Start Time: {{ $json._context.initialParams.startTime }}\n- End Time: {{ $json._context.initialParams.endTime }}\n\nIMPORTANT:\n- These are Unix timestamps in seconds\n- Convert for display: new Date(timestamp * 1000).toISOString()\n- DO NOT use mock dates like \"2024-06-15\"\n- For current timestamp, use new Date().toISOString()\n\n## üìã CONTEXT INFORMATION:\n- Context ID: {{ $json._context.contextId }}\n- Stage 2 Root Cause: {{ $json.stage2Data.root_cause.issue }}\n- Affected Services: {{ JSON.stringify($json.stage2Data.correlation_matrix.affected_services) }}\n\n## üîß TOOL RESPONSE HANDLING:\n\n### Alert History 24h Tool - SINGLE CALL ONLY:\nThis tool returns aggregated history for ALL alerts with query:\ncount by (alertname, severity) (ALERTS{alertstate=\"firing\"})\n\n‚ö†Ô∏è USAGE:\n- Call ONCE to get 24-hour trend for ALL alerts\n- Response contains counts for EACH alert type over time\n- DO NOT call per alert - it already includes all alerts\n- Use the single response to analyze patterns for all alerts\n\nExample interpretation:\n- If response shows alertname=\"KubePodCrashLooping\" increasing ‚Üí trend detected\n- If multiple alertnames appear at same timestamps ‚Üí correlation exists\n- Empty response ‚Üí no historical alerts in 24h\n\n### For Active Alerts Details tool:\nThe tool uses this query to get Kubernetes-related alerts:\nALERTS{alertstate=\"firing\",alertname=~\"Kube.*|Container.*|Pod.*|Node.*\"}\n\nThe tool will return alerts with these labels:\n- alertname: Name of the alert (e.g., KubePodCrashLooping, KubeNodeNotReady)\n- alertstate: Will be \"firing\" \n- severity: Alert severity (critical, warning, info) if defined in the alert rule\n- namespace: Kubernetes namespace where the issue is occurring\n- pod: Pod name if the alert is pod-related\n- node: Node name if the alert is node-related\n- container: Container name if applicable\n\nNote: Summary and description are defined in the alert rules, not in the metrics. If you need detailed descriptions, refer to the alert names:\n- KubePodCrashLooping: Pod is restarting frequently\n- KubeNodeNotReady: Node is not in ready state\n- KubeDeploymentReplicasMismatch: Deployment has incorrect replica count\n- KubeContainerWaiting: Container is in waiting state\n- KubePodNotReady: Pod is not ready to serve traffic\n\nWhen analyzing alerts:\n1. Count of each alert type\n2. Which namespaces/pods/nodes are affected\n3. Severity distribution\n4. How long alerts have been firing (if timestamp available)\n\n## üìä ALERT HISTORY PROCESSING (After single call):\nFrom the Alert History 24h response, extract:\n1. Which alerts have been recurring (appear in multiple time slots)\n2. Peak times when most alerts fired\n3. Any correlation between different alert types\n4. Trend direction (increasing/decreasing/stable)\n\nDO NOT make additional calls to get more detail!\n\n### For SLO Status Check Tools:\n**CRITICAL**: SLO tools may return \"NaN\", empty results, or errors. Handle these cases:\n- If result is \"NaN\" ‚Üí assume 100% (no issues detected)\n- If result is empty array ‚Üí assume 100% (no metrics to check)\n- If result has error ‚Üí assume 100% and note in debug\n- If result has value ‚Üí use the numeric value\n\n## üìä COMPOSITE SLO CALCULATION:\nIf multiple SLO tools are available, calculate a weighted composite:\n\nCall each SLO tool and collect results:\n- Pod Ready SLO ‚Üí weight: 30%\n- Container Running SLO ‚Üí weight: 20%\n- Node Ready SLO ‚Üí weight: 25%\n- Pod Restart Rate SLO ‚Üí weight: 15%\n- Deployment Health ‚Üí weight: 10%\n\nFor each SLO result:\n- If \"NaN\" or empty ‚Üí use 100\n- If error ‚Üí use 100 and note in debug\n- Otherwise use actual numeric value\n\nCalculate composite:\ncomposite = (podReady * 0.3) + (containerRunning * 0.2) + (nodeReady * 0.25) + (restartRate * 0.15) + (deploymentHealth * 0.1)\n\nInterpret composite score:\n- >= 99.9 ‚Üí \"green\" (SLO Met)\n- 99.0-99.9 ‚Üí \"yellow\" (SLO Warning)\n- < 99.0 ‚Üí \"red\" (SLO Violation)\n\n## Common Kubernetes Alert Descriptions:\nconst alertDescriptions = {\n  \"KubePodCrashLooping\": {\n    summary: \"Pod is crash looping\",\n    description: \"Pod has restarted more than 5 times in the last 10 minutes\",\n    severity: \"critical\"\n  },\n  \"KubeNodeNotReady\": {\n    summary: \"Node is not ready\",\n    description: \"Node has been unready for more than 5 minutes\",\n    severity: \"critical\"\n  },\n  \"KubeDeploymentReplicasMismatch\": {\n    summary: \"Deployment replica mismatch\",\n    description: \"Deployment has not matched the expected number of replicas\",\n    severity: \"warning\"\n  },\n  \"KubeContainerWaiting\": {\n    summary: \"Container waiting\",\n    description: \"Container has been in waiting state for more than 1 hour\",\n    severity: \"warning\"\n  },\n  \"KubePodNotReady\": {\n    summary: \"Pod not ready\",\n    description: \"Pod has been in a non-ready state for more than 5 minutes\",\n    severity: \"warning\"\n  },\n  \"KubeHpaMaxedOut\": {\n    summary: \"HPA maxed out\",\n    description: \"HPA has been at max replicas for more than 15 minutes\",\n    severity: \"warning\"\n  }\n};\n\n## üîß TOOL PARAMETERS (USE EXACTLY):\n\n### Alert History 24h:\nNO PARAMETERS NEEDED - Tool automatically uses:\n- start: 24 hours ago\n- end: now\n- step: 3600 (hourly buckets)\n- query: count by (alertname, severity) for ALL alerts\n\n### SLO Tools:\n{\n  \"namespace\": \"{{ $json._context.initialParams.namespaces[0] || 'etiyamobile-production' }}\",\n  \"service\": \"{{ $json.output.correlation_matrix.affected_services && $json.output.correlation_matrix.affected_services[0] || '' }}\"\n}\n\n## STOP CONDITIONS:\n- No active alerts ‚Üí Skip all remaining tools\n- Total tool calls = 7 ‚Üí Stop immediately\n- All SLOs return 100% ‚Üí Skip remaining SLOs\n\n## üö® CRITICAL OUTPUT REQUIREMENT:\nRETURN ONLY VALID JSON - NO MARKDOWN, NO CODE BLOCKS\nDO NOT WRAP YOUR RESPONSE IN ```json``` TAGS\nHANDLE ALL EMPTY/NULL RESPONSES GRACEFULLY\n\nReturn ONLY this JSON structure:\n{\n  \"stage\": \"alert_intelligence\",\n  \"active_alerts\": [\n    {\n      \"name\": \"<actual alert name from tool response or 'No alerts'>\",\n      \"severity\": \"<actual severity from tool response or 'unknown'>\",\n      \"count\": <actual count from tool response or 0>,\n      \"duration\": \"<calculate from current time minus alert start time or 'unknown'>\",\n      \"labels\": <actual labels object from tool response or {}>,\n      \"annotations\": <actual annotations from tool response if available or {}>\n    }\n  ],\n  \"alert_groups\": [\n    {\n      \"root_alert\": \"<identify main alert based on correlation or 'none'>\",\n      \"related_alerts\": [<list other related alerts or empty array>],\n      \"correlation_score\": <calculate 0.0-1.0 based on shared labels or 0>,\n      \"shared_labels\": <identify common labels between alerts or {}>\n    }\n  ],\n  \"knowledge_base_matches\": [\n    {\n      \"alert\": \"<alert name or 'none'>\",\n      \"kb_entry\": {\n        \"root_causes\": [\"Based on alert type and previous incidents\"],\n        \"diagnostic_commands\": [\"kubectl describe\", \"kubectl logs\"],\n        \"immediate_actions\": [\"Check pod status\", \"Review recent changes\"],\n        \"long_term_solutions\": [\"Update resource limits\", \"Fix application code\"]\n      },\n      \"applicability_score\": <0.0-1.0 based on match or 0>\n    }\n  ],\n  \"alert_patterns\": {\n    \"recurring\": [],\n    \"storm_detection\": {\n      \"detected\": false,\n      \"alert_count\": <count of alerts or 0>,\n      \"time_window\": \"5m\",\n      \"likely_root\": \"<identify if there's a common cause or null>\"\n    }\n  },\n  \"slo_impact\": {\n    \"availability_slo\": {\n      \"target\": \"99.9%\",\n      \"current\": \"<calculated SLO value or '100'>%\",\n      \"error_budget_used\": \"<calculated percentage or '0'>%\",\n      \"time_remaining\": \"<based on burn rate or '30d'>\",\n      \"components\": {\n        \"deployment_health\": \"<if single SLO tool used, put value here or '100'>%\"\n      },\n      \"status\": \"<green|yellow|red based on current vs target>\"\n    },\n    \"affected_slis\": [<list SLIs below target or empty array>]\n  },\n  \"recommended_alert_actions\": [\n    {\n      \"alert\": \"<alert name or 'none'>\",\n      \"action\": \"<specific remediation action or 'Monitor'>\",\n      \"confidence\": <0.0-1.0 or 0>,\n      \"risk\": \"<low|medium|high>\",\n      \"command\": \"<kubectl or other command or null>\"\n    }\n  ],\n  \"proceed_to_stage4\": <true if alerts need investigation, false otherwise>,\n  \"auto_remediation_approved\": <true only for low-risk known issues>,\n  \"_context\": <copy the exact _context object from input>,\n  \"_debug\": {\n    \"nodeType\": \"Stage 3: Alert Intelligence\",\n    \"processedAt\": \"<current ISO timestamp from new Date().toISOString()>\",\n    \"contextId\": \"<copy from input _context.contextId>\",\n    \"contextPreserved\": true,\n    \"receivedFromStage\": \"Fix Stage 2 Context\",\n    \"stageSequence\": <take input _debug.stageSequence array and add \"Stage 3: Alert Intelligence\">,\n    \"timeRangeUsed\": {\n      \"start\": <copy from input _context.initialParams.startTime>,\n      \"end\": <copy from input _context.initialParams.endTime>\n    },\n    \"sloToolErrors\": [],\n    \"toolCallCount\": <actual number of tool calls made>,\n    \"alertHistoryCallCount\": <should be 1 or 0>\n  }\n}\n\n## üìù IMPORTANT NOTES:\n- If no alerts are found, return empty arrays but still complete the analysis\n- Use actual values from tool responses, don't make up data\n- For _context: Copy exactly as received in input\n- For timestamps: Use actual current time, not placeholders\n- Use knowledge from alertDescriptions to enrich alert information\n- ALWAYS handle NaN and empty responses gracefully\n- Default to safe values when data is missing\n- Alert History 24h must be called MAXIMUM ONCE\n\n",
        "options": {}
      },
      "id": "fb2bfc14-f15f-4619-b801-f7a32c7c7f9a",
      "name": "Stage 3: Alert Intelligence",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -912,
        560
      ],
      "typeVersion": 1.9
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# Stage 4: Automated Diagnosis & Deep Dive - CONTEXT AWARE\n\nExecute targeted diagnostics based on previous findings.\n\n## üïê TIME PARAMETERS:\n- Start: {{ $json._context.initialParams.startTime }}\n- End: {{ $json._context.initialParams.endTime }}\n- Display: new Date(timestamp * 1000).toISOString()\n- DO NOT use fake dates like \"2024-01-15\"\n\n## üìã CONTEXT:\n- Context ID: {{ $json._context.contextId }}\n- Primary Issue: {{ $json.stage3Data.recommended_actions[0].alert }}\n- Root Cause: {{ $json.stage2Data.root_cause.issue }}\n\n## üéØ CRITICAL POD INFORMATION:\n- Pod Name: {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\n- Namespace: {{ $json.stage2Data.critical_pods[0].namespace || $json.namespaces[0] }}\n- Status: {{ $json.stage2Data.critical_pods[0].status || 'Unknown' }}\n- Restart Count: {{ $json.stage2Data.critical_pods[0].restart_count || 0 }}\n- Memory Usage: {{ $json.stage2Data.critical_pods[0].resource_usage.memory || 'Unknown' }}\n- CPU Usage: {{ $json.stage2Data.critical_pods[0].resource_usage.cpu || 'Unknown' }}\n\n## üîß DIAGNOSTIC EXECUTION:\n\nBased on findings, execute appropriate diagnostics:\n- For pod issues: Use pod-specific tools with actual pod names\n- For node issues: Use node-specific tools with actual node names\n- Use exact timestamps from context\n\nTool parameters:\n{\n  \"namespace\": \"{{ $json.namespaces[0] }}\",\n  \"start\": {{ $json._context.initialParams.startTime }},\n  \"end\": {{ $json._context.initialParams.endTime }},\n  \"pod\": \"{{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\",\n  \"node\": \"{{ $json.stage2Data.critical_pods[0].node || 'unknown' }}\"\n}\n\nIMPORTANT: You MUST use the following pod for diagnostics:\n- Target Pod: {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\n- DO NOT use any mock pod names like \"pod-abc123\" or \"pod-xyz123\"\n- DO NOT use mock deployment names like \"mobile-app-deployment\"\n- Use the ACTUAL pod name provided above\n\n## üö® OUTPUT REQUIREMENT:\n**RETURN ONLY VALID JSON WITH ACTUAL DATA**\n\n{\n  \"stage\": \"automated_diagnosis\",\n  \"diagnostics_executed\": [\n    {\n      \"target\": \"{{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\",\n      \"type\": \"pod\",\n      \"commands_run\": [\n        \"kubectl describe pod {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }} -n {{ $json.namespaces[0] }}\",\n        \"kubectl logs {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }} -n {{ $json.namespaces[0] }} --since=24h\",\n        \"kubectl get events -n {{ $json.namespaces[0] }} --field-selector involvedObject.name={{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\"\n      ],\n      \"findings\": {\n        \"pod_status\": {\n          \"phase\": \"{{ $json.stage2Data.critical_pods[0].status || 'Unknown' }}\",\n          \"restart_count\": {{ $json.stage2Data.critical_pods[0].restart_count || 0 }},\n          \"last_termination\": {\n            \"reason\": \"OOMKilled\",\n            \"exit_code\": 137,\n            \"finished_at\": \"{{ new Date($json._context.initialParams.endTime * 1000).toISOString() }}\"\n          }\n        },\n        \"error_logs\": [\n          {\n            \"timestamp\": \"{{ new Date($json._context.initialParams.endTime * 1000).toISOString() }}\",\n            \"level\": \"Error\",\n            \"message\": \"Container killed due to memory limit\",\n            \"stack_trace\": null\n          }\n        ],\n        \"events\": [<actual k8s events>],\n        \"resource_usage\": {\n          \"memory_request\": \"1Gi\",\n          \"memory_limit\": \"2Gi\",\n          \"memory_used\": \"{{ $json.stage2Data.critical_pods[0].resource_usage.memory || 'Unknown' }}\",\n          \"cpu_used\": \"{{ $json.stage2Data.critical_pods[0].resource_usage.cpu || 'Unknown' }}\"\n        }\n      }\n    }\n  ],\n  \"enriched_context\": {\n    \"deployment_info\": {\n      \"name\": \"{{ ($json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown').split('-').slice(0, -2).join('-') }}\",\n      \"version\": \"unknown\",\n      \"replicas\": \"unknown\",\n      \"last_update\": \"{{ new Date($json._context.initialParams.endTime * 1000).toISOString() }}\",\n      \"update_strategy\": \"RollingUpdate\"\n    },\n    \"recent_changes\": [\n      {\n        \"type\": \"deployment\",\n        \"time\": \"{{ new Date($json._context.initialParams.endTime * 1000).toISOString() }}\",\n        \"change\": \"Pod experiencing memory issues\",\n        \"user\": \"system\"\n      }\n    ],\n    \"dependencies\": {\n      \"upstream\": [],\n      \"downstream\": {{ $json.stage2Data.affected_services || [] }},\n      \"databases\": [],\n      \"external\": []\n    }\n  },\n  \"diagnostic_summary\": {\n    \"confirmed_issues\": [\n      {\n        \"issue\": \"{{ $json.stage2Data.root_cause.issue || 'Pod instability detected' }}\",\n        \"evidence\": {{ $json.stage2Data.root_cause.evidence || [] }},\n        \"severity\": \"critical\",\n        \"impact\": \"Service {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }} is experiencing outages\",\n        \"namespace\": \"{{ $json.namespaces[0] }}\"\n      }\n    ],\n    \"secondary_issues\": []\n  },\n  \"proceed_to_stage5\": true,\n  \"remediation_confidence\": {{ $json.stage2Data.root_cause.confidence || 0.85 }},\n  \"_context\": {{ $json._context }},\n  \"_debug\": {\n    \"nodeType\": \"Stage 4: Automated Diagnosis\",\n    \"processedAt\": \"<current ISO timestamp>\",\n    \"contextId\": \"{{ $json._context.contextId }}\",\n    \"contextPreserved\": true,\n    \"receivedFromStage\": \"Fix Stage 3 Context\",\n    \"stageSequence\": \"\",\n    \"diagnosticsCount\": 1,\n    \"autoRemediationEnabled\": true,\n    \"actualPodUsed\": \"{{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}\",\n    \"timeRangeUsed\": {\n      \"start\": {{ $json._context.initialParams.startTime }},\n      \"end\": {{ $json._context.initialParams.endTime }}\n    }\n  }\n}\n\n## ‚ö†Ô∏è CRITICAL:\n- ALL TIMESTAMPS MUST BE FROM ACTUAL DATA\n- NO HARDCODED DATES\n- USE REAL PROMETHEUS METRICS\n- NO MOCK DATA\n- secondary_issues MUST BE AN ARRAY (even if empty: [])\n- TARGET POD MUST BE: {{ $json.stage2Data.critical_pods[0].pod || $json.stage2Data.critical_pods[0].pod_name || 'unknown' }}",
        "options": {
          "systemMessage": "CRITICAL: You MUST respond with ONLY valid JSON that exactly matches the schema. \nDo not include any text before or after the JSON.\nDo not include markdown code blocks.\nStart your response with { and end with }"
        }
      },
      "id": "186caad2-417f-4d49-a812-8386ee23b3a7",
      "name": "Stage 4: Automated Diagnosis",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        -336,
        544
      ],
      "typeVersion": 1.9
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# Stage 5: AI-Powered Remediation Plan - CONTEXT AWARE\n\nGenerate remediation plan based on all findings.\n\n## üö® CRITICAL OUTPUT REQUIREMENT:\n**YOU MUST RETURN ONLY VALID JSON - NO MARKDOWN, NO CODE BLOCKS, NO EXTRA TEXT**\n**DO NOT WRAP YOUR RESPONSE IN ```json``` TAGS**\n**RETURN RAW JSON ONLY**\n\n## üïê TIME PARAMETERS:\n- Analysis Period: From timestamp {{ $json._context.initialParams.startTime }} to {{ $json._context.initialParams.endTime }}\n- Current Time: Use new Date().toISOString() for current timestamp\n\n## üìã COMPLETE CONTEXT:\n- Context ID: {{ $json._context.contextId }}\n- Primary Issue: {{ $json.primaryDiagnosis.issue }}\n- Severity: {{ $json.primaryDiagnosis.severity }}\n- Affected Component: {{  $json.stage4Data.enriched_context.deployment_info.name}}\n\n## üíæ OUTPUT FORMAT (MUST BE PURE JSON):\n\n{\n  \"stage\": \"ai_powered_analysis\",\n  \"analysis_id\": \"{{ $json._context.contextId }}-stage5\",\n  \"remediation_plan\": {\n    \"immediate_actions\": [\n      {\n        \"action\": \"Rollback deployment to previous version\",\n        \"command\": \"kubectl rollout undo deployment/{{ $json.stage4Data.enriched_context.deployment_info}} -n {{ $json.primaryDiagnosis.namespace }}\",\n        \"risk\": \"low\",\n        \"estimated_time\": \"2-5 minutes\",\n        \"expected_outcome\": \"Restore service to previous stable version\"\n      }\n    ],\n    \"short_term_fixes\": [\n      {\n        \"action\": \"Increase memory limits temporarily\",\n        \"timeline\": \"1-2 days\",\n        \"details\": \"Set memory limit to 2Gi while investigating root cause\"\n      }\n    ],\n    \"long_term_solutions\": [\n      {\n        \"action\": \"Fix memory leak in TransactionHandler\",\n        \"timeline\": \"1-2 weeks\",\n        \"details\": \"Review and fix the memory leak in payment processing code\"\n      }\n    ],\n    \"preventive_measures\": [\n      \"Implement memory profiling in CI/CD\",\n      \"Add memory leak detection tests\",\n      \"Set up gradual rollout strategy\"\n    ]\n  },\n  \"risk_assessment\": {\n    \"overall_risk\": \"medium\",\n    \"factors\": [\n      \"Payment service is critical\",\n      \"Rollback is tested and safe\",\n      \"Memory issue is contained to specific pods\"\n    ],\n    \"mitigation_steps\": [\n      \"Monitor closely after rollback\",\n      \"Keep team on standby\",\n      \"Prepare hotfix if needed\"\n    ]\n  },\n  \"implementation_order\": [\n    {\n      \"step\": 1,\n      \"action\": \"Execute rollback\",\n      \"dependencies\": [],\n      \"validation\": \"Check pod status and memory usage\"\n    },\n    {\n      \"step\": 2,\n      \"action\": \"Verify service health\",\n      \"dependencies\": [\"step_1\"],\n      \"validation\": \"Check error rates and response times\"\n    },\n    {\n      \"step\": 3,\n      \"action\": \"Update monitoring alerts\",\n      \"dependencies\": [\"step_2\"],\n      \"validation\": \"Ensure alerts are firing correctly\"\n    }\n  ],\n  \"success_metrics\": {\n    \"immediate\": [\n      \"Pod restart count = 0\",\n      \"Memory usage < 80% of limit\",\n      \"Error rate < 0.1%\"\n    ],\n    \"short_term\": [\n      \"No OOMKilled events in 24h\",\n      \"SLO compliance > 99.9%\"\n    ],\n    \"long_term\": [\n      \"Memory leak fixed in code\",\n      \"Automated memory testing in place\"\n    ]\n  },\n  \"rollback_plan\": {\n    \"trigger_conditions\": [\n      \"Error rate > 5%\",\n      \"Multiple pod failures\",\n      \"Memory usage continues to spike\"\n    ],\n    \"steps\": [\n      \"Revert to current version\",\n      \"Scale up replicas\",\n      \"Enable circuit breaker\"\n    ],\n    \"validation\": \"Verify previous version number before rollback\"\n  },\n  \"_context\": {{ JSON.stringify($json._context) }},\n  \"_debug\": {\n    \"nodeType\": \"Stage 5: AI-Powered Analysis\",\n    \"processedAt\": \"<use new Date().toISOString()>\",\n    \"contextId\": \"{{ $json._context.contextId }}\",\n    \"contextPreserved\": true,\n    \"analysisTimeRange\": {\n      \"start\": {{ $json._context.initialParams.startTime }},\n      \"end\": {{ $json._context.initialParams.endTime }}\n    },\n    \"stagesCompleted\": 5\n  }\n}\n\n## ‚ö†Ô∏è FINAL REMINDER:\n- **RETURN ONLY THE JSON OBJECT ABOVE**\n- **NO MARKDOWN FORMATTING**\n- **NO EXPLANATORY TEXT**\n- **NO CODE BLOCKS**",
        "options": {}
      },
      "id": "1569cf53-f72f-4ec7-bee5-8ccb085191b8",
      "name": "Stage 5: Smart Remediation",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        160,
        544
      ],
      "typeVersion": 1.9
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=# Stage 6: Prevention & Learning System - CONTEXT AWARE\n\nYou are the Prevention specialist, implementing long-term fixes and capturing learnings.\n\n## üéØ YOUR MISSION: PREVENT RECURRENCE\n\n**Complete Context Journey**: \n- Context ID: {{ $json._context.contextId }}\n- Source: {{ $json._context.source.type }}\n- Priority: {{ $json._context.priority }}\n- Workflow Duration: {{ $json._context.createdAt }} to now\n- Total Stages Executed: {{ $json._debug.stageSequence ? $json._debug.stageSequence.length : 5 }}\n\n**All Stage Results**: \n- Stage 1: {{ JSON.stringify($json._context.stageResults?.stage1?.output?.overall_status) }}\n- Stage 2: {{ JSON.stringify($json._context.stageResults?.stage2?.output?.root_cause?.issue) }}\n- Stage 3: {{ JSON.stringify($json._context.stageResults?.stage3?.output?.active_alerts?.length) }} alerts\n- Stage 4: Diagnostics completed\n- Stage 5: {{ JSON.stringify($json.stage5Results || $json) }}\n\n**Full Context**: {{ JSON.stringify($json._context) }}\n\n// Stage 6 Prompt'una eklenecek b√∂l√ºm\n// \"**All Stage Results**:\" kƒ±smƒ±ndan sonra ekleyin:\n\n## üìö KNOWLEDGE BASE LEARNING CONTEXT:\n\n**Current KB Stats**: \n- Total Alerts in KB: {{ $node[\"Load Alert Knowledge Base\"].json._alertKBData?.length || 0 }}\n- KB Last Updated: {{ $node[\"Load Alert Knowledge Base\"].json._alertKB?.loadedAt || 'Never' }}\n\n**Stage 3 KB Matches**: {{ JSON.stringify($json._context.stageResults?.stage3?.output?.knowledge_base_matches?.length || 0) }} alerts matched\n**Stage 4 KB Enhanced Issues**: {{ JSON.stringify($json._context.stageResults?.stage4?.output?.diagnostic_summary?.confirmed_issues?.filter(i => i.kb_enhanced)?.length || 0) }}\n**Stage 5 KB Actions Used**: {{ JSON.stringify($json._context.stageResults?.stage5?.output?.remediation_plan?.immediate_actions?.filter(a => a.source === \"Alert Knowledge Base\")?.length || 0) }}\n\n## üß† LEARNING OBJECTIVES:\n1. Identify new alert patterns not in KB\n2. Update KB with successful remediation strategies\n3. Refine existing KB entries based on outcomes\n4. Create new monitoring rules for prevention\n\nBased on the full journey through all 6 stages, generate:\n- New KB entries for unmatched alerts\n- Updates to existing KB entries\n- Preventive monitoring rules\n- Team training recommendations\n\n## üîß PREVENTION TOOLS:\n\n1. `Update Alert Rules` - Tune thresholds\n2. `Create Runbook Entry` - Document solution\n3. `Generate Prevention PR` - Code/config fixes\n4. `Update Knowledge Base` - Add to Excel\n5. `Schedule Follow-up` - Future checks\n6. `Training Recommendation` - Team education\n\n## üìö LEARNING CAPTURE:\n\n### What Happened?\n- Root cause identification from context\n- Impact assessment from all stages\n- Timeline reconstruction: {{ $json._context.createdAt }} to now\n\n### What Worked?\n- Successful remediation steps from Stage 5\n- Effective diagnostics from Stage 4\n- Quick wins identified\n\n### What Didn't?\n- Failed attempts\n- Misleading symptoms\n- Time wasters\n\n### What's Next?\n- Preventive measures based on priority: {{ $json._context.priority }}\n- Monitoring improvements\n- Process updates\n\n## üíæ OUTPUT FORMAT:\n\n```json\n{\n  \"stage\": \"prevention_learning\",\n  \"incident_summary\": {\n    \"id\": \"INC-{{ $json._context.contextId }}\",\n    \"title\": \"{{ $json._context.priority === 'critical' ? 'CRITICAL: ' : '' }}{{ $json._context.stageResults?.stage2?.output?.root_cause?.issue || 'Kubernetes Cluster Issue' }}\",\n    \"duration\": \"{{ new Date() - new Date($json._context.createdAt) }} ms\",\n    \"severity\": \"{{ $json._context.priority }}\",\n    \"services_affected\": {{ JSON.stringify($json._context.stageResults?.stage2?.output?.correlation_matrix?.affected_services || []) }},\n    \"customer_impact\": \"{{ $json._context.priority === 'critical' ? 'Significant impact' : 'Limited impact' }}\",\n    \"root_cause\": \"{{ $json._context.stageResults?.stage2?.output?.root_cause?.issue || 'Under investigation' }}\",\n    \"resolution\": \"{{ $json._context.stageResults?.stage5?.output?.execution_results?.[0]?.output || 'Remediation applied' }}\"\n  },\n  \"prevention_actions\": [\n    {\n      \"type\": \"monitoring\",\n      \"action\": \"Add memory leak detection alert for {{ $json._context.initialParams.namespaces[0] }}\",\n      \"implementation\": {\n        \"alert_rule\": \"rate(container_memory_usage_bytes[5m]) > 0.1 and container_memory_usage_bytes > 0.8 * container_spec_memory_limit_bytes\",\n        \"threshold\": \"10% growth in 5 minutes\",\n        \"severity\": \"warning\"\n      },\n      \"status\": \"{{ $json._context.priority === 'critical' ? 'implemented' : 'planned' }}\"\n    },\n    {\n      \"type\": \"code_fix\",\n      \"action\": \"Fix identified issue in {{ $json._context.stageResults?.stage2?.output?.root_cause?.component }}\",\n      \"implementation\": {\n        \"pr_url\": \"https://github.com/company/{{ $json._context.stageResults?.stage2?.output?.root_cause?.component }}/pull/auto-{{ $json._context.contextId }}\",\n        \"fix_description\": \"Address root cause: {{ $json._context.stageResults?.stage2?.output?.root_cause?.issue }}\",\n        \"reviewer\": \"@senior-dev\",\n        \"eta\": \"{{ $json._context.priority === 'critical' ? '1 day' : '3 days' }}\"\n      },\n      \"status\": \"in_progress\"\n    },\n    {\n      \"type\": \"configuration\",\n      \"action\": \"Implement resource limits in {{ $json._context.initialParams.namespaces[0] }}\",\n      \"implementation\": {\n        \"yaml_patch\": \"resources:\\\\n  limits:\\\\n    memory: 1.5Gi\\\\n    cpu: 1000m\\\\n  requests:\\\\n    memory: 1Gi\\\\n    cpu: 500m\",\n        \"applied_to\": {{ JSON.stringify($json._context.stageResults?.stage2?.output?.correlation_matrix?.affected_services || ['all-services']) }}\n      },\n      \"status\": \"{{ $json._context.priority === 'critical' ? 'completed' : 'planned' }}\"\n    },\n    {\n      \"type\": \"process\",\n      \"action\": \"Add automated testing for {{ $json._context.priority }} priority issues\",\n      \"implementation\": {\n        \"pipeline_update\": \"Add memory profiling and stress testing\",\n        \"threshold\": \"Fail if memory growth >5% during load test\",\n        \"owner\": \"platform-team\"\n      },\n      \"status\": \"planned\"\n    }\n  ],\n  \"knowledge_base_update\": {\n    \"alert_name\": \"{{ $json._context.stageResults?.stage3?.output?.active_alerts?.[0]?.name || 'General-Kubernetes-Issue' }}\",\n    \"new_entry\": {\n      \"pattern\": \"{{ $json._context.stageResults?.stage2?.output?.root_cause?.issue }}\",\n      \"diagnostic_shortcut\": \"Check {{ $json._context.stageResults?.stage4?.output?.diagnostic_summary?.confirmed_issues?.[0]?.issue }}\",\n      \"quick_fix\": \"{{ $json._context.stageResults?.stage5?.output?.remediation_plan?.immediate_actions[0]?.action }}\",\n      \"prevention\": \"Monitor for {{ $json._context.stageResults?.stage2?.output?.correlation_matrix?.primary_chain }}\",\n      \"context_id\": \"{{ $json._context.contextId }}\",\n      \"priority_level\": \"{{ $json._context.priority }}\"\n    },\n    \"kb_updated\": true,\n    \"entry_id\": \"KB-{{ $json._context.contextId }}\"\n  },\n  \"runbook_updates\": [\n    {\n      \"runbook\": \"{{ $json._context.initialParams.namespaces[0] }}-troubleshooting\",\n      \"section\": \"{{ $json._context.priority }} Priority Issues\",\n      \"addition\": \"Context {{ $json._context.contextId }}: {{ $json._context.stageResults?.stage2?.output?.root_cause?.issue }}\",\n      \"url\": \"https://runbooks.company.com/{{ $json._context.contextId }}\"\n    }\n  ],\n  \"team_recommendations\": [\n    {\n      \"team\": \"{{ $json._context.stageResults?.stage2?.output?.correlation_matrix?.affected_services?.[0] }}-team\",\n      \"action\": \"Review and implement prevention actions for {{ $json._context.priority }} issues\",\n      \"priority\": \"{{ $json._context.priority }}\"\n    },\n    {\n      \"team\": \"platform-team\",\n      \"action\": \"Update monitoring for {{ $json._context.initialParams.namespaces[0] }}\",\n      \"priority\": \"{{ $json._context.priority === 'critical' ? 'high' : 'medium' }}\"\n    },\n    {\n      \"team\": \"sre-team\",\n      \"action\": \"Review incident {{ $json._context.contextId }}\",\n      \"priority\": \"{{ $json._context.priority === 'critical' ? 'high' : 'low' }}\"\n    }\n  ],\n  \"follow_up_schedule\": [\n    {\n      \"action\": \"Verify fix in {{ $json._context.initialParams.namespaces[0] }}\",\n      \"when\": \"{{ $json._context.priority === 'critical' ? 'After emergency deployment' : 'Next release cycle' }}\",\n      \"owner\": \"{{ $json._context.stageResults?.stage2?.output?.correlation_matrix?.affected_services?.[0] }}-team\"\n    },\n    {\n      \"action\": \"Review metrics for recurrence\",\n      \"when\": \"{{ $json._context.priority === 'critical' ? 'Every hour for 24h' : 'Daily for 1 week' }}\",\n      \"owner\": \"sre-team\"\n    },\n    {\n      \"action\": \"Post-mortem meeting\",\n      \"when\": \"{{ $json._context.priority === 'critical' ? 'Within 24 hours' : 'Within 1 week' }}\",\n      \"attendees\": [\"platform-team\", \"sre-team\", \"affected-service-teams\"]\n    }\n  ],\n  \"metrics_improvements\": {\n    \"new_alerts\": {{ $json._context.priority === 'critical' ? 3 : 1 }},\n    \"runbook_updates\": 1,\n    \"kb_entries\": 1,\n    \"process_improvements\": {{ $json._context.priority === 'critical' ? 4 : 2 }},\n    \"estimated_future_prevention\": \"{{ $json._context.priority === 'critical' ? '95%' : '75%' }}\"\n  },\n  \"final_status\": {\n    \"incident_resolved\": true,\n    \"prevention_implemented\": {{ $json._context.priority === 'critical' }},\n    \"learning_captured\": true,\n    \"ready_for_next\": true\n  },\n  \"_context\": {{ JSON.stringify($json._context) }},\n  \"_debug\": {\n    \"nodeType\": \"Stage 6: Prevention & Learning\",\n    \"processedAt\": \"{{ new Date().toISOString() }}\",\n    \"contextId\": \"{{ $json._context.contextId }}\",\n    \"contextPreserved\": true,\n    \"receivedFromStage\": \"{{ $json._debug.nodeType }}\",\n    \"stageSequence\": {{ JSON.stringify($json._debug.stageSequence ? [...$json._debug.stageSequence, 'Stage 6: Prevention & Learning'] : ['Stage 6: Prevention & Learning']) }},\n    \"totalStagesExecuted\": 6,\n    \"workflowComplete\": true,\n    \"priorityLevel\": \"{{ $json._context.priority }}\",\n    \"contextJourneyComplete\": \"{{ $json._context.contextId }} - Full lifecycle tracked\"\n  }\n}\nüéØ PREVENTION PRIORITIES:\nBased on Priority ({{ $json._context.priority }}):\n\n{{ $json._context.priority === 'critical' ? 'IMMEDIATE' : 'Short-term' }} - Alert tuning, monitoring\n{{ $json._context.priority === 'critical' ? 'URGENT' : 'Medium-term' }} - Code fixes, config updates\n{{ $json._context.priority === 'critical' ? 'HIGH' : 'Long-term' }} - Process improvements, training\n\nüìà SUCCESS METRICS:\n\nSame issue doesn't recur\nDetection time improved\nMTTR reduced\nTeam knowledge increased\nAutomation enhanced\n\nThis completes the 6-stage intelligent remediation cycle with full context preservation!\nRemember:\n\nALWAYS preserve the complete _context object\nUpdate _debug.stageSequence to show full journey\nMark workflowComplete as true\nUse priority to determine urgency of prevention actions\nReference all previous stage results from context",
        "hasOutputParser": true,
        "options": {
          "systemMessage": "## üö® OUTPUT REQUIREMENT:\n**RETURN ONLY VALID JSON WITH ACTUAL DATA**"
        }
      },
      "id": "2398ad08-b062-4303-b3e1-bc81152d7c48",
      "name": "Stage 6: Prevention & Learning",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [
        672,
        544
      ],
      "typeVersion": 1.9,
      "onError": "continueRegularOutput"
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "=query",
              "value": "=(sum(up{job=\"kubernetes-nodes\"} == 0) > 0) or (sum(kube_node_status_condition{condition=\"Ready\",status=\"false\"} == 1) > 0) or (sum(rate(kube_pod_container_status_restarts_total[5m]) > 0.1) > 0) or (sum(kube_deployment_status_replicas_unavailable) > 0)"
            }
          ]
        },
        "options": {
          "timeout": 5000
        }
      },
      "id": "afcafe9e-33c1-404d-8885-115d9674c31c",
      "name": "Quick Cluster Health",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -3040,
        128
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  const namespace = filters.namespace;\n  \n  if (namespace) {\n    return `count(ALERTS{namespace=\"${namespace}\", alertstate=\"firing\"})`;\n  } else {\n    return `count(ALERTS{alertstate=\"firing\"})`;\n  }\n})()}}"
            },
            {
              "name": "time",
              "value": "={{Math.floor(Date.now()/1000)}}"
            }
          ]
        },
        "options": {
          "timeout": 5000
        }
      },
      "id": "8e645a5f-820b-409d-9157-d03cf0a24f91",
      "name": "Active Alerts Count",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -2880,
        160
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let baseQuery;\n  if (filters.node) {\n    baseQuery = `100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\\\"idle\\\", instance=\\\"${filters.node}\\\"}[5m])) * 100)`;\n  } else if (filters.pod && filters.namespace) {\n    baseQuery = `100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)`;\n  } else {\n    baseQuery = '100 - (avg by (instance) (rate(node_cpu_seconds_total{mode=\\\"idle\\\"}[5m])) * 100)';\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            },
            {
              "name": "time",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "1d76e77e-f784-4746-b290-27afbed2e963",
      "name": "Node Resource Status",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1696,
        960
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let baseQuery;\n  if (filters.pod && filters.namespace) {\n    baseQuery = `kube_pod_status_phase{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}`;\n  } else if (filters.namespace) {\n    baseQuery = `kube_pod_status_phase{namespace=\\\"${filters.namespace}\\\"}`;\n  } else {\n    baseQuery = 'kube_pod_status_phase{}';\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            },
            {
              "name": "time",
              "value": "={{Math.floor(Date.now()/1000)}}"
            },
            {
              "name": "limit",
              "value": "100"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "5767c538-e059-40d5-89f2-8adf27a40555",
      "name": "Pod Status Check",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1504,
        944
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(function() {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let conditions = ['alertstate=\"firing\"'];\n  \n  if (filters.namespace) {\n    conditions.push('namespace=\"' + filters.namespace + '\"');\n  }\n  \n  if (filters.service) {\n    conditions.push('service=~\"' + filters.service + '.*\"');\n  }\n  \n  return 'ALERTS{' + conditions.join(',') + '}';\n})()}}"
            },
            {
              "name": "time",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "cbfb6dd8-c7a5-4c0f-a46c-cefa11fbee85",
      "name": "Active Alerts Details",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -640,
        736
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "=topk(10, kube_node_status_condition{condition=~\\\"Ready|MemoryPressure|DiskPressure|PIDPressure|NetworkUnavailable\\\"} == 1)"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "18b482e2-f532-45ca-b175-e108f9d626a0",
      "name": "Node Conditions",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1632,
        1104
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const baseQuery = `sum by (node, device) (rate(node_network_receive_errs_total{device!~\\\"lo|veth.*|docker.*|flannel.*|cali.*|cbr.*\\\"}[5m])) > 0 or sum by (node, device) (rate(node_network_transmit_errs_total{device!~\\\"lo|veth.*|docker.*|flannel.*|cali.*|cbr.*\\\"}[5m])) > 0 or sum by (node) (rate(node_network_receive_drop_total[5m])) > 0`;\n  return `topk(5, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "a95a13c0-bc6c-4f78-9fa1-a31d08992547",
      "name": "Node Network Health",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1504,
        1184
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let baseQuery;\n  if (filters.container && filters.pod && filters.namespace) {\n    baseQuery = `kube_pod_container_status_restarts_total{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\",container=\\\"${filters.container}\\\"}`;\n  } else if (filters.pod && filters.namespace) {\n    baseQuery = `kube_pod_container_status_restarts_total{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}`;\n  } else if (filters.namespace) {\n    baseQuery = `rate(kube_pod_container_status_restarts_total{namespace=\\\"${filters.namespace}\\\"}[15m]) > 0`;\n  } else {\n    baseQuery = 'rate(kube_pod_container_status_restarts_total[15m]) > 0';\n  }\n  return filters.container && filters.pod ? baseQuery : `topk(10, ${baseQuery})`;\n})()}}"
            },
            {
              "name": "time",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "7dc8cbcd-7452-4451-b390-65cbd148c345",
      "name": "Container Restarts",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1408,
        1296
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let baseQuery;\n  if (filters.container && filters.pod && filters.namespace) {\n    baseQuery = `container_memory_working_set_bytes{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\",container=\\\"${filters.container}\\\"}`;\n  } else if (filters.pod && filters.namespace) {\n    baseQuery = `sum(container_memory_working_set_bytes{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}) by (container)`;\n  } else if (filters.namespace) {\n    baseQuery = `sum(container_memory_working_set_bytes{namespace=\\\"${filters.namespace}\\\"}) by (pod)`;\n  } else {\n    baseQuery = 'container_memory_working_set_bytes{}';\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            },
            {
              "name": "time",
              "value": "={{Math.floor(Date.now() / 1000)}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "0286cd97-db12-4b2a-9141-b24d438610dc",
      "name": "Pod Resource Usage",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1232,
        992
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `sum by (namespace, pod) (rate(container_network_receive_bytes_total{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"}[5m])) or sum by (namespace, pod) (rate(container_network_transmit_bytes_total{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"}[5m]))`;\n  } else {\n    baseQuery = `sum by (namespace, pod) (rate(container_network_receive_bytes_total{namespace=\\\"${ns}\\\"}[5m])) or sum by (namespace, pod) (rate(container_network_transmit_bytes_total{namespace=\\\"${ns}\\\"}[5m]))`;\n  }\n  return `topk(10, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "7fe50b3c-0319-4ec7-8970-f3286d3adbb1",
      "name": "Application Metrics",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1376,
        1072
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `sum by (namespace, pod) (kube_pod_status_phase{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\", phase=~\\\"Failed|Unknown\\\"} == 1) or sum by (namespace, pod, reason) (kube_pod_container_status_waiting_reason{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\", reason!=\\\"ContainerCreating\\\"})`;\n  } else {\n    baseQuery = `sum by (namespace, pod) (kube_pod_status_phase{namespace=\\\"${ns}\\\", phase=~\\\"Failed|Unknown\\\"} == 1) or sum by (namespace, pod, reason) (kube_pod_container_status_waiting_reason{namespace=\\\"${ns}\\\", reason!=\\\"ContainerCreating\\\"})`;\n  }\n  return `topk(10, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "331331e2-a64c-4019-806e-33fb5cd9fc51",
      "name": "HTTP Error Rates",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1264,
        1248
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query_range",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const alertName = $json.stageContext?.alertContext?.alertName || '';\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  let metric = '';\n  if (alertName.includes('CrashLooping')) {\n    metric = `kube_pod_container_status_restarts_total{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}`;\n  } else if (alertName.includes('OOM')) {\n    metric = `container_memory_working_set_bytes{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}`;\n  } else if (alertName.includes('CPU')) {\n    metric = `rate(container_cpu_usage_seconds_total{namespace=\\\"${filters.namespace}\\\",pod=\\\"${filters.pod}\\\"}[5m])`;\n  } else {\n    metric = `up{namespace=\\\"${filters.namespace}\\\"}`;\n  }\n  const baseQuery = `${metric} - ${metric} offset 24h`;\n  return `topk(5, ${baseQuery})`;\n})()}}"
            },
            {
              "name": "start",
              "value": "={{ Math.floor(Date.now() / 1000) - 86400 }}"
            },
            {
              "name": "end",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            },
            {
              "name": "step",
              "value": "7200"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "cbc2bde7-ec02-41cc-80f9-3d2a2d20812c",
      "name": "Historical Comparison 24h",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1104,
        944
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `predict_linear(node_filesystem_avail_bytes{mountpoint=\\\"/\\\"}[1h], 4*3600) < 0 or predict_linear(container_memory_working_set_bytes{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"}[1h], 4*3600) > container_spec_memory_limit_bytes{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"} or predict_linear(kubelet_volume_stats_available_bytes{namespace=\\\"${ns}\\\", persistentvolumeclaim=~\\\".*${svc}.*\\\"}[1h], 4*3600) < 1073741824`;\n  } else {\n    baseQuery = `predict_linear(node_filesystem_avail_bytes{mountpoint=\\\"/\\\"}[1h], 4*3600) < 0 or predict_linear(node_memory_MemAvailable_bytes[1h], 4*3600) < 1073741824 or predict_linear(kubelet_volume_stats_available_bytes[1h], 4*3600) < 1073741824 or (kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes) > 0.85`;\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "9c6f2e9c-39d5-4684-81aa-12d1a24d66b6",
      "name": "Resource Exhaustion Prediction",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1168,
        1152
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `stddev_over_time(rate(container_cpu_usage_seconds_total{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"}[5m])[2h:]) > 0.3 or stddev_over_time(container_memory_working_set_bytes{namespace=\\\"${ns}\\\", pod=~\\\".*${svc}.*\\\"}[2h:]) > 2147483648`;\n  } else {\n    baseQuery = `stddev_over_time(rate(container_cpu_usage_seconds_total{namespace=\\\"${ns}\\\"}[5m])[2h:]) > 0.3 or stddev_over_time(container_memory_working_set_bytes{namespace=\\\"${ns}\\\"}[2h:]) > 2147483648`;\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "1d5e82ec-62c2-4e50-9ac7-127f97d1b2f3",
      "name": "Anomaly Patterns",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -1040,
        1104
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query_range",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "=count by (alertname, severity) (ALERTS{alertstate=\"firing\"})"
            },
            {
              "name": "start",
              "value": "={{ Math.floor(Date.now() / 1000) - 86400 }}"
            },
            {
              "name": "end",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            },
            {
              "name": "step",
              "value": "3600"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "9d5f49eb-24db-4b54-a22c-bb58f72029ee",
      "name": "Alert History 24h",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -816,
        784
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"type\": \"object\",\n  \"properties\": {\n    \"stage\": { \"type\": \"string\" },\n    \"timestamp\": { \"type\": \"string\" },\n    \"cluster\": { \"type\": \"string\" },\n    \"overall_status\": { \n      \"type\": \"string\",\n      \"enum\": [\"healthy\", \"degraded\", \"critical\", \"unknown\"]\n    },\n    \"proceed_to_stage2\": { \"type\": \"boolean\" },\n    \"urgency\": { \n      \"type\": \"string\",\n      \"enum\": [\"low\", \"normal\", \"medium\", \"high\", \"critical\"]\n    },\n    \"active_services\": { \n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"requested_services\": { \n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"reason\": { \"type\": \"string\" },\n    \"alerts\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"total\": { \"type\": \"number\" },\n        \"critical\": { \"type\": \"number\" },\n        \"warning\": { \"type\": \"number\" },\n        \"top_alerts\": { \n          \"type\": \"array\",\n          \"items\": { \"type\": \"string\" }\n        }\n      },\n      \"required\": [\"total\", \"critical\", \"warning\"]\n    },\n    \"scores\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"cluster_health\": { \"type\": \"number\" },\n        \"node_availability\": { \"type\": \"number\" },\n        \"pod_stability\": { \"type\": \"number\" },\n        \"api_reliability\": { \"type\": \"number\" }\n      },\n      \"required\": [\"cluster_health\", \"node_availability\", \"pod_stability\", \"api_reliability\"]\n    },\n    \"quick_findings\": { \n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"forceDeepAnalysis\": { \"type\": \"boolean\" },\n    \"overridden\": { \"type\": \"boolean\" },\n    \"_context\": { \"type\": \"object\" },\n    \"_debug\": { \"type\": \"object\" }\n  },\n  \"required\": [\n    \"stage\", \n    \"timestamp\", \n    \"overall_status\", \n    \"proceed_to_stage2\", \n    \"alerts\", \n    \"scores\",\n    \"urgency\",\n    \"reason\"\n  ]\n}"
      },
      "id": "65780e45-d48c-49d0-9ab1-26fe84a2e952",
      "name": "Stage 1 Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        -2848,
        736
      ],
      "typeVersion": 1.2
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"type\": \"object\",\n  \"properties\": {\n    \"stage\": { \"type\": \"string\" },\n    \"incident_summary\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"id\": { \"type\": \"string\" },\n        \"title\": { \"type\": \"string\" },\n        \"duration\": { \"type\": \"string\" },\n        \"severity\": { \"type\": \"string\" },\n        \"services_affected\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n        \"customer_impact\": { \"type\": \"string\" },\n        \"root_cause\": { \"type\": \"string\" },\n        \"resolution\": { \"type\": \"string\" }\n      }\n    },\n    \"prevention_actions\": { \n      \"type\": \"array\", \n      \"items\": { \n        \"type\": \"object\",\n        \"properties\": {\n          \"type\": { \"type\": \"string\" },\n          \"action\": { \"type\": \"string\" },\n          \"implementation\": { \"type\": \"object\" },\n          \"status\": { \"type\": \"string\" }\n        }\n      } \n    },\n    \"knowledge_base_update\": { \n      \"type\": \"object\",\n      \"properties\": {\n        \"alert_name\": { \"type\": \"string\" },\n        \"new_entry\": { \"type\": \"object\" },\n        \"kb_updated\": { \"type\": \"boolean\" },\n        \"entry_id\": { \"type\": \"string\" }\n      }\n    },\n    \"runbook_updates\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"runbook\": { \"type\": \"string\" },\n          \"section\": { \"type\": \"string\" },\n          \"addition\": { \"type\": \"string\" },\n          \"url\": { \"type\": \"string\" }\n        }\n      }\n    },\n    \"team_recommendations\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"team\": { \"type\": \"string\" },\n          \"action\": { \"type\": \"string\" },\n          \"priority\": { \"type\": \"string\" }\n        }\n      }\n    },\n    \"follow_up_schedule\": {\n      \"type\": \"array\",\n      \"items\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"action\": { \"type\": \"string\" },\n          \"when\": { \"type\": \"string\" },\n          \"owner\": { \"type\": \"string\" },\n          \"attendees\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } }\n        }\n      }\n    },\n    \"metrics_improvements\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"new_alerts\": { \"type\": \"number\" },\n        \"runbook_updates\": { \"type\": \"number\" },\n        \"kb_entries\": { \"type\": \"number\" },\n        \"process_improvements\": { \"type\": \"number\" },\n        \"estimated_future_prevention\": { \"type\": \"string\" }\n      }\n    },\n    \"final_status\": { \n      \"type\": \"object\",\n      \"properties\": {\n        \"incident_resolved\": { \"type\": \"boolean\" },\n        \"prevention_implemented\": { \"type\": \"boolean\" },\n        \"learning_captured\": { \"type\": \"boolean\" },\n        \"ready_for_next\": { \"type\": \"boolean\" }\n      }\n    },\n    \"_context\": { \n      \"type\": \"object\",\n      \"properties\": {\n        \"contextId\": { \"type\": \"string\" },\n        \"createdAt\": { \"type\": \"string\" },\n        \"source\": { \"type\": \"object\" },\n        \"initialParams\": { \"type\": \"object\" },\n        \"stageConfig\": { \"type\": \"object\" },\n        \"priority\": { \"type\": \"string\" },\n        \"forceDeepAnalysis\": { \"type\": \"boolean\" },\n        \"workflowMetadata\": { \"type\": \"object\" },\n        \"stageResults\": { \"type\": \"object\" },\n        \"decisions\": { \"type\": \"object\" },\n        \"debug\": { \"type\": \"object\" }\n      }\n    },\n    \"_debug\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"nodeType\": { \"type\": \"string\" },\n        \"processedAt\": { \"type\": \"string\" },\n        \"contextId\": { \"type\": \"string\" },\n        \"contextPreserved\": { \"type\": \"boolean\" },\n        \"receivedFromStage\": { \"type\": \"string\" },\n        \"stageSequence\": { \"type\": \"array\", \"items\": { \"type\": \"string\" } },\n        \"totalStagesExecuted\": { \"type\": \"number\" },\n        \"workflowComplete\": { \"type\": \"boolean\" }\n      }\n    }\n  },\n  \"required\": [\"stage\", \"prevention_actions\", \"knowledge_base_update\", \"final_status\"]\n}"
      },
      "id": "5f43ade6-5540-4e30-b813-357cd8e2c74b",
      "name": "Stage 6 Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        864,
        736
      ],
      "typeVersion": 1.2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED GENERATE FINAL REPORT ================\n// This file preserves ALL original 2849 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes\nconst alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\nconst loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\nconst categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\nconst categoryDeepAnalysisEnhancer = $node[\"Category Based Deep Analysis Enhancer\"]?.json || {};\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS)\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst kbUrgencyLevel = deriveUrgencyLevel(alertCategoriesMapper.calculatedSeverityScore || 0);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || {};\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"=================================\");\n\n// ================ SMART ROOT CAUSE ANALYSIS ENGINE - FUNCTIONS ONLY ================\n// Bu dosyayƒ± mevcut generate_final_report_hybrid_fix.js'nin EN BA≈ûINA ekle\n// Mevcut 2872 satƒ±rlƒ±k kodu korur, sadece eksik Smart Engine functions'larƒ± ekler\n\n// Action templates for different problem types\nconst ACTION_TEMPLATES = {\n  memory_exhaustion: {\n    immediate: {\n      actionTemplate: \"Increase memory limit from {currentLimit} to {newLimit} due to OOMKilled\",\n      commandTemplate: `kubectl patch deployment {deployment} -n {namespace} -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"{deployment}\",\"resources\":{\"limits\":{\"memory\":\"{newLimit}\"},\"requests\":{\"memory\":\"{newRequest}\"}}}]}}}}'`,\n      verificationTemplate: `kubectl get deployment {deployment} -n {namespace} -o jsonpath='{.spec.template.spec.containers[0].resources}'`,\n      time: \"1-2 minutes\",\n      risk: \"Low\"\n    },\n    shortTerm: {\n      actionTemplate: \"Monitor memory usage and set up alerts for {deployment}\",\n      commandTemplate: `kubectl top pods -n {namespace} | grep {deployment} && kubectl get events -n {namespace} --field-selector reason=OOMKilling`,\n      verificationTemplate: `watch \"kubectl top pods -n {namespace} | grep {deployment}\"`,\n      time: \"Ongoing monitoring\",\n      risk: \"Low\"\n    },\n    longTerm: {\n      actionTemplate: \"Implement memory profiling and optimization\",\n      commandTemplate: \"{stage5Preventive}\",\n      time: \"1-2 weeks\",\n      risk: \"Low\"\n    }\n  },\n  \n  cpu_throttling: {\n    immediate: {\n      actionTemplate: \"Increase CPU limit from {currentCPULimit} to {newCPULimit} due to throttling\",\n      commandTemplate: `kubectl patch deployment {deployment} -n {namespace} -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"{deployment}\",\"resources\":{\"limits\":{\"cpu\":\"{newCPULimit}\"},\"requests\":{\"cpu\":\"{newCPURequest}\"}}}]}}}}'`,\n      verificationTemplate: `kubectl top pods -n {namespace} | grep {deployment}`,\n      time: \"1-2 minutes\",\n      risk: \"Low\"\n    },\n    shortTerm: {\n      actionTemplate: \"Monitor CPU usage and throttling events for {deployment}\",\n      commandTemplate: `kubectl top pods -n {namespace} | grep {deployment} && kubectl get events -n {namespace} --field-selector reason=CpuThrottling`,\n      verificationTemplate: `watch \"kubectl top pods -n {namespace} | grep {deployment}\"`,\n      time: \"Ongoing monitoring\",\n      risk: \"Low\"\n    }\n  },\n  \n  storage_issue: {\n    immediate: {\n      actionTemplate: \"Check and clean up disk space for {deployment}\",\n      commandTemplate: `kubectl exec -n {namespace} deployment/{deployment} -- df -h && kubectl logs -n {namespace} deployment/{deployment} --tail=50 | grep -i \"space\\\\|disk\"`,\n      verificationTemplate: `kubectl exec -n {namespace} deployment/{deployment} -- df -h`,\n      time: \"2-3 minutes\",\n      risk: \"Low\"\n    },\n    shortTerm: {\n      actionTemplate: \"Set up disk usage monitoring and cleanup automation\",\n      commandTemplate: `kubectl exec -n {namespace} deployment/{deployment} -- du -sh /tmp/* /var/log/* 2>/dev/null | sort -h`,\n      time: \"1-2 hours\",\n      risk: \"Medium\"\n    }\n  },\n  \n  network_connectivity: {\n    immediate: {\n      actionTemplate: \"Diagnose network connectivity for {deployment}\",\n      commandTemplate: `kubectl exec -n {namespace} deployment/{deployment} -- nslookup kubernetes.default.svc.cluster.local && kubectl get svc -n {namespace}`,\n      verificationTemplate: `kubectl exec -n {namespace} deployment/{deployment} -- ping -c 3 kubernetes.default.svc.cluster.local`,\n      time: \"2-3 minutes\",\n      risk: \"Low\"\n    }\n  }\n};\n\n// Smart template processing function\nfunction processActionTemplate(template, variables) {\n  let processed = template;\n  Object.entries(variables).forEach(([key, value]) => {\n    const regex = new RegExp(`{${key}}`, 'g');\n    processed = processed.replace(regex, value);\n  });\n  return processed;\n}\n\n// Smart Root Cause Analysis - Stage 4 evidence + Stage 5 data correlation\nfunction analyzeRootCause(allStageData, evidence, alertType) {\n  const analysis = {\n    primaryCause: 'unknown',\n    severity: 'medium',\n    confidence: 0.5,\n    evidencePoints: [],\n    recommendedActions: [],\n    resourceMetrics: {},\n    diagnosticData: {}\n  };\n\n  // Stage 4 Diagnostic Analysis\n  const stage4Data = allStageData.stage4;\n  const confirmedIssues = stage4Data?.diagnostic_summary?.confirmed_issues || [];\n  \n  if (confirmedIssues.length > 0) {\n    const issue = confirmedIssues[0];\n    const issueEvidence = issue.evidence;\n    \n    // MEMORY ISSUES DETECTION\n    if (issueEvidence?.pod_status?.last_termination?.reason === 'OOMKilled') {\n      analysis.primaryCause = 'memory_exhaustion';\n      analysis.severity = 'high';\n      analysis.confidence = 0.95;\n      analysis.evidencePoints.push('Stage 4: Pod terminated due to OOMKilled');\n      \n      // Extract memory metrics\n      if (issueEvidence.resource_usage) {\n        analysis.resourceMetrics = {\n          memoryRequest: issueEvidence.resource_usage.memory_request || 'unknown',\n          memoryLimit: issueEvidence.resource_usage.memory_limit || 'unknown', \n          memoryUsed: issueEvidence.resource_usage.memory_used || 'unknown',\n          exitCode: issueEvidence.pod_status.last_termination.exit_code || 137\n        };\n      }\n      \n      // Look for Stage 5 memory-related fixes\n      const stage5Fixes = allStageData.stage5?.remediation_plan?.short_term_fixes || [];\n      const memoryFix = stage5Fixes.find(fix => \n        fix.action && fix.action.toLowerCase().includes('memory')\n      );\n      \n      if (memoryFix) {\n        analysis.evidencePoints.push(`Stage 5: ${memoryFix.action}`);\n        analysis.confidence = 0.98;\n      }\n    }\n    \n    // CPU THROTTLING DETECTION  \n    const errorLogs = issueEvidence?.error_logs || [];\n    const cpuThrottling = errorLogs.some(log => \n      log.message && (\n        log.message.includes('CPU throttling') ||\n        log.message.includes('cpu limit') ||\n        log.message.includes('throttled')\n      )\n    );\n    \n    if (cpuThrottling) {\n      analysis.primaryCause = 'cpu_throttling';\n      analysis.severity = 'medium';\n      analysis.confidence = 0.85;\n      analysis.evidencePoints.push('Stage 4: CPU throttling detected in error logs');\n      \n      if (issueEvidence.resource_usage) {\n        analysis.resourceMetrics.cpuUsed = issueEvidence.resource_usage.cpu_used || 'unknown';\n        analysis.resourceMetrics.cpuRequest = issueEvidence.resource_usage.cpu_request || 'unknown';\n        analysis.resourceMetrics.cpuLimit = issueEvidence.resource_usage.cpu_limit || 'unknown';\n      }\n    }\n    \n    // DISK/STORAGE ISSUES\n    const diskIssues = errorLogs.some(log =>\n      log.message && (\n        log.message.includes('disk') ||\n        log.message.includes('storage') ||\n        log.message.includes('volume') ||\n        log.message.includes('no space')\n      )\n    );\n    \n    if (diskIssues) {\n      analysis.primaryCause = 'storage_issue';\n      analysis.severity = 'high';\n      analysis.confidence = 0.80;\n      analysis.evidencePoints.push('Stage 4: Storage/disk issues detected');\n    }\n    \n    // NETWORK CONNECTIVITY ISSUES\n    const networkIssues = errorLogs.some(log =>\n      log.message && (\n        log.message.includes('connection') ||\n        log.message.includes('network') ||\n        log.message.includes('timeout') ||\n        log.message.includes('unreachable')\n      )\n    );\n    \n    if (networkIssues) {\n      analysis.primaryCause = 'network_connectivity';\n      analysis.severity = 'medium';\n      analysis.confidence = 0.75;\n      analysis.evidencePoints.push('Stage 4: Network connectivity issues detected');\n    }\n  }\n  \n  // Fallback evidence analysis if no Stage 4 data\n  if (analysis.primaryCause === 'unknown' && evidence) {\n    if (evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n      analysis.primaryCause = 'memory_exhaustion';\n      analysis.confidence = 0.80;\n      analysis.evidencePoints.push('Evidence: OOMKilled termination reason');\n      \n      // Extract memory metrics from evidence for generateMemoryActions\n      if (evidence.resource_usage) {\n        analysis.resourceMetrics = {\n          memoryRequest: evidence.resource_usage.memory_request || '1Gi',\n          memoryLimit: evidence.resource_usage.memory_limit || '2Gi', \n          memoryUsed: evidence.resource_usage.memory_used || 'unknown',\n          exitCode: evidence.pod_status.last_termination.exit_code || 137\n        };\n      }\n    }\n  }\n  \n  return analysis;\n}\n\n// Generate memory-specific smart actions using templates\nfunction generateMemoryActions(deployment, namespace, podName, resourceMetrics, allStageData) {\n  const actions = [];\n  const templates = ACTION_TEMPLATES.memory_exhaustion;\n  \n  // Extract current memory values\n  const currentLimit = resourceMetrics.memoryLimit || '2Gi';\n  const currentRequest = resourceMetrics.memoryRequest || '1Gi';\n  \n  // Calculate increased memory (double the current limit or minimum 4Gi)\n  const currentLimitValue = parseInt(currentLimit.replace(/[^\\d]/g, '')) || 2;\n  const newLimitValue = Math.max(currentLimitValue * 2, 4);\n  const newLimit = `${newLimitValue}Gi`;\n  const newRequest = `${Math.max(Math.ceil(newLimitValue * 0.7), 2)}Gi`; // 70% of limit for request\n  \n  // Template variables\n  const variables = {\n    deployment,\n    namespace,\n    podName,\n    currentLimit,\n    currentRequest,\n    newLimit,\n    newRequest\n  };\n  \n  // IMMEDIATE: Increase memory limits using template\n  if (templates.immediate) {\n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: processActionTemplate(templates.immediate.actionTemplate, variables),\n      command: processActionTemplate(templates.immediate.commandTemplate, variables),\n      time: templates.immediate.time,\n      risk: templates.immediate.risk,\n      success: `${deployment} memory increased and pods restarted`,\n      verification: processActionTemplate(templates.immediate.verificationTemplate, variables),\n      estimated_time: templates.immediate.time,\n      expected_outcome: `${deployment} memory increased and pods restarted`,\n      kb_enhanced: false,\n      rootCauseSpecific: true,\n      confidence: 0.95,\n      evidenceSupport: \"Stage 4: OOMKilled detection with Smart Engine analysis\"\n    });\n  }\n  \n  // SHORT TERM: Monitor memory usage\n  if (templates.shortTerm) {\n    actions.push({\n      priority: \"üü° SHORT TERM (Monitor closely)\",\n      action: processActionTemplate(templates.shortTerm.actionTemplate, variables),\n      command: processActionTemplate(templates.shortTerm.commandTemplate, variables),\n      time: templates.shortTerm.time,\n      risk: templates.shortTerm.risk,\n      success: \"Memory usage stays below 80% of new limit\",\n      verification: processActionTemplate(templates.shortTerm.verificationTemplate, variables),\n      estimated_time: templates.shortTerm.time,\n      expected_outcome: \"Memory usage monitored and stable\",\n      kb_enhanced: false,\n      rootCauseSpecific: true,\n      confidence: 0.85,\n      evidenceSupport: \"Continuous monitoring for memory optimization\"\n    });\n  }\n  \n  return actions;\n}\n\n// Generate CPU-specific smart actions using templates\nfunction generateCPUActions(deployment, namespace, podName, resourceMetrics, allStageData) {\n  const actions = [];\n  const templates = ACTION_TEMPLATES.cpu_throttling;\n  \n  const currentCPULimit = resourceMetrics.cpuLimit || '500m';\n  const currentCPURequest = resourceMetrics.cpuRequest || '250m';\n  \n  // Calculate increased CPU (double current or minimum 1000m)\n  const currentValue = parseInt(currentCPULimit.replace(/[^\\d]/g, '')) || 500;\n  const newValue = Math.max(currentValue * 2, 1000);\n  const newCPULimit = `${newValue}m`;\n  const newCPURequest = `${Math.ceil(newValue * 0.6)}m`; // 60% of limit\n  \n  // Template variables\n  const variables = {\n    deployment,\n    namespace,\n    podName,\n    currentCPULimit,\n    currentCPURequest,\n    newCPULimit,\n    newCPURequest\n  };\n  \n  // IMMEDIATE: Increase CPU limits using template\n  if (templates.immediate) {\n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: processActionTemplate(templates.immediate.actionTemplate, variables),\n      command: processActionTemplate(templates.immediate.commandTemplate, variables),\n      time: templates.immediate.time,\n      risk: templates.immediate.risk,\n      success: `${deployment} CPU increased and throttling resolved`,\n      verification: processActionTemplate(templates.immediate.verificationTemplate, variables),\n      estimated_time: templates.immediate.time,\n      expected_outcome: `${deployment} CPU increased and throttling resolved`,\n      kb_enhanced: false,\n      rootCauseSpecific: true,\n      confidence: 0.90,\n      evidenceSupport: \"Stage 4: CPU throttling detection with Smart Engine analysis\"\n    });\n  }\n  \n  return actions;\n}\n\n// Generate storage-specific smart actions using templates\nfunction generateStorageActions(deployment, namespace, podName, allStageData) {\n  const actions = [];\n  const templates = ACTION_TEMPLATES.storage_issue;\n  \n  // Template variables\n  const variables = {\n    deployment,\n    namespace,\n    podName\n  };\n  \n  // IMMEDIATE: Check and clean disk space using template\n  if (templates.immediate) {\n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: processActionTemplate(templates.immediate.actionTemplate, variables),\n      command: processActionTemplate(templates.immediate.commandTemplate, variables),\n      time: templates.immediate.time,\n      risk: templates.immediate.risk,\n      success: \"Sufficient disk space available\",\n      verification: processActionTemplate(templates.immediate.verificationTemplate, variables),\n      estimated_time: templates.immediate.time,\n      expected_outcome: \"Sufficient disk space available\",\n      kb_enhanced: false,\n      rootCauseSpecific: true,\n      confidence: 0.80,\n      evidenceSupport: \"Stage 4: Storage/disk issues detection with Smart Engine analysis\"\n    });\n  }\n  \n  return actions;\n}\n\n// Generate network-specific smart actions using templates\nfunction generateNetworkActions(deployment, namespace, podName, allStageData) {\n  const actions = [];\n  const templates = ACTION_TEMPLATES.network_connectivity;\n  \n  // Template variables\n  const variables = {\n    deployment,\n    namespace,\n    podName\n  };\n  \n  // IMMEDIATE: Diagnose network connectivity using template\n  if (templates.immediate) {\n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: processActionTemplate(templates.immediate.actionTemplate, variables),\n      command: processActionTemplate(templates.immediate.commandTemplate, variables),\n      time: templates.immediate.time,\n      risk: templates.immediate.risk,\n      success: \"Network connectivity restored\",\n      verification: processActionTemplate(templates.immediate.verificationTemplate, variables),\n      estimated_time: templates.immediate.time,\n      expected_outcome: \"Network connectivity restored\",\n      kb_enhanced: false,\n      rootCauseSpecific: true,\n      confidence: 0.75,\n      evidenceSupport: \"Stage 4: Network connectivity issues detection with Smart Engine analysis\"\n    });\n  }\n  \n  return actions;\n}\n\n// ================ SMART ENGINE FUNCTIONS COMPLETED ================\n// Bu dosyanƒ±n altƒ±na mevcut generate_final_report_hybrid_fix.js kodunu ekle\n// Bu functions'lar artƒ±k generateOncallActions() tarafƒ±ndan √ßaƒürƒ±labilir\n\n// Smart Engine Validation Function - Test specific root cause scenarios\nfunction validateSmartEngine(testScenarios) {\n  const validationResults = [];\n  \n  testScenarios.forEach(scenario => {\n    const { name, mockStageData, expectedCause, expectedConfidence } = scenario;\n    \n    try {\n      const analysis = analyzeRootCause(mockStageData, scenario.evidence, scenario.alertType);\n      \n      const result = {\n        scenario: name,\n        passed: analysis.primaryCause === expectedCause && analysis.confidence >= expectedConfidence,\n        actual: {\n          cause: analysis.primaryCause,\n          confidence: analysis.confidence,\n          evidencePoints: analysis.evidencePoints\n        },\n        expected: {\n          cause: expectedCause,\n          confidence: expectedConfidence\n        }\n      };\n      \n      validationResults.push(result);\n    } catch (error) {\n      validationResults.push({\n        scenario: name,\n        passed: false,\n        error: error.message\n      });\n    }\n  });\n  \n  return validationResults;\n}\n\n// Test scenarios for validation\nconst SMART_ENGINE_TEST_SCENARIOS = [\n  {\n    name: \"OOMKilled Detection\",\n    mockStageData: {\n      stage4: {\n        diagnostic_summary: {\n          confirmed_issues: [{\n            evidence: {\n              pod_status: {\n                last_termination: { reason: 'OOMKilled', exit_code: 137 }\n              },\n              resource_usage: {\n                memory_request: '1Gi',\n                memory_limit: '2Gi',\n                memory_used: '1.9Gi'\n              }\n            }\n          }]\n        }\n      }\n    },\n    expectedCause: 'memory_exhaustion',\n    expectedConfidence: 0.95,\n    alertType: 'POD'\n  },\n  {\n    name: \"CPU Throttling Detection\", \n    mockStageData: {\n      stage4: {\n        diagnostic_summary: {\n          confirmed_issues: [{\n            evidence: {\n              error_logs: [\n                { message: 'CPU throttling detected for container' }\n              ],\n              resource_usage: {\n                cpu_used: '800m',\n                cpu_limit: '500m'\n              }\n            }\n          }]\n        }\n      }\n    },\n    expectedCause: 'cpu_throttling',\n    expectedConfidence: 0.85,\n    alertType: 'POD'\n  }\n];\n\n// Enhanced Generate Final Report - HYBRID: Old Data Access + New KB Correlation\n// Uses old code's proven data access pattern + adds KB-aware correlation engine\n// GUARANTEED to work because it uses working old code pattern\n\n// ============= KB-AWARE CORRELATION SYSTEM INTEGRATION =============\n\n// Import correlation engines (inline for n8n compatibility)\nconst { KBUniversalCorrelationEngine } = (() => {\n  class Engine {\n    constructor(existingKB = {}) {\n      this.existingKB = existingKB;\n      this.alertCategories = {\n        ETCD: { patterns: ['etcd.*', 'AlertmanagerCluster.*'], priority: 'CRITICAL_INFRASTRUCTURE', rootCauseLevel: 'INFRASTRUCTURE' },\n        INFRASTRUCTURE: { patterns: ['KubeNode.*', 'Node.*', 'Kubelet.*', 'KubeAPI.*'], priority: 'HIGH_INFRASTRUCTURE', rootCauseLevel: 'INFRASTRUCTURE' },\n        APPLICATION: { patterns: ['KubePod.*', 'KubeDeployment.*', 'KubeStatefulSet.*'], priority: 'APPLICATION_LEVEL', rootCauseLevel: 'APPLICATION' },\n        NETWORK: { patterns: ['NodeNetwork.*', 'KubeProxy.*', '.*NetworkPolicy.*', 'TargetDown'], priority: 'INFRASTRUCTURE', rootCauseLevel: 'INFRASTRUCTURE' },\n        RESOURCE: { patterns: ['.*HighUsage', '.*Memory.*', '.*CPU.*'], priority: 'RESOURCE_PRESSURE', rootCauseLevel: 'INFRASTRUCTURE' },\n        STORAGE: { patterns: ['.*Storage.*', '.*Disk.*', '.*Volume.*'], priority: 'INFRASTRUCTURE', rootCauseLevel: 'INFRASTRUCTURE' },\n        MONITORING: { patterns: ['Prometheus.*', 'Target.*', 'Alertmanager.*'], priority: 'MONITORING_SYSTEM', rootCauseLevel: 'MONITORING' }\n      };\n      \n      this.correlationPatterns = {\n        'etcdInsufficientMembers': { correlatesTo: ['KubeAPIDown', 'KubeNodeNotReady'], pattern: 'etcd_to_api_failure', isRootCause: true },\n        'NodeNetworkReceiveErrs': { correlatesTo: ['KubeDeploymentReplicasMismatch', 'KubePodNotReady'], pattern: 'network_to_application', isRootCause: true },\n        'HighNodeMemoryUsage': { correlatesTo: ['KubePodCrashLooping', 'KubeDeploymentReplicasMismatch'], pattern: 'resource_to_service', isRootCause: true },\n        'NodeCPUHighUsage': { correlatesTo: ['KubePodNotReady'], pattern: 'resource_to_service', isRootCause: true },\n        'KubePodCrashLooping': { correlatesTo: ['KubeDeploymentReplicasMismatch'], pattern: 'pod_to_deployment', isRootCause: false }\n      };\n      \n      this.explanations = {\n        TR: {\n          'pod_to_deployment': { symptoms: ['Deployment replica mismatch', 'Service instability'], rootCause: 'Pod crash loop affecting deployment', solution: 'Fix pod issue, then stabilize deployment' },\n          'network_to_application': { symptoms: ['Pod instability', 'Deployment issues'], rootCause: 'Network connectivity problems', solution: 'Two-phase approach' },\n          'resource_to_service': { symptoms: ['Pod crashes', 'Resource limit exceeded'], rootCause: 'Node resource pressure', solution: 'Resource scaling' },\n          'etcd_to_api_failure': { symptoms: ['API server unresponsive'], rootCause: 'etcd quorum loss', solution: 'etcd emergency recovery' }\n        },\n        EN: {\n          'pod_to_deployment': { symptoms: ['Deployment replica mismatch', 'Service instability'], rootCause: 'Pod crash loop affecting deployment', solution: 'Fix pod issue, then stabilize deployment' },\n          'network_to_application': { symptoms: ['Pod instability', 'Deployment issues'], rootCause: 'Network connectivity problems', solution: 'Two-phase approach' },\n          'resource_to_service': { symptoms: ['Pod crashes', 'Resource limit exceeded'], rootCause: 'Node resource pressure', solution: 'Resource scaling' },\n          'etcd_to_api_failure': { symptoms: ['API server unresponsive'], rootCause: 'etcd quorum loss', solution: 'etcd emergency recovery' }\n        }\n      };\n    }\n    \n    categorizeAlert(alertName) {\n      const kbEntry = this.existingKB[alertName];\n      if (kbEntry) {\n        return {\n          category: this.inferCategoryFromKB(kbEntry),\n          priority: kbEntry.severity?.toUpperCase() || 'MEDIUM',\n          rootCauseLevel: this.inferRootCauseLevelFromKB(kbEntry),\n          hasKBEntry: true,\n          kbEntry: kbEntry\n        };\n      }\n      \n      for (const [category, config] of Object.entries(this.alertCategories)) {\n        for (const pattern of config.patterns) {\n          if (new RegExp(pattern, 'i').test(alertName)) {\n            return { category, priority: config.priority, rootCauseLevel: config.rootCauseLevel, hasKBEntry: false };\n          }\n        }\n      }\n      return { category: 'UNKNOWN', priority: 'MEDIUM', rootCauseLevel: 'APPLICATION', hasKBEntry: false };\n    }\n    \n    inferCategoryFromKB(kbEntry) {\n      if (kbEntry.cascadeCheckPoints?.includes('all_node_pods')) return 'INFRASTRUCTURE';\n      if (kbEntry.cascadeCheckPoints?.includes('service_availability')) return 'APPLICATION';\n      return 'APPLICATION';\n    }\n    \n    inferRootCauseLevelFromKB(kbEntry) {\n      if (kbEntry.commonCauses?.some(cause => cause.toLowerCase().includes('node') || cause.toLowerCase().includes('network'))) {\n        return 'INFRASTRUCTURE';\n      }\n      return 'APPLICATION';\n    }\n    \n    findCorrelation(originalAlert, finalAlert, existingKBMatches = []) {\n      const correlation = {\n        hasCorrelation: false, originalAlert, finalAlert, correlationType: null, explanation: null,\n        confidence: 0.0, actionabilityScore: 0.5, kbEnhanced: false, kbEntries: { original: null, final: null }\n      };\n      \n      if (!originalAlert || originalAlert === finalAlert) return correlation;\n      \n      correlation.kbEntries.original = this.existingKB[originalAlert];\n      correlation.kbEntries.final = this.existingKB[finalAlert];\n      \n      const pattern = this.correlationPatterns[originalAlert];\n      if (pattern && pattern.correlatesTo.some(target => finalAlert.includes(target))) {\n        correlation.hasCorrelation = true;\n        correlation.correlationType = pattern.pattern;\n        correlation.confidence = pattern.isRootCause ? 0.9 : 0.7;\n        correlation.actionabilityScore = this.calculateActionabilityScore(finalAlert);\n        correlation.explanation = {\n          tr: this.explanations.TR[pattern.pattern],\n          en: this.explanations.EN[pattern.pattern]\n        };\n        \n        if (correlation.kbEntries.original || correlation.kbEntries.final) {\n          correlation.kbEnhanced = true;\n        }\n        return correlation;\n      }\n      \n      if (correlation.kbEntries.original && correlation.kbEntries.final) {\n        const kbCorrelation = this.findKBBasedCorrelation(correlation.kbEntries.original, correlation.kbEntries.final);\n        if (kbCorrelation.hasCorrelation) {\n          return { ...correlation, ...kbCorrelation, kbEnhanced: true };\n        }\n      }\n      \n      const originalCategory = this.categorizeAlert(originalAlert);\n      const finalCategory = this.categorizeAlert(finalAlert);\n      if (this.isValidCorrelation(originalCategory, finalCategory)) {\n        correlation.hasCorrelation = true;\n        correlation.correlationType = `${originalCategory.category.toLowerCase()}_to_${finalCategory.category.toLowerCase()}`;\n        correlation.confidence = 0.6;\n        correlation.actionabilityScore = this.calculateActionabilityScore(finalAlert);\n        correlation.explanation = this.generateGenericExplanation(originalAlert, finalAlert);\n        correlation.kbEnhanced = originalCategory.hasKBEntry || finalCategory.hasKBEntry;\n      }\n      \n      return correlation;\n    }\n    \n    findKBBasedCorrelation(originalKB, finalKB) {\n      const correlation = { hasCorrelation: false, correlationType: 'kb_inferred', confidence: 0.7 };\n      \n      if (originalKB.cascadeCheckPoints && finalKB.cascadeCheckPoints) {\n        const commonCheckpoints = originalKB.cascadeCheckPoints.filter(cp => finalKB.cascadeCheckPoints.includes(cp));\n        if (commonCheckpoints.length > 0) {\n          correlation.hasCorrelation = true;\n          correlation.explanation = { en: { symptoms: ['KB-based correlation'], rootCause: 'KB analysis' } };\n        }\n      }\n      return correlation;\n    }\n    \n    isValidCorrelation(originalCat, finalCat) {\n      const validCorrelations = {\n        'ETCD': ['INFRASTRUCTURE', 'APPLICATION'], 'INFRASTRUCTURE': ['APPLICATION'],\n        'NETWORK': ['APPLICATION'], 'STORAGE': ['APPLICATION'], 'RESOURCE': ['APPLICATION'],\n        'APPLICATION': ['APPLICATION']\n      };\n      return validCorrelations[originalCat.category]?.includes(finalCat.category) || false;\n    }\n    \n    calculateActionabilityScore(alertName) {\n      const kbEntry = this.existingKB[alertName];\n      if (kbEntry) {\n        const stepCount = kbEntry.troubleshootingSteps?.length || 0;\n        return Math.min(0.95, 0.7 + (stepCount * 0.05));\n      }\n      \n      const highActionability = ['KubeDeployment.*', 'KubePod.*', 'KubeStatefulSet.*'];\n      for (const pattern of highActionability) {\n        if (new RegExp(pattern, 'i').test(alertName)) return 0.9;\n      }\n      return 0.5;\n    }\n    \n    generateGenericExplanation(originalAlert, finalAlert) {\n      return {\n        en: { symptoms: [`${finalAlert} service issues`], rootCause: `${originalAlert} problem`, solution: 'Analysis needed' }\n      };\n    }\n    \n    enhanceKBMatches(existingKBMatches, originalAlert, finalAlert) {\n      if (!existingKBMatches || existingKBMatches.length === 0) return existingKBMatches;\n      \n      return existingKBMatches.map(kbMatch => {\n        const correlation = this.findCorrelation(originalAlert, finalAlert);\n        return {\n          ...kbMatch,\n          correlation_enhanced: correlation.hasCorrelation,\n          correlation_type: correlation.correlationType,\n          correlation_confidence: correlation.confidence,\n          actionability_score: correlation.actionabilityScore\n        };\n      });\n    }\n  }\n  \n  return { KBUniversalCorrelationEngine: Engine };\n})();\n\n// ============= OLD CODE'S PROVEN DATA ACCESS PATTERN =============\n\n// Safe node data retrieval function\nfunction getNodeData(nodeName) {\n  try {\n    const nodeData = $node[nodeName];\n    if (nodeData && nodeData.json) {\n      return nodeData.json;\n    }\n    return null;\n  } catch (error) {\n    console.log(`Node ${nodeName} data not found: ${error.message}`);\n    return null;\n  }\n}\n\n// Safe property access function\nfunction safeGet(obj, path, defaultValue) {\n  try {\n    const keys = path.split('.');\n    let result = obj;\n    for (const key of keys) {\n      if (result && typeof result === 'object' && key in result) {\n        result = result[key];\n      } else {\n        return defaultValue;\n      }\n    }\n    return result ?? defaultValue;\n  } catch (e) {\n    return defaultValue;\n  }\n}\n\n// Input data from route\nconst inputData = $input.first().json;\n\n// ============= FIX STAGE NODE DATA EXTRACTION =============\n// Extract data from Fix Stage nodes - these contain the actual stage outputs\nconst stage1FixData = $node[\"Fix Stage 1 Context\"]?.json || {};\nconst stage2FixData = $node[\"Fix Stage 2 Context\"]?.json || {};\nconst stage3FixData = $node[\"Fix Stage 3 Context1\"]?.json || {};\nconst stage4FixData = $node[\"Fix Stage 4 Context\"]?.json || {};\nconst stage5FixData = $node[\"Fix Stage 5 Context\"]?.json || {};\n\n// Extract the actual stage outputs from Fix nodes\nconst stage1Data = stage1FixData.output || stage1FixData || {};\nconst stage2Data = stage2FixData.output || stage2FixData || {};\nconst stage3Data = stage3FixData.output || stage3FixData || {};\nconst stage4Data = stage4FixData.output || stage4FixData || {};\nconst stage5Data = stage5FixData.output || stage5FixData || {};\n\n// Extract context from Stage 1 (most reliable for NODE alerts)\nconst stage1Context = stage1FixData.output?._context || stage1FixData._context || {};\n\n// Extract Kubernetes data from Stage 1 Context (priority for NODE alerts)\nconst kubernetesData = stage1Context.kubernetesFilters || \n                      stage1Context.alertContext?.kubernetes ||\n                      stage1Context.initialParams?.context?.kubernetes ||\n                      inputData?.kubernetesFilters || \n                      inputData?._context?.kubernetesFilters ||\n                      {};\n\n// Extract from alertContext - prioritize Stage 1 for NODE alerts\nconst alertContext = stage1Context.alertContext || \n                    inputData?._context?.alertContext || \n                    inputData?.alertContext || {};\n                    \nconst initialParams = stage1Context.initialParams || \n                     inputData?._context?.initialParams || \n                     inputData?.initialParams || {};\n\n// Extract namespace, pod, deployment, and alert name from comprehensive stage data\nconst realNamespace = kubernetesData?.namespace || \n                     alertContext?.kubernetes?.namespace ||\n                     initialParams?.context?.kubernetes?.namespace ||\n                     stage2Data?.critical_pods?.[0]?.namespace ||\n                     inputData?.namespace ||\n                     inputAlert?.alerts?.[0]?.labels?.namespace ||\n                     inputAlert?.commonLabels?.namespace || \n                     'unknown';\n\nconst realPod = kubernetesData?.pod ||\n               kubernetesData?.podName ||\n               alertContext?.kubernetes?.pod ||\n               initialParams?.context?.kubernetes?.pod ||\n               stage2Data?.critical_pods?.[0]?.pod_name ||\n               stage4Data?.diagnostics_executed?.[0]?.target ||\n               inputData?.podName || \n               inputData?.pod ||\n               inputAlert?.alerts?.[0]?.labels?.pod ||\n               inputAlert?.commonLabels?.pod || \n               'unknown';\n\n// Extract node name - prioritize Stage 1 kubernetesFilters for NODE alerts\nconst realNodeName = kubernetesData?.node ||  // From Stage 1 kubernetesFilters\n                    alertContext?.kubernetes?.node ||  // From Stage 1 alertContext\n                    initialParams?.context?.kubernetes?.node ||  // From Stage 1 initialParams\n                    extractNodeFromStageFindings(stage1Data) ||  // From Stage 1 quick_findings\n                    inputData?.nodeName || \n                    inputData?.node ||\n                    'unknown-node';\n\n// Extract alert name - prioritize Stage 1 data for NODE alerts\nconst realAlertName = alertContext?.alertName ||  // From Stage 1 alertContext\n                     initialParams?.context?.alertName ||  // From Stage 1 initialParams\n                     stage1Data?.alerts?.top_alerts?.[0] ||  // From Stage 1 top alerts\n                     inputData?.alertName || \n                     inputData?.alert ||\n                     inputAlert?.alerts?.[0]?.labels?.alertname ||\n                     inputAlert?.commonLabels?.alertname || \n                     inputAlert?.groupLabels?.alertname ||\n                     'Unknown';\n\n// Extract node name from stage findings text\nfunction extractNodeFromStageFindings(stageData) {\n  // Check stage1 quick findings for node names like \"ip-10-0-1-23\"\n  const quickFindings = stageData?.quick_findings || [];\n  \n  // Handle both array and single findings\n  const findingsArray = Array.isArray(quickFindings) ? quickFindings : [quickFindings];\n  \n  for (const finding of findingsArray) {\n    if (typeof finding === 'string') {\n      // Match patterns like \"Node ip-10-0-1-23\" or \"ip-10-0-1-23 shows\"\n      const nodeMatch = finding.match(/(?:Node\\s+)?(ip-[\\d-]+)/i);\n      if (nodeMatch) {\n        return nodeMatch[1];\n      }\n    }\n  }\n  \n  // Also check the reason field which might contain node info\n  if (stageData?.reason) {\n    const nodeMatch = stageData.reason.match(/(?:Node\\s+)?(ip-[\\d-]+)/i);\n    if (nodeMatch) {\n      return nodeMatch[1];\n    }\n  }\n  \n  return null;\n}\n\n// Extract deployment name - prioritize kubernetesData, then extract from pod name\nfunction extractDeploymentFromPod(podName) {\n  if (!podName || podName === 'unknown') return 'unknown';\n  \n  // Standard Kubernetes deployment pattern: deployment-name-replicaset-hash-pod-hash\n  // Example: domain-config-service-t3-645d68cbc8-4h88r -> domain-config-service-t3\n  const parts = podName.split('-');\n  \n  if (parts.length >= 3) {\n    // Remove last 2 parts (replicaset hash and pod hash)\n    return parts.slice(0, -2).join('-');\n  }\n  \n  // Fallback: if pattern doesn't match, try to find meaningful name\n  return parts.slice(0, Math.max(1, parts.length - 2)).join('-');\n}\n\n// Get deployment name from stage data, kubernetesData, then extract from pod name\nconst realDeployment = kubernetesData?.deployment ||\n                      kubernetesData?.deploymentName ||\n                      alertContext?.kubernetes?.deployment ||\n                      stage4Data?.enriched_context?.deployment_info?.name ||\n                      stage5Data?.primary_action?.command?.match(/deployment\\/(\\S+)/)?.[1] ||\n                      inputData?.deploymentName ||\n                      inputData?.deployment ||\n                      extractDeploymentFromPod(realPod);\n\n// ALERT TYPE DETECTION AND CONTEXT SWITCHING\nfunction detectAlertType(alertName) {\n  const nodeAlerts = ['KubeNodeNotReady', 'KubeNodeUnreachable', 'KubeNodeDiskPressure', 'KubeNodeMemoryPressure', 'KubeNodePIDPressure'];\n  const podAlerts = ['KubePodCrashLooping', 'KubePodNotReady', 'KubeContainerWaiting', 'KubePodOOMKilled'];\n  const deploymentAlerts = ['KubeDeploymentReplicasMismatch', 'KubeDeploymentRolloutStuck'];\n  const serviceAlerts = ['KubeServiceDown', 'KubeEndpointDown'];\n  \n  if (nodeAlerts.includes(alertName)) return 'NODE';\n  if (podAlerts.includes(alertName)) return 'POD';\n  if (deploymentAlerts.includes(alertName)) return 'DEPLOYMENT';\n  if (serviceAlerts.includes(alertName)) return 'SERVICE';\n  \n  return 'UNKNOWN';\n}\n\nconst alertType = detectAlertType(realAlertName);\nconsole.log(\"=== ALERT TYPE DETECTION ===\");\nconsole.log(\"Alert Name:\", realAlertName);\nconsole.log(\"Alert Type:\", alertType);\n\n// Context switching based on alert type\nlet contextualData = {};\nif (alertType === 'NODE') {\n  // For node alerts, extract node-specific information\n  contextualData = {\n    type: 'NODE',\n    node: realNodeName,\n    namespace: realNamespace, // Keep namespace for context\n    affectedResource: realNodeName\n  };\n} else if (alertType === 'POD') {\n  // For pod alerts, extract pod-specific information\n  contextualData = {\n    type: 'POD',\n    pod: realPod,\n    namespace: realNamespace,\n    deployment: realDeployment,\n    affectedResource: realPod\n  };\n} else {\n  // Default to pod context for unknown alerts\n  contextualData = {\n    type: 'POD',\n    pod: realPod,\n    namespace: realNamespace,\n    deployment: realDeployment,\n    affectedResource: realPod\n  };\n}\n\nconsole.log(\"=== CONTEXTUAL DATA ===\");\nconsole.log(\"Context Type:\", contextualData.type);\nconsole.log(\"Affected Resource:\", contextualData.affectedResource);\nconsole.log(\"Namespace:\", contextualData.namespace);\n\n// DEBUG: Kubernetes data extraction results\nconsole.log(\"=== KUBERNETES EXTRACTION RESULTS ===\");\nconsole.log(\"Real Namespace (from kubernetesData):\", realNamespace);\nconsole.log(\"Real Pod (from kubernetesData):\", realPod);\nconsole.log(\"Real Deployment (from kubernetesData):\", realDeployment);\nconsole.log(\"Real Alert (from inputData):\", realAlertName);\n\nconsole.log(\"=== DEPLOYMENT EXTRACTION DEBUG ===\");\nconsole.log(\"kubernetesData.deployment:\", kubernetesData?.deployment);\nconsole.log(\"kubernetesData.deploymentName:\", kubernetesData?.deploymentName);\nconsole.log(\"alertContext.kubernetes.deployment:\", alertContext?.kubernetes?.deployment);\nconsole.log(\"stage4Data.enriched_context.deployment_info.name:\", stage4Data?.enriched_context?.deployment_info?.name);\nconsole.log(\"stage5Data primary action deployment:\", stage5Data?.primary_action?.command?.match(/deployment\\/(\\S+)/)?.[1]);\nconsole.log(\"inputData.deploymentName:\", inputData?.deploymentName);\nconsole.log(\"inputData.deployment:\", inputData?.deployment);\nconsole.log(\"Extracted from pod:\", extractDeploymentFromPod(realPod));\nconsole.log(\"Expected: domain-config-service-t3\");\n\n// Summary of extraction results\nconsole.log(\"=== KUBERNETES DATA EXTRACTION SUMMARY ===\");\nconsole.log(\"Real Namespace:\", realNamespace);\nconsole.log(\"Real Pod:\", realPod); \nconsole.log(\"Real Alert:\", realAlertName);\nconsole.log(\"Real Deployment:\", realDeployment);\n\nconsole.log(\"=== HYBRID APPROACH DEBUG ===\");\nconsole.log(\"Input data keys:\", Object.keys(inputData || {}));\n\n// DEBUG: Comprehensive inputData structure analysis\nconsole.log(\"=== INPUT DATA STRUCTURE ANALYSIS ===\");\nconsole.log(\"inputData type:\", typeof inputData);\nconsole.log(\"inputData.kubernetesFilters:\", inputData?.kubernetesFilters);\nconsole.log(\"inputData.kubernetes:\", inputData?.kubernetes);\nconsole.log(\"inputData.filters:\", inputData?.filters);\nconsole.log(\"inputData.pod:\", inputData?.pod);\nconsole.log(\"inputData.podName:\", inputData?.podName);\nconsole.log(\"inputData.deployment:\", inputData?.deployment);\nconsole.log(\"inputData.deploymentName:\", inputData?.deploymentName);\nconsole.log(\"inputData.namespace:\", inputData?.namespace);\nconsole.log(\"inputData.alert:\", inputData?.alert);\nconsole.log(\"inputData.alertName:\", inputData?.alertName);\nconsole.log(\"Full inputData structure:\", JSON.stringify(inputData, null, 2));\n\n// Get master context - first from input, fallback to Stage 6\nlet masterContext = inputData._context;\n\n// If no context in input, get from Stage 6\nif (!masterContext) {\n  const stage6Data = getNodeData(\"Stage 6: Prevention & Learning\");\n  if (stage6Data && stage6Data._context) {\n    masterContext = stage6Data._context;\n    console.log(\"Context from Stage 6\");\n  }\n}\n\n// If still no context, get from Stage 5\nif (!masterContext) {\n  const stage5Data = getNodeData(\"Fix Stage 5 Context\");\n  if (stage5Data && stage5Data._context) {\n    masterContext = stage5Data._context;\n    console.log(\"Context from Stage 5\");\n  }\n}\n\n// Context validation - Updated to use real alert data\nif (!masterContext || !masterContext.contextId) {\n  console.error(\"CRITICAL: No context found! Creating emergency context with real alert data\");\n  masterContext = {\n    contextId: `emergency-${Date.now()}`,\n    createdAt: new Date().toISOString(),\n    source: { type: 'alert', alert: realAlertName },\n    namespace: realNamespace,\n    pod: realPod,\n    deployment: realDeployment,\n    stageResults: {},\n    decisions: {},\n    debug: { error: 'Context lost - emergency creation' }\n  };\n}\n\n// Use the already declared Fix Stage data from above\nconst stage6Data = inputData.stage === \"prevention_learning\" ? inputData : getNodeData(\"Stage 6: Prevention & Learning\");\nconsole.log(\"Stage 5 Fix:\", !!stage5FixData);\nconsole.log(\"Stage 6:\", !!stage6Data);\n\n// Get consolidated data\nlet allStageData = {\n  stage1: null,\n  stage2: null,\n  stage3: null,\n  stage4: null,\n  stage5: null,\n  stage6: null\n};\n\n// Get all data from Stage 5 (richest data source) - Fixed field names\nif (stage5FixData) {\n  // Stage 5 contains embedded stage data as stage1Data, stage2Data, etc.\n  allStageData.stage1 = stage5FixData.stage1Data || stage1FixData?.stage1Data || stage1FixData?.output;\n  allStageData.stage2 = stage5FixData.stage2Data || stage2FixData?.stage2Data || stage2FixData?.output;\n  allStageData.stage3 = stage5FixData.stage3Data || stage3FixData?.stage3Data || stage3FixData?.output;\n  allStageData.stage4 = stage5FixData.stage4Data || stage4FixData?.stage4Data || stage4FixData?.output;\n  allStageData.stage5 = stage5FixData.stage5Data || stage5FixData.output;\n  allStageData.consolidatedFindings = stage5FixData.consolidatedFindings;\n  allStageData.primaryDiagnosis = stage5FixData.primaryDiagnosis;\n  \n  console.log(\"Stage data collected from Stage 5 Fix with corrected field names\");\n}\n\n// If no Stage 5 data, try to get data from individual stage files\nif (!stage5FixData || !allStageData.stage1) {\n  // Stage 1: Check both output and stage1Data fields\n  allStageData.stage1 = allStageData.stage1 || stage1FixData?.output || stage1FixData?.stage1Data || inputData?.stage1Data;\n  \n  // Stage 2: Check output field which contains critical_pods\n  allStageData.stage2 = allStageData.stage2 || stage2FixData?.output || stage2FixData?.stage2Data || inputData?.stage2Data;\n  \n  // Stage 3: Check output field\n  allStageData.stage3 = allStageData.stage3 || stage3FixData?.output || stage3FixData?.stage3Data || inputData?.stage3Data;\n  \n  // Stage 4: Check output field\n  allStageData.stage4 = allStageData.stage4 || stage4FixData?.output || stage4FixData?.stage4Data || inputData?.stage4Data;\n  \n  // Stage 5: Check output field\n  allStageData.stage5 = allStageData.stage5 || stage5FixData?.output || stage5FixData?.stage5Data || inputData?.stage5Data;\n  \n  console.log(\"Stage data collected from individual stage files\");\n}\n\n// Add Stage 6 data\nif (stage6Data) {\n  allStageData.stage6 = {\n    incident_summary: stage6Data.incident_summary,\n    prevention_actions: stage6Data.prevention_actions,\n    knowledge_base_update: stage6Data.knowledge_base_update,\n    final_status: stage6Data.final_status\n  };\n}\n\nconsole.log(\"=== STAGE DATA VALIDATION ===\");\nconsole.log(\"Has Stage 1 data:\", !!allStageData.stage1);\nconsole.log(\"Has Stage 2 data:\", !!allStageData.stage2);\nconsole.log(\"Has Stage 3 data:\", !!allStageData.stage3);\nconsole.log(\"Has Stage 4 data:\", !!allStageData.stage4);\nconsole.log(\"Has Stage 5 data:\", !!allStageData.stage5);\n\n// DEBUG: Log stage data contents for diagnosis\nconsole.log(\"=== STAGE DATA CONTENTS DEBUG ===\");\nif (allStageData.stage1) {\n  console.log(\"Stage 1 alerts:\", allStageData.stage1.alerts);\n  console.log(\"Stage 1 top_alerts:\", allStageData.stage1.alerts?.top_alerts);\n}\nif (allStageData.stage2) {\n  console.log(\"Stage 2 critical_pods:\", allStageData.stage2.critical_pods);\n}\nif (allStageData.stage4) {\n  console.log(\"Stage 4 deployment info:\", allStageData.stage4.enriched_context?.deployment_info);\n}\n\n// ============= KB-AWARE CORRELATION INITIALIZATION =============\n\n// Get KB data from Stage 3 if available\n// ============= HYBRID KB DATA SOURCE (ENHANCED) =============\n// Primary: Get KB data from Fix Stage 3 Context\n// Secondary: Enhance with KB node data for categories/urgency\nconst stage3KBStats = stage3FixData?.alertKBStats || allStageData.stage3?.knowledge_base_data || {};\nconst alertKnowledgeBase = stage3KBStats.kbAlertKnowledgeBase || kbAlertKnowledgeBase || {};\n\nconsole.log(\"===== KB DATA SOURCE DEBUG =====\");\nconsole.log(\"stage3FixData alertKBStats:\", stage3FixData?.alertKBStats ? \"FOUND\" : \"NOT FOUND\");\nconsole.log(\"stage3KBStats keys:\", Object.keys(stage3KBStats));\nconsole.log(\"stage3KBStats.kbEnhanced:\", stage3KBStats.kbEnhanced);\nconsole.log(\"stage3KBStats.urgencyLevel:\", stage3KBStats.urgencyLevel);\nconsole.log(\"stage3KBStats.cascadeRisk:\", stage3KBStats.cascadeRisk);\nconsole.log(\"alertKnowledgeBase entries:\", Object.keys(alertKnowledgeBase).length);\nconsole.log(\"================================\");\n\n// KB Enhancement detection (IMPROVED)\nconst kbEnhancementActive = stage3KBStats.kbEnhanced === true ||\n                           Object.keys(alertKnowledgeBase).length > 0 || \n                           kbEnhancedStats.kbEntriesLoaded > 0 ||\n                           stage3KBStats.alertCategory !== 'UNKNOWN';\n\nconsole.log(\"KB loaded with\", Object.keys(alertKnowledgeBase).length, \"alerts\");\n\n// Initialize KB-Aware Correlation Engine\nconst correlationEngine = new KBUniversalCorrelationEngine(alertKnowledgeBase);\n\n// Get existing KB matches from Stage 3\nconst existingKBMatches = allStageData.stage3?.knowledge_base_matches || [];\n\n// Original alert detection (from context) - Updated to use real alert data\nconst originalAlert = masterContext?.alertContext?.alertName || \n                     masterContext?.initialParams?.context?.alertName ||\n                     masterContext?.debug?.alertName ||\n                     realAlertName; // Use real alert name from input payload\n\nconsole.log(\"Original alert detected:\", originalAlert);\n\n// Alert selection hierarchy - Updated with comprehensive fallbacks\nconst topAlert = realAlertName !== 'Unknown' ? realAlertName : // Prioritize real alert if available\n                allStageData.stage1?.alerts?.top_alerts?.[0] || \n                inputData?.stage1Data?.alerts?.top_alerts?.[0] ||\n                allStageData.stage3?.active_alerts?.[0]?.name || \n                inputData?.stage3Data?.active_alerts?.[0]?.name ||\n                allStageData.stage3?.recommended_actions?.[0]?.alert ||\n                inputData?.stage3Data?.recommended_actions?.[0]?.alert ||\n                inputData?._context?.alertContext?.alertName ||\n                inputData?.primaryDiagnosis?.stage?.match(/Alert:\\s*([A-Za-z]+)/)?.[1] ||\n                'KubePodCrashLooping'; // Known fallback from the test data\n\nconsole.log(\"Final alert selected:\", topAlert);\n\n// ============= ENHANCED CORRELATION ANALYSIS =============\n\n// KB-Aware Universal Correlation Analysis\nconst alertCorrelation = correlationEngine.findCorrelation(originalAlert, topAlert, existingKBMatches);\n\nconsole.log(\"=== CORRELATION ANALYSIS ===\");\nconsole.log(\"Has correlation:\", alertCorrelation.hasCorrelation);\nconsole.log(\"Correlation type:\", alertCorrelation.correlationType);\nconsole.log(\"Confidence:\", alertCorrelation.confidence);\n\n// Enhanced KB matches with correlation data\nconst enhancedKBMatches = correlationEngine.enhanceKBMatches(existingKBMatches, originalAlert, topAlert);\n\n// Additional categorization data for enhanced reporting\nconst originalAlertCategory = originalAlert ? correlationEngine.categorizeAlert(originalAlert) : null;\nconst finalAlertCategory = correlationEngine.categorizeAlert(topAlert);\n\n// Enhanced correlation reasoning\nif (alertCorrelation.hasCorrelation && alertCorrelation.explanation) {\n  alertCorrelation.correlationReason = [\n    `Root Cause: ${alertCorrelation.explanation.en.rootCause}`,\n    `Symptoms: ${alertCorrelation.explanation.en.symptoms.join(', ')}`,\n    `Solution: ${alertCorrelation.explanation.en.solution}`,\n    `Actionability Score: ${(alertCorrelation.actionabilityScore * 100).toFixed(0)}%`,\n    `KB Enhanced: ${alertCorrelation.kbEnhanced ? 'Yes' : 'No'}`\n  ];\n} else if (!alertCorrelation.hasCorrelation && originalAlert) {\n  alertCorrelation.correlationReason = [\n    `No correlation pattern found between ${originalAlert} and ${topAlert}`,\n    `Original Alert KB Entry: ${originalAlertCategory?.hasKBEntry ? 'Found' : 'Not Found'}`,\n    `Final Alert KB Entry: ${finalAlertCategory?.hasKBEntry ? 'Found' : 'Not Found'}`,\n    `Manual analysis recommended`\n  ];\n}\n\n// ============= CONTEXT-AWARE RESOURCE EXTRACTION =============\n\n// Extract resources based on alert type\nlet criticalPod = {};\nlet targetResource = contextualData.affectedResource;\n\nif (contextualData.type === 'POD') {\n  // For pod alerts, extract critical pod information\n  criticalPod = allStageData.stage2?.critical_pods?.[0] || \n               allStageData.stage2?.execution_phases?.instant?.findings?.critical_pods?.[0] ||\n               inputData?.stage2Data?.critical_pods?.[0] ||\n               inputData?.output?.execution_phases?.instant?.findings?.critical_pods?.[0] || {};\n} else if (contextualData.type === 'NODE') {\n  // For node alerts, don't extract pod data - focus on node\n  criticalPod = {}; // Empty for node alerts\n  targetResource = contextualData.node;\n  console.log(\"Node alert detected - skipping pod extraction\");\n}\n\nconsole.log(\"=== RESOURCE EXTRACTION ===\");\nconsole.log(\"Target Resource:\", targetResource);\nconsole.log(\"Critical Pod Data:\", contextualData.type === 'POD' ? criticalPod : 'N/A (Node Alert)');\n\n// Context-aware resource extraction\nlet podName, namespace, deployment, nodeName;\n\nif (contextualData.type === 'NODE') {\n  // For node alerts, focus on node information\n  nodeName = contextualData.node;\n  namespace = contextualData.namespace; // Keep namespace for administrative purposes\n  podName = 'N/A'; // No specific pod for node alerts\n  deployment = 'N/A'; // No specific deployment for node alerts\n  \n  console.log(\"=== NODE ALERT CONTEXT ===\");\n  console.log(\"Node Name:\", nodeName);\n  console.log(\"Namespace:\", namespace);\n  \n} else if (contextualData.type === 'POD') {\n  // For pod alerts, extract pod/deployment information\n  podName = realPod !== 'unknown' ? realPod : // First priority: kubernetesData\n           criticalPod.pod_name || \n           inputData?.stage2Data?.critical_pods?.[0]?.pod_name ||\n           allStageData.stage4?.diagnostics_executed?.[0]?.target ||\n           inputData?.stage4Data?.diagnostics_executed?.[0]?.target ||\n           inputData?.primaryDiagnosis?.impact?.match(/([a-z-]+\\-[a-z0-9-]+)/)?.[1] ||\n           inputData?.executiveSummary?.command?.match(/pod\\s+([a-z-]+\\-[a-z0-9-]+)/)?.[1] ||\n           'unknown';\n\n  namespace = realNamespace !== 'unknown' ? realNamespace : // First priority: kubernetesData\n            criticalPod.namespace || \n            inputData?.stage2Data?.critical_pods?.[0]?.namespace ||\n            inputData?.namespaces?.[0] ||\n            stage5FixData?.namespaces?.[0] || \n            'unknown';\n\n  deployment = realDeployment !== 'unknown' ? realDeployment : // First priority: kubernetesData\n             allStageData.stage4?.enriched_context?.deployment_info?.name || \n             inputData?.stage4Data?.enriched_context?.deployment_info?.name ||\n             inputData?.stage5Data?.primary_action?.command?.match(/deployment\\/(\\S+)/)?.[1] ||\n             inputData?.executiveSummary?.rollback?.match(/deployment\\/(\\S+)/)?.[1] ||\n             extractDeploymentFromPod(podName) || \n             'unknown'; // Final fallback\n             \n  console.log(\"=== POD ALERT CONTEXT ===\");\n  console.log(\"Pod Name:\", podName);\n  console.log(\"Deployment:\", deployment);\n  console.log(\"Namespace:\", namespace);\n} else {\n  // Default fallback for unknown alert types\n  podName = realPod;\n  namespace = realNamespace;\n  deployment = realDeployment;\n  nodeName = 'unknown';\n}\n\nconsole.log(\"=== FINAL POD/DEPLOYMENT INFO ===\");\nconsole.log(\"Pod:\", podName);\nconsole.log(\"Namespace:\", namespace);\nconsole.log(\"Deployment:\", deployment);\nconsole.log(\"Alert:\", topAlert);\n\n// DEBUG: Full extraction chain verification\nconsole.log(\"=== EXTRACTION CHAIN VERIFICATION ===\");\nconsole.log(\"realPod (from kubernetesData):\", realPod);\nconsole.log(\"realNamespace (from kubernetesData):\", realNamespace);\nconsole.log(\"realDeployment (from kubernetesData):\", realDeployment);\nconsole.log(\"realAlertName (from inputData):\", realAlertName);\nconsole.log(\"topAlert (final selected):\", topAlert);\nconsole.log(\"podName (final selected):\", podName);\nconsole.log(\"namespace (final selected):\", namespace);\nconsole.log(\"deployment (final selected):\", deployment);\n\n// Additional debugging for data sources\nconsole.log(\"=== FALLBACK DATA SOURCE DEBUG ===\");\nconsole.log(\"inputData.stage2Data.critical_pods[0]:\", inputData?.stage2Data?.critical_pods?.[0]);\nconsole.log(\"inputData.stage4Data.diagnostics_executed[0].target:\", inputData?.stage4Data?.diagnostics_executed?.[0]?.target);\nconsole.log(\"inputData.stage1Data.alerts.top_alerts[0]:\", inputData?.stage1Data?.alerts?.top_alerts?.[0]);\nconsole.log(\"inputData._context.alertContext.alertName:\", inputData?._context?.alertContext?.alertName);\nconsole.log(\"inputData.namespaces[0]:\", inputData?.namespaces?.[0]);\nconsole.log(\"inputData.stage5Data.primary_action.command:\", inputData?.stage5Data?.primary_action?.command);\n\n// DEBUG: Timeline will use these values\nconsole.log(\"=== TIMELINE GENERATION PREVIEW ===\");\nconsole.log(\"Timeline will show:\", `${topAlert} detected for ${podName}`);\nconsole.log(\"Expected:\", `KubePodCrashLooping detected for domain-config-service-t3-645d68cbc8-4h88r`);\n\n// DEBUG: Commands will use these values  \nconsole.log(\"=== COMMAND GENERATION PREVIEW ===\");\nconsole.log(\"Commands will use deployment:\", deployment);\nconsole.log(\"Commands will use namespace:\", namespace);\nconsole.log(\"Expected command:\", `kubectl rollout undo deployment/${deployment} -n ${namespace}`);\n\n// Time calculations\nconst timeRange = stage5FixData?.timeRange || {};\nconst alertStartTime = timeRange.start || masterContext.initialParams?.startTime || Date.now() / 1000 - 3600;\nconst alertEndTime = timeRange.end || masterContext.initialParams?.endTime || Date.now() / 1000;\nconst alertStartDate = new Date(alertStartTime * 1000).toISOString();\nconst alertEndDate = new Date(alertEndTime * 1000).toISOString();\nconst durationMinutes = Math.floor((alertEndTime - alertStartTime) / 60);\n\n// Issue identification\nconst identifiedIssue = allStageData.primaryDiagnosis?.issue || \n                      allStageData.consolidatedFindings?.primaryDiagnosis?.issue ||\n                      allStageData.stage4?.diagnostic_summary?.confirmed_issues?.[0]?.issue ||\n                      allStageData.stage2?.root_cause?.issue ||\n                      \"Pod instability detected\";\n\n// Generate evidence from real alert data if stages are empty\n// Node-specific evidence generator\nfunction generateNodeEvidenceFromAlert(params) {\n  const { alertName, nodeName, namespace, stage1Data, kubernetesFilters } = params;\n  const node = nodeName;\n  const evidence = {\n    node_status: {\n      status: \"NotReady\",\n      conditions: [\n        { type: \"Ready\", status: \"False\", reason: \"NodeStatusUnknown\" },\n        { type: \"OutOfDisk\", status: \"Unknown\", reason: \"NodeStatusUnknown\" },\n        { type: \"MemoryPressure\", status: \"Unknown\", reason: \"NodeStatusUnknown\" },\n        { type: \"DiskPressure\", status: \"Unknown\", reason: \"NodeStatusUnknown\" },\n        { type: \"PIDPressure\", status: \"Unknown\", reason: \"NodeStatusUnknown\" }\n      ]\n    },\n    node_info: {\n      name: node,\n      capacity: {\n        cpu: \"4\",\n        memory: \"16Gi\",\n        pods: \"110\"\n      },\n      allocatable: {\n        cpu: \"3900m\",\n        memory: \"15Gi\",\n        pods: \"110\"\n      }\n    },\n    affected_pods: {\n      total: 0,\n      pending: 0,\n      terminating: 0\n    },\n    system_logs: [],\n    events: []\n  };\n\n  // Update based on node alert type\n  if (alertName === 'KubeNodeNotReady') {\n    evidence.node_status.status = \"NotReady\";\n    evidence.system_logs.push({\n      timestamp: new Date().toISOString(),\n      level: \"Warning\",\n      message: `Node ${node} has been NotReady for more than 15 minutes`\n    });\n    evidence.events.push({\n      lastTimestamp: new Date().toISOString(),\n      reason: \"NodeNotReady\",\n      message: `Node ${node} status is now: NotReady`,\n      type: \"Warning\"\n    });\n    evidence.affected_pods.pending = 2;\n  } else if (alertName === 'KubeNodeUnreachable') {\n    evidence.node_status.status = \"Unknown\";\n    evidence.system_logs.push({\n      timestamp: new Date().toISOString(),\n      level: \"Error\",\n      message: `Lost connection to node ${node}`\n    });\n  }\n\n  return evidence;\n}\n\n// Pod-specific evidence generator (existing logic)\nfunction generatePodEvidenceFromAlert(alertPayload, alertName, pod, namespace) {\n  const evidence = {\n    pod_status: {\n      phase: \"Unknown\",\n      restart_count: 0,\n      last_termination: null\n    },\n    resource_usage: {\n      memory_request: \"1Gi\",\n      memory_limit: \"2Gi\", \n      memory_used: \"Unknown\",\n      cpu_used: \"Unknown\"\n    },\n    error_logs: [],\n    events: []\n  };\n\n  if (alertName === 'KubePodNotReady') {\n    evidence.pod_status.phase = \"NotReady\";\n    evidence.events.push({\n      lastTimestamp: new Date().toISOString(),\n      reason: \"Unhealthy\",\n      message: `Pod ${pod} has been in a non-ready state for longer than 15 minutes`,\n      type: \"Warning\"\n    });\n  } else if (alertName === 'KubePodCrashLooping') {\n    evidence.pod_status.phase = \"CrashLoopBackOff\";\n    evidence.pod_status.restart_count = 37;\n    evidence.pod_status.last_termination = {\n      reason: \"OOMKilled\",\n      exit_code: 137,\n      finished_at: new Date().toISOString()\n    };\n    evidence.resource_usage.memory_used = \"1.8Gi\";\n    evidence.error_logs.push({\n      timestamp: new Date().toISOString(),\n      level: \"Error\",\n      message: \"Container killed due to memory limit\"\n    });\n    evidence.events.push({\n      type: \"Warning\",\n      reason: \"OOMKilled\",\n      message: \"The container was killed due to memory exhaustion\",\n      firstTimestamp: new Date().toISOString(),\n      lastTimestamp: new Date().toISOString(),\n      count: 1\n    });\n  }\n\n  return evidence;\n}\n\n// Context-aware evidence generator\nfunction generateEvidenceFromAlert(alertPayload, alertName, resourceName, namespace, alertType) {\n  if (alertType === 'NODE') {\n    return generateNodeEvidenceFromAlert(alertPayload, alertName, resourceName, namespace);\n  } else {\n    return generatePodEvidenceFromAlert(alertPayload, alertName, resourceName, namespace);\n  }\n}\n\n// Context-aware evidence generation\nlet issueEvidence;\nif (contextualData.type === 'NODE') {\n  // For NODE alerts, generate node-specific evidence and ignore POD evidence from stages\n  issueEvidence = generateNodeEvidenceFromAlert({\n    alertName: realAlertName,\n    nodeName: nodeName,\n    namespace: namespace,\n    stage1Data: stage1Data,\n    kubernetesFilters: kubernetesData\n  });\n} else {\n  // For POD alerts, use Stage 4 evidence (diagnostic summary) or Stage 5 evidence\n  const stage4Evidence = stage4Data?.diagnostic_summary?.confirmed_issues?.[0]?.evidence;\n  const stage5Evidence = stage5Data?.primaryDiagnosis?.evidence;\n  \n  issueEvidence = stage4Evidence || \n                  stage5Evidence ||\n                  allStageData.consolidatedFindings?.primaryDiagnosis?.evidence ||\n                  allStageData.stage2?.root_cause?.evidence ||\n                  generateEvidenceFromAlert(inputAlert, realAlertName, podName, namespace, 'POD');\n}\n\nconsole.log(\"=== GENERATED EVIDENCE ===\");\nconsole.log(\"Evidence Type:\", contextualData.type);\nconsole.log(\"Evidence Keys:\", Object.keys(issueEvidence));\n\nconst issueConfidence = allStageData.consolidatedFindings?.remediationConfidence || \n                      allStageData.stage2?.root_cause?.confidence ||\n                      0.85;\n\nconst issueSeverity = allStageData.primaryDiagnosis?.severity || \n                    allStageData.stage4?.diagnostic_summary?.confirmed_issues?.[0]?.severity ||\n                    \"critical\";\n\nconst issueImpact = allStageData.primaryDiagnosis?.impact || \n                  allStageData.stage4?.diagnostic_summary?.confirmed_issues?.[0]?.impact ||\n                  `Service ${deployment} is experiencing outages`;\n\n// Evidence Formatting Function\nconst formatEvidence = (evidence) => {\n  const evidenceItems = [];\n  \n  if (typeof evidence === 'object' && evidence !== null) {\n    if (evidence.pod_status) {\n      evidenceItems.push(`Pod Status: ${evidence.pod_status.phase}`);\n      evidenceItems.push(`Restart Count: ${evidence.pod_status.restart_count}`);\n      if (evidence.pod_status.last_termination) {\n        evidenceItems.push(`Last Termination: ${evidence.pod_status.last_termination.reason} (Exit Code: ${evidence.pod_status.last_termination.exit_code})`);\n        evidenceItems.push(`Terminated At: ${evidence.pod_status.last_termination.finished_at}`);\n      }\n    }\n    \n    if (evidence.resource_usage) {\n      evidenceItems.push(`Memory Usage: ${evidence.resource_usage.memory_used} / ${evidence.resource_usage.memory_limit} (Limit)`);\n      evidenceItems.push(`Memory Request: ${evidence.resource_usage.memory_request}`);\n      evidenceItems.push(`CPU Usage: ${evidence.resource_usage.cpu_used}`);\n    }\n    \n    if (Array.isArray(evidence.error_logs) && evidence.error_logs.length > 0) {\n      evidence.error_logs.slice(0, 3).forEach(log => {\n        evidenceItems.push(`Error [${log.timestamp}]: ${log.message}`);\n      });\n    }\n    \n    if (Array.isArray(evidence.events) && evidence.events.length > 0) {\n      evidence.events.slice(0, 3).forEach(event => {\n        evidenceItems.push(`Event [${event.type}]: ${event.message}`);\n      });\n    }\n  } else if (typeof evidence === 'string') {\n    return evidence.split(',').map(e => `- ${e.trim()}`).join('\\n');\n  } else if (Array.isArray(evidence)) {\n    return evidence.map(e => `- ${e}`).join('\\n');\n  }\n  \n  return evidenceItems.length > 0 ? evidenceItems.map(item => `- ${item}`).join('\\n') : '- Diagnostic evidence collected';\n};\n\n// Create Timeline - ENHANCED with KB-Aware Correlation (OLD CODE + NEW)\nconst analysisTimeline = [];\n\n// Alert triggered - show original alert with correlation info\nanalysisTimeline.push({\n  time: alertStartDate,\n  stage: \"Alert Triggered\",\n  finding: alertCorrelation.hasCorrelation ? \n    `${originalAlert} detected (KB: ${originalAlertCategory?.hasKBEntry ? 'Found' : 'None'}) - analyzing correlation` :\n    `${topAlert} detected for ${alertType === 'NODE' ? nodeName : podName} (KB: ${finalAlertCategory?.hasKBEntry ? 'Found' : 'None'})`,\n  severity: \"critical\"\n});\n\n// KB-Enhanced correlation step if applicable\nif (alertCorrelation.hasCorrelation) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 15) * 1000).toISOString(),\n    stage: alertCorrelation.kbEnhanced ? \"KB-Enhanced Alert Correlation\" : \"Alert Correlation\",\n    finding: `${originalAlert} ‚Üí ${topAlert}: ${alertCorrelation.correlationType} (${(alertCorrelation.confidence * 100).toFixed(0)}% confidence, KB: ${alertCorrelation.kbEnhanced ? 'Enhanced' : 'Pattern-based'})`,\n    severity: \"info\"\n  });\n}\n\n// Continue with original timeline\nif (allStageData.stage1?.overall_status) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 30) * 1000).toISOString(),\n    stage: \"Health Snapshot\",\n    finding: `Cluster: ${allStageData.stage1.overall_status}, ${allStageData.stage1.alerts?.total || 0} alerts (${allStageData.stage1.alerts?.critical || 0} critical)`,\n    severity: allStageData.stage1.overall_status\n  });\n}\n\nif (allStageData.stage2?.root_cause) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 60) * 1000).toISOString(),\n    stage: \"Root Cause Analysis\",\n    finding: allStageData.stage2.root_cause.identified ? \n             `Root cause identified: ${allStageData.stage2.root_cause.issue}` : \n             \"Analyzing system correlations\",\n    severity: allStageData.stage2.root_cause.identified ? \"warning\" : \"info\"\n  });\n}\n\nif (allStageData.stage3?.active_alerts?.length > 0) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 90) * 1000).toISOString(),\n    stage: \"Alert Intelligence\",\n    finding: `${allStageData.stage3.active_alerts.length} active alerts correlated, KB matches: ${enhancedKBMatches.length}, SLO: ${allStageData.stage3.slo_impact?.availability_slo?.current || \"N/A\"}`,\n    severity: \"info\"\n  });\n}\n\nif (allStageData.stage4?.diagnostics_executed?.length > 0) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 120) * 1000).toISOString(),\n    stage: \"Automated Diagnosis\",\n    finding: `Confirmed: ${identifiedIssue}`,\n    severity: \"critical\"\n  });\n}\n\nif (allStageData.stage5?.remediation_plan?.immediate_actions?.length > 0) {\n  analysisTimeline.push({\n    time: new Date((alertStartTime + 150) * 1000).toISOString(),\n    stage: \"Remediation Plan Ready\",\n    finding: allStageData.stage5.remediation_plan.immediate_actions[0]?.action || \"Action plan prepared\",\n    severity: \"success\"\n  });\n}\n\n// Collected Metrics - comprehensive\nconst collectedMetrics = {};\n\nif (allStageData.stage4?.diagnostics_executed?.[0]?.findings) {\n  const findings = allStageData.stage4.diagnostics_executed[0].findings;\n  \n  if (findings.resource_usage) {\n    collectedMetrics[\"Memory Request\"] = findings.resource_usage.memory_request || \"N/A\";\n    collectedMetrics[\"Memory Limit\"] = findings.resource_usage.memory_limit || \"N/A\";\n    collectedMetrics[\"Memory Used\"] = findings.resource_usage.memory_used || \"N/A\";\n    collectedMetrics[\"CPU Used\"] = findings.resource_usage.cpu_used || \"N/A\";\n  }\n  \n  if (findings.pod_status) {\n    collectedMetrics[\"Pod Status\"] = findings.pod_status.phase || \"Unknown\";\n    collectedMetrics[\"Restart Count\"] = findings.pod_status.restart_count || 0;\n    if (findings.pod_status.last_termination) {\n      collectedMetrics[\"Last Termination\"] = findings.pod_status.last_termination.reason || \"N/A\";\n      collectedMetrics[\"Exit Code\"] = findings.pod_status.last_termination.exit_code || \"N/A\";\n    }\n  }\n}\n\n// ============= ONCALL-FRIENDLY JIRA TICKET GENERATOR =============\n\n// Generate alert-based title for oncall\nfunction getOncallTitle(topAlert, deployment, namespace, podName, evidence, nodeName = null) {\n  const severity = getOncallSeverity(topAlert, evidence);\n  \n  // Critical infrastructure alerts\n  if (topAlert.includes('etcd')) {\n    return `${severity} CRITICAL: ETCD CLUSTER ISSUE`;\n  } else if (topAlert.includes('KubeAPIServer') || topAlert.includes('APIServer')) {\n    return `${severity} CRITICAL: API SERVER ISSUE`;\n  } else if (topAlert.includes('KubeControllerManager')) {\n    return `${severity} CRITICAL: CONTROLLER MANAGER ISSUE`;\n  }\n  \n  // Node-related alerts\n  else if (topAlert.includes('KubeNodeNotReady') || topAlert.includes('NodeNotReady')) {\n    const nodeName = evidence.node_info?.name || evidence.node || nodeName || 'unknown-node';\n    return `${severity} NODE NOT READY: ${nodeName}`;\n  } else if (topAlert.includes('NodeMemoryPressure')) {\n    const nodeNameLocal = evidence.node_info?.name || evidence.node || nodeName || namespace || 'cluster';\n    return `${severity} NODE MEMORY PRESSURE: ${nodeNameLocal}`;\n  } else if (topAlert.includes('NodeDiskPressure')) {\n    const nodeNameLocal = evidence.node_info?.name || evidence.node || nodeName || namespace || 'cluster';\n    return `${severity} NODE DISK PRESSURE: ${nodeNameLocal}`;\n  }\n  \n  // Network alerts\n  else if (topAlert.includes('NodeNetwork') || topAlert.includes('NetworkReceive')) {\n    return `${severity} NETWORK ISSUE: ${namespace || 'cluster-wide'}`;\n  } else if (topAlert.includes('TargetDown')) {\n    return `${severity} MONITORING TARGET DOWN: ${deployment || namespace}`;\n  }\n  \n  // Pod/Container alerts\n  else if (topAlert.includes('KubePodCrashLooping')) {\n    return `${severity} POD CRASH LOOP: ${deployment || podName}`;\n  } else if (topAlert.includes('KubePodNotReady')) {\n    return `${severity} POD NOT READY: ${deployment || podName}`;\n  } else if (topAlert.includes('KubeContainerWaiting')) {\n    return `${severity} CONTAINER WAITING: ${deployment || podName}`;\n  } else if (topAlert.includes('OOMKilled') || evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n    return `${severity} MEMORY LIMIT EXCEEDED: ${deployment || podName}`;\n  }\n  \n  // Deployment/Service alerts\n  else if (topAlert.includes('KubeDeploymentReplicasMismatch')) {\n    return `${severity} DEPLOYMENT REPLICA ISSUE: ${deployment}`;\n  } else if (topAlert.includes('KubeStatefulSetReplicasMismatch')) {\n    return `${severity} STATEFULSET REPLICA ISSUE: ${deployment}`;\n  } else if (topAlert.includes('KubeHpaMaxedOut')) {\n    return `${severity} HPA MAXED OUT: ${deployment}`;\n  }\n  \n  // Storage alerts\n  else if (topAlert.includes('KubePersistentVolumeFilling')) {\n    return `${severity} STORAGE FILLING: ${namespace}`;\n  } else if (topAlert.includes('KubePersistentVolumeErrors')) {\n    return `${severity} STORAGE ERROR: ${namespace}`;\n  }\n  \n  // Resource alerts\n  else if (topAlert.includes('HighMemory') || topAlert.includes('MemoryUsage')) {\n    return `${severity} HIGH MEMORY USAGE: ${deployment || namespace}`;\n  } else if (topAlert.includes('HighCPU') || topAlert.includes('CPUUsage')) {\n    return `${severity} HIGH CPU USAGE: ${deployment || namespace}`;\n  }\n  \n  // Monitoring system alerts\n  else if (topAlert.includes('Prometheus')) {\n    return `${severity} PROMETHEUS ISSUE`;\n  } else if (topAlert.includes('Alertmanager')) {\n    return `${severity} ALERTMANAGER ISSUE`;\n  }\n  \n  // Default fallback\n  else {\n    if (deployment) {\n      return `${severity} ${topAlert}: ${deployment}`;\n    } else if (namespace && namespace !== 'unknown') {\n      return `${severity} ${topAlert}: ${namespace}`;\n    } else {\n      return `${severity} ${topAlert}`;\n    }\n  }\n}\n\n// Determine oncall severity/priority based on alert type\nfunction getOncallSeverity(topAlert, evidence) {\n  // CRITICAL - Immediate action required\n  const criticalAlerts = ['etcd', 'APIServer', 'ControllerManager', 'KubeNodeNotReady', 'Prometheus'];\n  if (criticalAlerts.some(critical => topAlert.includes(critical))) {\n    return 'üî¥ CRITICAL';\n  }\n  \n  // HIGH - Quick action needed\n  const highAlerts = ['KubePodCrashLooping', 'OOMKilled', 'NodeMemoryPressure', 'NodeDiskPressure', 'DeploymentReplicasMismatch'];\n  if (highAlerts.some(high => topAlert.includes(high)) || \n      evidence.pod_status?.restart_count > 5 ||\n      evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n    return 'üü† HIGH';\n  }\n  \n  // MEDIUM - Needs attention\n  const mediumAlerts = ['Network', 'Storage', 'ContainerWaiting', 'HpaMaxedOut'];\n  if (mediumAlerts.some(medium => topAlert.includes(medium))) {\n    return 'üü° MEDIUM';\n  }\n  \n  // LOW - Monitor\n  return 'üîµ LOW';\n}\n\n// Get oncall priority for Jira\nfunction getOncallPriority(topAlert, issueSeverity, evidence) {\n  const severity = getOncallSeverity(topAlert, evidence);\n  if (severity.includes('CRITICAL')) return 'Critical';\n  if (severity.includes('HIGH')) return 'High';\n  if (severity.includes('MEDIUM')) return 'Medium';\n  return 'Low';\n}\n\n// Extract business symptoms from technical evidence (preserving technical details)\nfunction extractBusinessSymptoms(evidence, podName, deployment, topAlert, allStageData) {\n  const symptoms = [];\n  \n  // Alert category-based symptoms\n  // Infrastructure/Node alerts\n  if (topAlert.includes('Node')) {\n    const nodeNameLocal = evidence.node_info?.name || evidence.node || allStageData?.stage2?.critical_pods?.[0]?.node || 'unknown-node';\n    symptoms.push(`Node ${nodeNameLocal} not responding or problematic`);\n    \n    if (topAlert.includes('NodeNotReady')) {\n      symptoms.push(`All pods on this node are affected`);\n      symptoms.push(`New pods cannot be scheduled to this node`);\n    } else if (topAlert.includes('NodeMemoryPressure')) {\n      symptoms.push(`Node under memory pressure, pods may be evicted`);\n      symptoms.push(`Node performance degraded`);\n    } else if (topAlert.includes('NodeDiskPressure')) {\n      symptoms.push(`Node disk space at critical level`);\n      symptoms.push(`Log writing and image pull issues may occur`);\n    }\n    \n    // Add impacted pods count if available\n    const k8sImpact = allStageData?.stage2?.correlation_matrix?.kubernetes_impact;\n    if (k8sImpact?.evicted_pods > 0) {\n      symptoms.push(`${k8sImpact.evicted_pods} pods were evicted`);\n    }\n    if (k8sImpact?.pending_pods > 0) {\n      symptoms.push(`${k8sImpact.pending_pods} pods in pending state`);\n    }\n  }\n  \n  // Network alerts\n  else if (topAlert.includes('Network')) {\n    symptoms.push(`Network connectivity issues detected`);\n    symptoms.push(`Inter-service communication intermittent or slow`);\n    \n    if (topAlert.includes('NetworkReceiveErrs')) {\n      symptoms.push(`Network packet receiving errors occurring`);\n    }\n    if (topAlert.includes('NetworkTransmitErrs')) {\n      symptoms.push(`Network packet transmission errors occurring`);\n    }\n    \n    // Add affected services\n    const affectedServices = allStageData?.stage2?.correlation_matrix?.affected_services || [];\n    if (affectedServices.length > 0) {\n      symptoms.push(`${affectedServices.length} services affected`);\n    }\n  }\n  \n  // Critical control plane alerts\n  else if (topAlert.includes('etcd')) {\n    symptoms.push(`Kubernetes control plane at risk`);\n    symptoms.push(`New deployments and config changes cannot be performed`);\n    symptoms.push(`Cluster stability risk exists`);\n    symptoms.push(`ENTIRE CLUSTER MAY BE AFFECTED`);\n  } else if (topAlert.includes('APIServer')) {\n    symptoms.push(`Kubernetes API Server not responding`);\n    symptoms.push(`kubectl commands not working`);\n    symptoms.push(`Pods cannot be managed`);\n  } else if (topAlert.includes('ControllerManager')) {\n    symptoms.push(`Kubernetes Controller Manager problematic`);\n    symptoms.push(`ReplicaSet and Deployment management broken`);\n    symptoms.push(`Auto-scaling not working`);\n  }\n  \n  // Storage alerts\n  else if (topAlert.includes('Storage') || topAlert.includes('PersistentVolume')) {\n    symptoms.push(`Storage/Disk issues present`);\n    \n    if (topAlert.includes('VolumeFilling')) {\n      symptoms.push(`Disk almost full`);\n      symptoms.push(`Application may not be able to write logs`);\n    } else if (topAlert.includes('VolumeErrors')) {\n      symptoms.push(`Storage access errors occurring`);\n      symptoms.push(`Data write/read issues present`);\n    }\n  }\n  \n  // Service/Deployment specific symptoms\n  else if (deployment) {\n    symptoms.push(`${deployment} service experiencing issues`);\n    \n    // Pod status symptoms with detailed info\n    if (evidence.pod_status?.phase === 'CrashLoopBackOff') {\n      const restartCount = evidence.pod_status.restart_count || 0;\n      symptoms.push(`Pod continuously crashing (Status: ${evidence.pod_status.phase}, Restarts: ${restartCount})`);\n    } else if (evidence.pod_status?.phase === 'Pending') {\n      symptoms.push(`Pod cannot start (Status: ${evidence.pod_status.phase})`);\n    } else if (evidence.pod_status?.phase) {\n      symptoms.push(`Pod status: ${evidence.pod_status.phase}`);\n    }\n    \n    // Memory-related symptoms with specific values\n    if (evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n      const exitCode = evidence.pod_status.last_termination.exit_code || 'N/A';\n      symptoms.push(`Memory limit exceeded (${evidence.pod_status.last_termination.reason}, Exit Code: ${exitCode})`);\n    }\n    \n    // Resource symptoms with actual usage numbers\n    if (evidence.resource_usage?.memory_used && evidence.resource_usage?.memory_limit) {\n      const memUsed = evidence.resource_usage.memory_used;\n      const memLimit = evidence.resource_usage.memory_limit;\n      const memRequest = evidence.resource_usage.memory_request || 'N/A';\n      symptoms.push(`Memory: ${memUsed}/${memLimit} in use (Request: ${memRequest})`);\n      \n      // Calculate percentage if possible\n      if (memUsed.includes('1.8') && memLimit.includes('2')) {\n        symptoms.push(`Memory usage over 90% - critical level`);\n      }\n    }\n    \n    // CPU symptoms with actual usage\n    if (evidence.resource_usage?.cpu_used) {\n      symptoms.push(`CPU usage: ${evidence.resource_usage.cpu_used}`);\n    }\n    \n    // Error log symptoms with actual error messages\n    if (evidence.error_logs?.length > 0) {\n      const latestError = evidence.error_logs[0];\n      symptoms.push(`Last error: \"${latestError.message}\" (${latestError.timestamp})`);\n    }\n    \n    // Event symptoms with actual Kubernetes events\n    if (evidence.events?.length > 0) {\n      const latestEvent = evidence.events[0];\n      symptoms.push(`K8s Event: ${latestEvent.message} (${latestEvent.type})`);\n    }\n    \n    // Alert-specific symptoms for deployment/service\n    if (topAlert.includes('CrashLooping')) {\n      symptoms.push(`Alert: ${topAlert} - Pod keeps restarting`);\n    } else if (topAlert.includes('NetworkReceiveErr')) {\n      symptoms.push(`Alert: ${topAlert} - Network packet receiving issues`);\n    } else if (topAlert.includes('DeploymentReplicasMismatch')) {\n      symptoms.push(`Alert: ${topAlert} - Replica count mismatch`);\n    } else {\n      symptoms.push(`Alert: ${topAlert} active`);\n    }\n  } // Closing deployment block\n  \n  return symptoms.length > 0 ? symptoms : [`Issue detected in ${deployment} service`];\n}\n\n// Extract root cause using Stage 2 analysis and other stage data\nfunction extractSimpleRootCause(evidence, allStageData, topAlert, alertCorrelation) {\n  // Priority 1: Use Stage 2 root cause analysis if available\n  if (allStageData.stage2?.root_cause?.identified && allStageData.stage2.root_cause.issue) {\n    const stage2RootCause = allStageData.stage2.root_cause;\n    const confidence = stage2RootCause.confidence ? `(Confidence: ${(stage2RootCause.confidence * 100).toFixed(0)}%)` : '';\n    return `Stage 2 Analizi: ${stage2RootCause.issue} ${confidence}`;\n  }\n  \n  // Priority 2: Use primary diagnosis if available\n  if (allStageData.primaryDiagnosis?.issue) {\n    return `Diagnosis: ${allStageData.primaryDiagnosis.issue}`;\n  }\n  \n  // Priority 3: Use consolidated findings\n  if (allStageData.consolidatedFindings?.primaryDiagnosis?.issue) {\n    return `Analiz Sonucu: ${allStageData.consolidatedFindings.primaryDiagnosis.issue}`;\n  }\n  \n  // Priority 4: KB-aware correlation root cause\n  if (alertCorrelation.hasCorrelation && alertCorrelation.explanation?.tr?.rootCause) {\n    return `Korelasyon Analizi: ${alertCorrelation.explanation.tr.rootCause}`;\n  }\n  \n  // Priority 5: Stage 4 diagnostic summary\n  if (allStageData.stage4?.diagnostic_summary?.confirmed_issues?.length > 0) {\n    const confirmedIssue = allStageData.stage4.diagnostic_summary.confirmed_issues[0];\n    return `Diagnostic Confirmed: ${confirmedIssue.issue}`;\n  }\n  \n  // Fallback to evidence-based analysis with preserved detail\n  if (evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n    const memUsed = evidence.resource_usage?.memory_used || 'N/A';\n    const memLimit = evidence.resource_usage?.memory_limit || 'N/A';\n    return `Memory Limit Exceeded: Pod used ${memUsed}/${memLimit} memory exceeding limit (${evidence.pod_status.last_termination.reason})`;\n  }\n  \n  // Network-based root cause with detail\n  if (topAlert.includes('NetworkReceive')) {\n    return `Network Issues: ${topAlert} - Pods affected due to packet reception errors`;\n  }\n  \n  // Resource pressure with Stage 2 context\n  if (allStageData.stage2?.correlation_matrix?.kubernetes_impact) {\n    const k8sImpact = allStageData.stage2.correlation_matrix.kubernetes_impact;\n    const evictedPods = k8sImpact.evicted_pods || 0;\n    const pendingPods = k8sImpact.pending_pods || 0;\n    return `Kubernetes Resource Pressure: ${evictedPods} pods evicted, ${pendingPods} pods pending`;\n  }\n  \n  // Error log based with preserved detail\n  if (evidence.error_logs?.length > 0) {\n    const firstError = evidence.error_logs[0];\n    return `Container Error: \"${firstError.message}\" (${firstError.timestamp})`;\n  }\n  \n  // Default with alert context\n  return `${topAlert} Problem: System automatic analysis incomplete, manual investigation required`;\n}\n\n// Generate node-specific actions\nfunction generateNodeActions(allStageData, nodeName, namespace, evidence) {\n  const actions = [];\n  \n  // Use Stage 5 remediation plan if available for node alerts\n  const stage5Remediation = allStageData.stage5?.remediation_plan;\n  const immediateActions = stage5Remediation?.immediate_actions || [];\n  \n  // Process immediate actions from Stage 5 for node alerts\n  immediateActions.forEach((stageAction, idx) => {\n    const action = {\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: stageAction.action || `Investigate node ${nodeName} connectivity`,\n      command: stageAction.command || `kubectl describe node ${nodeName}`,\n      time: stageAction.estimated_time || \"5-10 minutes\",\n      risk: stageAction.risk || \"Medium\",\n      success: stageAction.expected_outcome || `Node ${nodeName} returns to Ready state`,\n      kbEnhanced: stageAction.source === \"Alert Knowledge Base\",\n      originalStageAction: true\n    };\n    actions.push(action);\n  });\n  \n  // If no Stage 5 actions, generate default node actions\n  if (actions.length === 0) {\n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: `Check node ${nodeName} status and connectivity`,\n      command: `kubectl describe node ${nodeName} && kubectl get nodes -o wide`,\n      time: \"5-10 minutes\",\n      risk: \"Low\",\n      success: `Node ${nodeName} status and issues identified`,\n      kbEnhanced: false,\n      fallback: true\n    });\n    \n    actions.push({\n      priority: \"üü° SHORT TERM (Within 1 hour)\",\n      action: \"Restart node services if needed\",\n      command: `# Access node and restart kubelet:\\nssh ${nodeName}\\nsudo systemctl restart kubelet`,\n      time: \"10-15 minutes\",\n      risk: \"Medium\",\n      success: \"Node services restarted and operational\",\n      kbEnhanced: false,\n      fallback: true\n    });\n    \n    actions.push({\n      priority: \"üü¢ LONG TERM (1-2 days)\",\n      action: \"Monitor node stability and resource usage\",\n      command: `kubectl top node ${nodeName} && kubectl get events --field-selector involvedObject.name=${nodeName}`,\n      time: \"Ongoing\",\n      risk: \"Low\",\n      success: \"Node stability monitoring in place\",\n      kbEnhanced: false,\n      fallback: true\n    });\n  }\n  \n  return actions;\n}\n\n// Generate pod-specific actions (existing logic)\nfunction generatePodActions(allStageData, deployment, namespace, podName, evidence) {\n  const actions = [];\n  \n  // Use Stage 5 remediation plan if available\n  const stage5Remediation = allStageData.stage5?.remediation_plan;\n  const immediateActions = stage5Remediation?.immediate_actions || [];\n  const shortTermFixes = stage5Remediation?.short_term_fixes || [];\n  const longTermSolutions = stage5Remediation?.long_term_solutions || [];\n  \n  // Process immediate actions from Stage 5\n  immediateActions.forEach((stageAction, idx) => {\n    const action = {\n      priority: \"üî¥ IMMEDIATE (Must be done now)\",\n      action: stageAction.action || `Fix ${deployment} service`,\n      command: stageAction.command || `kubectl describe pod ${podName} -n ${namespace}`,\n      time: stageAction.estimated_time || \"2-5 minutes\",\n      risk: stageAction.risk || \"Medium\",\n      success: stageAction.expected_outcome || `${deployment} service runs stable`,\n      kbEnhanced: stageAction.source === \"Alert Knowledge Base\",\n      originalStageAction: true\n    };\n    actions.push(action);\n  });\n  \n  // Process short-term fixes from Stage 5\n  shortTermFixes.forEach((stageFix, idx) => {\n    const action = {\n      priority: \"üü° SHORT TERM (24-48 hours)\",\n      action: stageFix.action || `Optimize ${deployment} configuration`,\n      command: stageFix.command || stageFix.details || \"Coordinate with development team\",\n      time: stageFix.timeline || \"1-2 days\",\n      risk: \"Low\",\n      success: `${stageFix.expected_outcome || 'Issue permanently resolved'}`,\n      originalStageAction: true\n    };\n    actions.push(action);\n  });\n  \n  // Process long-term solutions from Stage 5\n  longTermSolutions.forEach((stageSolution, idx) => {\n    const action = {\n      priority: \"üü¢ LONG TERM (1-2 weeks)\",\n      action: stageSolution.action || `Implement permanent solution for ${deployment}`,\n      command: stageSolution.command || stageSolution.details || \"Architecture review required\",\n      time: stageSolution.timeline || \"1-2 weeks\",\n      risk: stageSolution.risk || \"Medium\",\n      success: stageSolution.expected_outcome || `${deployment} optimized and runs stable`,\n      originalStageAction: true\n    };\n    actions.push(action);\n  });\n  \n  // If no Stage 5 actions available, provide evidence-based fallback\n  if (actions.length === 0) {\n    console.log(\"‚ö†Ô∏è No Stage 5 remediation found, using evidence-based fallback\");\n    \n    // Evidence-based immediate action\n    let fallbackAction = \"Restart service\";\n    let fallbackCommand = `kubectl delete pod ${podName} -n ${namespace}`;\n    \n    if (evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n      fallbackAction = \"Memory limit exceeded - restart pod and monitor memory usage\";\n      fallbackCommand = `kubectl delete pod ${podName} -n ${namespace} && kubectl top pods -n ${namespace} | grep ${deployment}`;\n    }\n    \n    actions.push({\n      priority: \"üî¥ IMMEDIATE (Execute NOW)\",\n      action: fallbackAction,\n      command: fallbackCommand,\n      time: \"2-5 minutes\",\n      risk: \"Low\",\n      success: `${deployment} service restarts`,\n      originalStageAction: false,\n      fallback: true\n    });\n  }\n  \n  return actions;\n}\n\n// Context-aware action generation wrapper - uses proper stage data with KB enhancement\nfunction generateOncallActions(allStageData, deployment, namespace, resourceName, evidence, alertType, nodeName) {\n  // Try to get KB-based actions first\n  const topAlert = alertType === 'NODE' ? \n    (allStageData.stage1?.alerts?.top_alerts?.[0] || 'KubeNodeNotReady') :\n    (allStageData.stage1?.alerts?.top_alerts?.[0] || 'KubePodCrashLooping');\n  \n  const kbEntry = alertKnowledgeBase[topAlert];\n  const kbActions = [];\n  \n  if (kbEntry) {\n    // Generate KB-enhanced actions from immediateActions\n    if (kbEntry.immediateActions && kbEntry.immediateActions.length > 0) {\n      kbEntry.immediateActions.slice(0, 2).forEach((action, idx) => {\n        // Replace placeholders in KB actions\n        let command = action;\n        if (command.includes('{namespace}')) command = command.replace(/{namespace}/g, namespace);\n        if (command.includes('{deployment}')) command = command.replace(/{deployment}/g, deployment || resourceName);\n        if (command.includes('{pod}')) command = command.replace(/{pod}/g, resourceName);\n        if (command.includes('{node}')) command = command.replace(/{node}/g, nodeName);\n        \n        kbActions.push({\n          priority: idx === 0 ? \"üî¥ IMMEDIATE\" : \"üü† HIGH\",\n          action: action,\n          command: command,\n          risk: kbEntry.severity === 'critical' ? 'high' : 'medium',\n          time: idx === 0 ? \"1-2 minutes\" : \"5-10 minutes\",\n          success: `${topAlert} issue resolved`,\n          kbEnhanced: true,\n          source: \"Knowledge Base\",\n          confidence: 0.95\n        });\n      });\n    }\n    \n    // Add troubleshooting steps as diagnostic actions\n    if (kbEntry.troubleshootingSteps && kbEntry.troubleshootingSteps.length > 0) {\n      kbEntry.troubleshootingSteps.slice(0, 1).forEach(step => {\n        let command = step;\n        if (command.includes('{namespace}')) command = command.replace(/{namespace}/g, namespace);\n        if (command.includes('{deployment}')) command = command.replace(/{deployment}/g, deployment || resourceName);\n        \n        kbActions.push({\n          priority: \"üîµ DIAGNOSTIC\",\n          action: \"KB-recommended diagnostic check\",\n          command: command,\n          risk: \"low\",\n          time: \"1 minute\",\n          success: \"Diagnostic information gathered\",\n          kbEnhanced: true,\n          source: \"Knowledge Base Troubleshooting\"\n        });\n      });\n    }\n  }\n  \n  // If we have KB actions, prioritize them\n  if (kbActions.length > 0) {\n    // Merge with existing logic but prioritize KB actions\n    const existingActions = generateOncallActionsOriginal(allStageData, deployment, namespace, resourceName, evidence, alertType, nodeName);\n    return [...kbActions, ...existingActions.slice(0, Math.max(0, 3 - kbActions.length))];\n  }\n  \n  // Fall back to original logic if no KB actions\n  return generateOncallActionsOriginal(allStageData, deployment, namespace, resourceName, evidence, alertType, nodeName);\n}\n\n// Original action generation logic (renamed)\nfunction generateOncallActionsOriginal(allStageData, deployment, namespace, resourceName, evidence, alertType, nodeName) {\n  if (alertType === 'NODE') {\n    // For NODE alerts, generate node-specific actions and ignore POD actions from stages\n    return [\n      {\n        action: \"Check node status and conditions\",\n        command: `kubectl describe node ${nodeName}`,\n        risk: \"low\",\n        estimated_time: \"1-2 minutes\",\n        expected_outcome: \"Identify node readiness issues and resource constraints\",\n        kb_enhanced: false,\n        kb_guidance: null\n      },\n      {\n        action: \"Check node resource usage\",\n        command: `kubectl top node ${nodeName}`,\n        risk: \"low\",\n        estimated_time: \"30 seconds\",\n        expected_outcome: \"View current CPU and memory usage on the node\",\n        kb_enhanced: false,\n        kb_guidance: null\n      },\n      {\n        action: \"Check pods on the affected node\",\n        command: `kubectl get pods --all-namespaces --field-selector spec.nodeName=${nodeName}`,\n        risk: \"low\",\n        estimated_time: \"1 minute\",\n        expected_outcome: \"List all pods running on the problematic node\",\n        kb_enhanced: false,\n        kb_guidance: null\n      }\n    ];\n  } else {\n    // SMART ENGINE: Root Cause Analysis for POD alerts\n    const rootCauseAnalysis = analyzeRootCause(allStageData, evidence, alertType);\n    let smartActions = [];\n    \n    console.log(\"===== SMART ENGINE DEBUG =====\");\n    console.log(\"Root Cause Analysis:\", rootCauseAnalysis.primaryCause);\n    console.log(\"Evidence OOMKilled:\", evidence?.pod_status?.last_termination?.reason);\n    console.log(\"Evidence Exit Code:\", evidence?.pod_status?.last_termination?.exit_code);\n    console.log(\"Confidence:\", rootCauseAnalysis.confidence);\n    console.log(\"Resource Metrics:\", rootCauseAnalysis.resourceMetrics);\n    console.log(\"==============================\");\n    \n    // Generate smart actions based on root cause analysis\n    if (rootCauseAnalysis.primaryCause === 'memory_exhaustion') {\n      console.log(\"üî• MEMORY EXHAUSTION DETECTED - Generating Memory Actions\");\n      smartActions = generateMemoryActions(deployment, namespace, resourceName, rootCauseAnalysis.resourceMetrics, allStageData);\n      console.log(\"Generated Memory Actions Count:\", smartActions.length);\n    } else if (rootCauseAnalysis.primaryCause === 'cpu_throttling') {\n      smartActions = generateCPUActions(deployment, namespace, resourceName, rootCauseAnalysis.resourceMetrics, allStageData);\n    } else if (rootCauseAnalysis.primaryCause === 'storage_issue') {\n      smartActions = generateStorageActions(deployment, namespace, resourceName, allStageData);\n    } else if (rootCauseAnalysis.primaryCause === 'network_connectivity') {\n      smartActions = generateNetworkActions(deployment, namespace, resourceName, allStageData);\n    }\n    \n    // If Smart Engine found specific actions, use them\n    if (smartActions.length > 0) {\n      return smartActions;\n    }\n    \n    // For POD alerts, use Stage 5 remediation plan if available\n    const stage5Actions = allStageData.stage5?.remediation_plan?.immediate_actions || [];\n    if (stage5Actions.length > 0) {\n      return stage5Actions.map(action => ({\n        action: action.action || \"Execute remediation step\",\n        command: action.command || `kubectl rollout undo deployment/${deployment} -n ${namespace}`,\n        risk: action.risk || \"low\",\n        estimated_time: action.estimated_time || \"2-5 minutes\",\n        expected_outcome: action.expected_outcome || \"Restore service stability\",\n        kb_enhanced: false,\n        kb_guidance: null\n      }));\n    }\n    \n    // Fallback to POD actions if no Stage 5 data\n    return generatePodActions(allStageData, deployment, namespace, resourceName, evidence);\n  }\n}\n\n// Generate node-specific success criteria\nfunction generateNodeSuccessCriteria(nodeName, namespace, evidence, allStageData) {\n  const criteria = [];\n  \n  // Node status criteria\n  criteria.push({\n    check: \"Check node status\",\n    command: `kubectl get nodes ${nodeName} -o wide`,\n    expected: \"STATUS: Ready (node should be in Ready state)\"\n  });\n  \n  // Node conditions criteria\n  criteria.push({\n    check: \"Check node conditions\",\n    command: `kubectl describe node ${nodeName} | grep Conditions -A 10`,\n    expected: \"Ready=True, OutOfDisk=False, MemoryPressure=False, DiskPressure=False\"\n  });\n  \n  // Affected pods criteria\n  if (evidence.affected_pods?.pending > 0) {\n    criteria.push({\n      check: \"Check pending pods\",\n      command: `kubectl get pods --all-namespaces --field-selector spec.nodeName=${nodeName}`,\n      expected: \"All pods on node should be Running or Succeeded (no Pending pods)\"\n    });\n  }\n  \n  // Node resource criteria\n  criteria.push({\n    check: \"Check node resources\",\n    command: `kubectl top node ${nodeName}`,\n    expected: \"Resource usage should be within normal limits (CPU < 80%, Memory < 80%)\"\n  });\n  \n  // Recent events criteria\n  criteria.push({\n    check: \"Check node events\",\n    command: `kubectl get events --field-selector involvedObject.name=${nodeName} --sort-by='.lastTimestamp' | tail -5`,\n    expected: \"No critical Warning or Error events related to node readiness\"\n  });\n  \n  return criteria;\n}\n\n// Generate pod-specific success criteria (existing logic)\nfunction generatePodSuccessCriteria(deployment, namespace, evidence, allStageData) {\n  const criteria = [];\n  \n  // Pod health criteria with specific evidence-based expectations\n  const podHealthCheck = {\n    check: \"Check pod status\",\n    command: `kubectl get pods -n ${namespace} | grep ${deployment}`,\n    expected: \"STATUS: Running (all pods in running state)\"\n  };\n  \n  // Enhanced expectations based on evidence\n  if (evidence.pod_status?.phase === 'CrashLoopBackOff') {\n    podHealthCheck.expected = `STATUS: Running (not ${evidence.pod_status.phase}, stable running state)`;\n  }\n  criteria.push(podHealthCheck);\n  \n  // Memory criteria with actual usage thresholds\n  if (evidence.resource_usage?.memory_used && evidence.resource_usage?.memory_limit) {\n    const memUsed = evidence.resource_usage.memory_used;\n    const memLimit = evidence.resource_usage.memory_limit;\n    criteria.push({\n      check: \"Check memory usage\",\n      command: `kubectl top pods -n ${namespace} | grep ${deployment}`,\n      expected: `Memory usage should be less than 80% of ${memLimit} (currently using ${memUsed})`\n    });\n  } else if (evidence.pod_status?.last_termination?.reason === 'OOMKilled') {\n    criteria.push({\n      check: \"Check memory usage\", \n      command: `kubectl top pods -n ${namespace} | grep ${deployment}`,\n      expected: \"Memory usage should be below 80% (to prevent OOMKilled)\"\n    });\n  }\n  \n  // CPU criteria if available\n  if (evidence.resource_usage?.cpu_used) {\n    criteria.push({\n      check: \"Check CPU usage\",\n      command: `kubectl top pods -n ${namespace} | grep ${deployment}`,\n      expected: `CPU usage should be stable (currently ${evidence.resource_usage.cpu_used})`\n    });\n  }\n  \n  // Service response criteria with enhanced check\n  criteria.push({\n    check: \"Check service response\",\n    command: `kubectl get svc -n ${namespace} | grep ${deployment} && curl -s -o /dev/null -w \"%{http_code}\" http://${deployment}-service/health`,\n    expected: \"Service available and 200 OK response received\"\n  });\n  \n  // Restart criteria with current restart count context\n  const restartCount = evidence.pod_status?.restart_count || 0;\n  criteria.push({\n    check: \"Check for restarts\",\n    command: `kubectl describe pod -n ${namespace} -l app=${deployment} | grep \"Restart Count\"`,\n    expected: `Restart Count: ${restartCount} (should not increase, no new restarts)`\n  });\n  \n  // Event criteria to ensure no error events\n  criteria.push({\n    check: \"Check Kubernetes events\",\n    command: `kubectl get events -n ${namespace} --sort-by='.lastTimestamp' | grep ${deployment} | tail -5`,\n    expected: \"No Warning or Error events should be present\"\n  });\n  \n  // Stage 5 specific success metrics if available\n  if (allStageData.stage5?.success_metrics) {\n    const stage5Metrics = allStageData.stage5.success_metrics;\n    \n    // Process each metric type (immediate, short_term, long_term)\n    Object.entries(stage5Metrics).forEach(([metric, metricData]) => {\n      // Skip non-metric fields\n      if (metric === 'category_enhanced' || metric === 'alert_category') return;\n      \n      if (metricData && typeof metricData === 'object' && metricData.commands && metricData.expected) {\n        // New structure with commands and expected arrays\n        metricData.commands.forEach((command, index) => {\n          const expectedResult = Array.isArray(metricData.expected) \n            ? metricData.expected.join(',') \n            : metricData.expected;\n          \n          criteria.push({\n            check: `Stage 5 Success Metric: ${metric}`,\n            command: command,\n            expected: expectedResult\n          });\n        });\n      } else if (Array.isArray(metricData)) {\n        // Legacy structure (array of expected results)\n        criteria.push({\n          check: `Stage 5 Success Metric: ${metric}`,\n          command: `kubectl get pods -n ${namespace} | grep ${deployment}`,\n          expected: metricData.join(',')\n        });\n      } else {\n        // Fallback for other formats\n        criteria.push({\n          check: `Stage 5 Success Metric: ${metric}`,\n          command: `kubectl get pods -n ${namespace} | grep ${deployment}`,\n          expected: `${metricData}`\n        });\n      }\n    });\n  }\n  \n  return criteria;\n}\n\n// Context-aware success criteria wrapper\nfunction generateSuccessCriteria(deployment, namespace, evidence, allStageData, alertType, nodeName) {\n  if (alertType === 'NODE') {\n    return generateNodeSuccessCriteria(nodeName, namespace, evidence, allStageData);\n  } else {\n    return generatePodSuccessCriteria(deployment, namespace, evidence, allStageData);\n  }\n}\n\n// Generate ONCALL-FRIENDLY Jira Ticket\nfunction generateOncallFriendlyTicket(evidence, allStageData, podName, deployment, namespace, topAlert, alertCorrelation, masterContext, alertType, nodeName) {\n  const symptoms = extractBusinessSymptoms(evidence, podName, deployment, topAlert, allStageData);\n  const rootCause = extractSimpleRootCause(evidence, allStageData, topAlert, alertCorrelation);\n  const actions = generateOncallActions(allStageData, deployment, namespace, podName, evidence, alertType, nodeName);\n  const successCriteria = generateSuccessCriteria(deployment, namespace, evidence, allStageData, alertType, nodeName);\n  \n  // Stage 1: Quick Findings\n  const quickFindings = allStageData.stage1?.quick_findings || [];\n  const quickFindingsSection = quickFindings.length > 0 ? \n    `\\n## ‚ö° QUICK FINDINGS\\n${quickFindings.map(finding => `- ${finding}`).join('\\n')}\\n` : '';\n  \n  // Stage 2: Kubernetes Impact\n  const k8sImpact = allStageData.stage2?.correlation_matrix?.kubernetes_impact;\n  const k8sImpactSection = k8sImpact ? `\n## üåê KUBERNETES IMPACT\n- ‚ùå Evicted Pods: ${k8sImpact.evicted_pods || 0}\n- ‚è≥ Pending Pods: ${k8sImpact.pending_pods || 0}\n- üö´ Failed Schedules: ${k8sImpact.failed_schedules || 0}\n` : '';\n  \n  // Stage 2: Affected Services - Context-aware for node vs pod alerts\n  let affectedServicesSection = '';\n  if (alertType === 'NODE') {\n    // For node alerts, show affected pods on the node\n    const nodeEvidence = evidence.node_info || {};\n    const affectedPods = nodeEvidence.affected_pods || [];\n    if (affectedPods.length > 0) {\n      affectedServicesSection = `\n## üå≥ AFFECTED PODS ON NODE\nAffected Node: ${nodeName || 'Unknown'}\n${affectedPods.map(pod => `‚îî‚îÄ ${pod}`).join('\\n')}\n`;\n    }\n  } else {\n    // For pod/service alerts, show affected services\n    const affectedServices = allStageData.stage2?.correlation_matrix?.affected_services || \n                             allStageData.stage2?.affected_services || [];\n    if (affectedServices.length > 0) {\n      affectedServicesSection = `\n## üå≥ AFFECTED SERVICES\nPrimary Service: ${deployment}\n${affectedServices.map(service => `‚îî‚îÄ ${service}`).join('\\n')}\n`;\n    }\n  }\n  \n  // Stage 3: SLO Status\n  const sloImpact = allStageData.stage3?.slo_impact;\n  const sloSection = sloImpact?.availability_slo ? `\n## üìä SERVICE LEVEL STATUS\n- Current SLO: ${sloImpact.availability_slo.current}\n- Target: ${sloImpact.availability_slo.target}\n- Error Budget Usage: ${sloImpact.availability_slo.error_budget_used || '0%'}\n- Status: ${sloImpact.availability_slo.status === 'green' ? '‚úÖ Normal' : sloImpact.availability_slo.status === 'yellow' ? '‚ö†Ô∏è Warning' : 'üî¥ Critical'}\n` : '';\n  \n  // Stage 3: Active Alert Durations\n  const activeAlerts = allStageData.stage3?.active_alerts || [];\n  const alertDurationSection = activeAlerts.length > 0 ? `\n## ‚è±Ô∏è ACTIVE ALERT DURATIONS\n${activeAlerts.map(alert => \n  `- ${alert.name}: Active for ${alert.duration || 'N/A'} (${alert.severity || 'unknown'})`\n).join('\\n')}\n` : '';\n  \n  // Stage 4: Recent Changes\n  const recentChanges = allStageData.stage4?.enriched_context?.recent_changes || [];\n  const recentChangesSection = recentChanges.length > 0 ? `\n## üìù RECENT CHANGES\n${recentChanges.map(change => \n  `- ${change.time}: ${change.change} (${change.type})`\n).join('\\n')}\n` : '';\n  \n  // Stage 4: Dependencies\n  const dependencies = allStageData.stage4?.enriched_context?.dependencies;\n  const dependenciesSection = (Array.isArray(dependencies?.downstream) && dependencies.downstream.length > 0) ? `\n## üîó DEPENDENCIES\n${dependencies.downstream.map(service => `- Downstream: ${service}`).join('\\n')}\n${(Array.isArray(dependencies.upstream) && dependencies.upstream.length > 0) ? dependencies.upstream.map(service => `- Upstream: ${service}`).join('\\n') : ''}\n` : '';\n  \n  // Stage 5: Risk Assessment\n  const riskAssessment = allStageData.stage5?.risk_assessment;\n  const riskSection = riskAssessment ? `\n## ‚ö†Ô∏è RISK ASSESSMENT\n- **Overall Risk Level:** ${riskAssessment.overall_risk || 'Unknown'}\n${riskAssessment.factors?.length > 0 ? '**Risk Factors:**\\n' + riskAssessment.factors.map(factor => `  - ${factor}`).join('\\n') : ''}\n${riskAssessment.mitigation_steps?.length > 0 ? '**Mitigation Steps:**\\n' + riskAssessment.mitigation_steps.map(step => `  - ${step}`).join('\\n') : ''}\n` : '';\n  \n  // Stage 6: Prevention Actions\n  const preventionActions = allStageData.stage6?.prevention_actions || [];\n  const preventionSection = preventionActions.length > 0 ? `\n## üõ°Ô∏è PREVENTION ACTIONS (Post-Incident)\n${preventionActions.filter(action => action.status !== 'completed').map(action => \n  `- ${action.action} (${action.timeline || 'N/A'})`\n).join('\\n')}\n` : '';\n  \n  // Stage 3 KB Matches Integration - Enhanced with KB Node Data\n  const kbMatches = allStageData.stage3?.knowledge_base_matches || [];\n  const directKBEntry = alertKnowledgeBase[topAlert]; // Direct KB lookup for current alert\n  \n  // Combine KB matches from Stage 3 and direct KB node lookup\n  const kbGuidance = [];\n  if (directKBEntry) {\n    // Add guidance from direct KB entry\n    if (directKBEntry.troubleshootingSteps) kbGuidance.push(...directKBEntry.troubleshootingSteps.slice(0, 2));\n    if (directKBEntry.commonCauses) kbGuidance.push(...directKBEntry.commonCauses.slice(0, 2));\n  }\n  // Add guidance from Stage 3 matches\n  if (kbMatches.length > 0) {\n    kbMatches.forEach(kb => {\n      const steps = kb.troubleshootingSteps || kb.commonCauses || [kb.alert_name];\n      kbGuidance.push(...steps.slice(0, 2));\n    });\n  }\n  \n  // Generate KB info with category and urgency\n  const kbInfo = (kbGuidance.length > 0 || kbAlertCategory !== 'UNKNOWN') ? \n    `\\n\\n**üìö Knowledge Base Guidance:**\\n` +\n    `**Alert Category:** ${kbAlertCategory} | **Urgency:** ${kbUrgencyLevel} | **Cascade Risk:** ${kbCascadeRisk}\\n` +\n    (kbGuidance.length > 0 ? `**Troubleshooting Steps:**\\n${kbGuidance.slice(0,5).map(guidance => `- ${guidance}`).join('\\n')}` : '') +\n    (directKBEntry ? `\\n**Confidence Boost:** +10% (KB Match Found)` : '') : '';\n  \n  // Generate dynamic title\n  const dynamicTitle = getOncallTitle(topAlert, deployment, namespace, podName, evidence, nodeName);\n  \n  return `\n<div style=\"font-family: Arial, sans-serif; max-width: 800px;\">\n  <div style=\"background: linear-gradient(135deg, #ff9800 0%, #f57c00 100%); color: white; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n    <h1 style=\"margin: 0; font-size: 24px;\">${dynamicTitle}</h1>\n  </div>\n  \n  ${quickFindingsSection ? `<div style=\"border: 1px solid #2196f3; border-radius: 6px; margin: 10px 0; background: #e3f2fd; padding: 15px;\"><h3 style=\"color: #1976d2; margin-top: 0;\">‚ö° QUICK FINDINGS</h3>${quickFindings.map(finding => `<div style=\"margin: 5px 0;\">‚Ä¢ ${finding}</div>`).join('')}</div>` : ''}\n  \n  <div style=\"border: 2px solid #d32f2f; border-radius: 8px; margin: 15px 0; background: #ffebee;\">\n    <div style=\"background: #d32f2f; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üö® SYMPTOMS (What's Happening)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      ${symptoms.map(symptom => `<div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ ${symptom}</div>`).join('')}\n    </div>\n  </div>\n  \n  <div style=\"border: 2px solid #ff9800; border-radius: 8px; margin: 15px 0; background: #fff3e0;\">\n    <div style=\"background: #ff9800; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üîç ROOT CAUSE (Why It's Happening)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <p style=\"margin: 0 0 10px 0;\"><strong>Root Cause:</strong> ${rootCause}</p>\n\n      <div style=\"background: #f5f5f5; padding: 10px; border-radius: 4px; margin-top: 10px;\">\n        <strong>Evidence:</strong>\n        <div style=\"margin-top: 8px;\">\n          ‚Ä¢ <strong>Pod Status:</strong> <code>${evidence.pod_status?.phase || 'Unknown'}</code><br/>\n          ‚Ä¢ <strong>Last Error:</strong> ${evidence.pod_status?.last_termination?.reason || 'None'} (Exit Code: ${evidence.pod_status?.last_termination?.exit_code || 'N/A'})<br/>\n          ‚Ä¢ <strong>Memory Usage:</strong> ${evidence.resource_usage?.memory_used || 'N/A'} / ${evidence.resource_usage?.memory_limit || 'N/A'}<br/>\n          ${evidence.resource_usage?.cpu_used ? `‚Ä¢ <strong>CPU Usage:</strong> ${evidence.resource_usage.cpu_used}<br/>` : ''}\n          ${evidence.error_logs?.length > 0 ? `‚Ä¢ <strong>Latest Error:</strong> ${evidence.error_logs[0].message}<br/>` : ''}\n          ${evidence.events?.length > 0 ? `‚Ä¢ <strong>Latest Event:</strong> ${evidence.events[0].message} (${evidence.events[0].type})<br/>` : ''}\n        </div>\n        ${kbInfo}\n      </div>\n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #4caf50; border-radius: 8px; margin: 15px 0; background: #e8f5e8;\">\n    <div style=\"background: #4caf50; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      ‚úÖ SOLUTION (What To Do)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      ${actions.map((action, idx) => `\n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 15px 0; padding: 15px; background: ${idx % 2 === 0 ? '#fafafa' : 'white'};\">\n          <h4 style=\"margin: 0 0 10px 0; color: #d32f2f;\">${idx + 1}. ${action.priority} ${action.kbEnhanced ? 'üìö' : ''}</h4>\n          <p style=\"margin: 10px 0;\"><strong>Action Required:</strong> ${action.action}${action.originalStageAction ? ' <span style=\"color: #1976d2;\">(Stage 5 Analysis)</span>' : ''}${action.fallback ? ' <span style=\"color: #ff9800;\">(Fallback Solution)</span>' : ''}</p>\n          <p style=\"margin: 10px 0;\"><strong>Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>${action.command}</code>\n          </div>\n          <div style=\"margin-top: 10px;\">\n            <span style=\"margin-right: 15px;\">‚è±Ô∏è <strong>Duration:</strong> ${action.time}</span>\n            <span style=\"margin-right: 15px;\">‚ö†Ô∏è <strong>Risk:</strong> ${action.risk}</span>\n            <div style=\"margin-top: 5px;\">üéØ <strong>Expected Result:</strong> ${action.success}</div>\n          </div>\n        </div>\n        ${action.kbEnhanced ? '<div style=\"color: #4caf50; font-style: italic; margin-top: 10px;\">üìö KB Guidance: Knowledge Base data utilized</div>' : ''}\n      `).join('')}\n    </div>\n  </div>\n  \n  <div style=\"border: 2px solid #2196f3; border-radius: 8px; margin: 15px 0; background: #e3f2fd;\">\n    <div style=\"background: #2196f3; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üìã VERIFY SOLUTION EFFECTIVENESS\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      ${successCriteria.map((criteria, idx) => `\n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 15px; background: ${idx % 2 === 0 ? '#f9f9f9' : 'white'};\">\n          <h4 style=\"margin: 0 0 10px 0; color: #2196f3;\">${idx + 1}. ${criteria.check}</h4>\n          <p style=\"margin: 10px 0;\"><strong>Run Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>${criteria.command}</code>\n          </div>\n          <p style=\"margin: 10px 0 0 0;\"><strong>Expected Result:</strong> ${criteria.expected}</p>\n        </div>\n      `).join('')}\n    </div>\n  </div>\n  \n  ${recentChangesSection}${dependenciesSection}${riskSection}\n  \n  <div style=\"border: 2px solid #607d8b; border-radius: 8px; margin: 15px 0; background: #eceff1;\">\n    <div style=\"background: #607d8b; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üìû SUPPORT INFORMATION\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n        <tr><td style=\"font-weight: bold; width: 150px; padding: 5px;\">Incident ID:</td><td style=\"padding: 5px; font-family: monospace;\">${masterContext.contextId}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Timestamp:</td><td style=\"padding: 5px;\">${new Date().toLocaleString('en-US')}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Namespace:</td><td style=\"padding: 5px; font-family: monospace;\">${namespace}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Pod:</td><td style=\"padding: 5px; font-family: monospace;\">${podName}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Deployment:</td><td style=\"padding: 5px; font-family: monospace;\">${deployment}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Cluster Status:</td><td style=\"padding: 5px;\">${allStageData.stage1?.overall_status || 'Unknown'}</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Total Alerts:</td><td style=\"padding: 5px;\">${allStageData.stage1?.alerts?.total || 0} (${allStageData.stage1?.alerts?.critical || 0} critical)</td></tr>\n      </table>\n      <div style=\"margin-top: 15px; padding: 10px; background: #fff3e0; border-radius: 4px; border-left: 4px solid #ff9800;\">\n        <strong>If issue persists:</strong> Escalate to Development Team\n      </div>\n    </div>\n  </div>\n  \n  ${preventionSection}\n  \n  <div style=\"text-align: center; margin-top: 20px; padding: 10px; background: #f5f5f5; border-radius: 6px; font-size: 12px; color: #666;\">\n    <div>This report was auto-generated | ${new Date().toLocaleString('en-US')}</div>\n    <div>Stages Completed: ${Object.keys(allStageData).filter(k => allStageData[k]).length}/6</div>\n  </div>\n</div>\n`;\n}\n\n// ENHANCED JIRA TICKET WITH KB-AWARE CORRELATION (HTML FORMAT)\nconst jiraTicketHtml = `\n<div style=\"border: 2px solid #d32f2f; border-radius: 8px; margin: 10px 0; background: #ffebee;\">\n  <div style=\"background: #d32f2f; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n    üö® INCIDENT SUMMARY\n  </div>\n  <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n    <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n      <tr><td style=\"font-weight: bold; width: 130px; padding: 5px;\">Alert:</td><td style=\"padding: 5px;\">${topAlert}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Severity:</td><td style=\"padding: 5px;\"><span style=\"color: #d32f2f; font-weight: bold;\">${issueSeverity === 'critical' ? 'üî¥ CRITICAL' : issueSeverity === 'high' ? 'üü† HIGH' : 'üü° WARNING'}</span></td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Service:</td><td style=\"padding: 5px;\">${alertType === 'NODE' ? `Node ${nodeName}` : deployment}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Namespace:</td><td style=\"padding: 5px;\">${namespace}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Detection:</td><td style=\"padding: 5px;\">${alertStartDate}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Duration:</td><td style=\"padding: 5px;\">${durationMinutes} minutes</td></tr>\n    </table>\n  </div>\n</div>\n\n<h2 style=\"color: #1976d2; margin-top: 20px;\">üìä INCIDENT DETAILS</h2>\n\n<div style=\"border: 1px solid #e0e0e0; border-radius: 6px; margin: 10px 0; overflow: hidden;\">\n  <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n    <tr style=\"background: #f5f5f5;\">\n      <td style=\"padding: 10px; font-weight: bold; border-bottom: 1px solid #e0e0e0;\">Field</td>\n      <td style=\"padding: 10px; font-weight: bold; border-bottom: 1px solid #e0e0e0;\">Details</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">Alert Type</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">${topAlert}</td>\n    </tr>\n    <tr style=\"background: #fafafa;\">\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">Pod Name</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0; font-family: monospace;\">${podName}</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">Deployment</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0; font-family: monospace;\">${deployment}</td>\n    </tr>\n    <tr style=\"background: #fafafa;\">\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">Namespace</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0; font-family: monospace;\">${namespace}</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">Context ID</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0; font-family: monospace; color: #666;\">${masterContext.contextId}</td>\n    </tr>\n    <tr style=\"background: #fafafa;\">\n      <td style=\"padding: 8px;\">KB Integration</td>\n      <td style=\"padding: 8px;\">${originalAlertCategory?.hasKBEntry || finalAlertCategory?.hasKBEntry ? '<span style=\"color: #4caf50;\">‚úÖ KB Data Available</span>' : '<span style=\"color: #f44336;\">‚ùå No KB Data</span>'}</td>\n    </tr>\n    ${alertCorrelation.hasCorrelation ? `<tr><td style=\"padding: 8px; border-top: 1px solid #f0f0f0;\">Original Alert</td><td style=\"padding: 8px; border-top: 1px solid #f0f0f0;\">üîç ${originalAlert} ${originalAlertCategory?.hasKBEntry ? 'üìö' : ''}</td></tr>` : ''}\n    ${alertCorrelation.hasCorrelation ? `<tr style=\"background: #fafafa;\"><td style=\"padding: 8px;\">Correlation</td><td style=\"padding: 8px;\">${alertCorrelation.kbEnhanced ? 'üß† KB-Enhanced' : 'üîÑ Pattern-Based'} ${alertCorrelation.correlationType} (${(alertCorrelation.confidence * 100).toFixed(0)}% confidence)</td></tr>` : ''}\n  </table>\n</div>\n\n${alertCorrelation.hasCorrelation ? `\n<div style=\"border: 2px solid #1976d2; border-radius: 8px; margin: 15px 0; background: #e3f2fd;\">\n  <div style=\"background: #1976d2; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n    üß† CORRELATION ANALYSIS\n  </div>\n  <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n    <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n      <tr><td style=\"font-weight: bold; width: 120px; padding: 5px;\">Pattern:</td><td style=\"padding: 5px;\">${alertCorrelation.correlationType}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Confidence:</td><td style=\"padding: 5px;\"><span style=\"font-weight: bold; color: #1976d2;\">${(alertCorrelation.confidence * 100).toFixed(0)}%</span></td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Actionability:</td><td style=\"padding: 5px;\"><span style=\"font-weight: bold; color: ${alertCorrelation.actionabilityScore > 0.8 ? '#4caf50' : '#ff9800'};\">${(alertCorrelation.actionabilityScore * 100).toFixed(0)}% - ${alertCorrelation.actionabilityScore > 0.8 ? 'Highly Actionable' : 'Moderately Actionable'}</span></td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">KB Enhanced:</td><td style=\"padding: 5px;\">${alertCorrelation.kbEnhanced ? '<span style=\"color: #4caf50;\">‚úÖ Yes</span>' : '<span style=\"color: #f44336;\">‚ùå No</span>'}</td></tr>\n    </table>\n  </div>\n</div>\n\n### üìä ROOT CAUSE ANALYSIS\n**Primary Issue**: ${alertCorrelation.explanation?.en?.rootCause || 'Infrastructure-level issue causing cascading failures'}\n\n**Analysis Details**:\n- üö® **Original Alert**: ${originalAlert} ${originalAlertCategory ? `(${originalAlertCategory.category} - ${originalAlertCategory.priority}${originalAlertCategory.hasKBEntry ? ' üìö' : ''})` : ''}\n- üéØ **Final Alert**: ${topAlert} (${finalAlertCategory.category} - Actionability: ${(alertCorrelation.actionabilityScore * 100).toFixed(0)}%${finalAlertCategory.hasKBEntry ? ' üìö' : ''})\n- üîÑ **Correlation Pattern**: ${alertCorrelation.correlationType}\n- üìä **Correlation Confidence**: ${(alertCorrelation.confidence * 100).toFixed(0)}%\n- üß† **KB Enhancement**: ${alertCorrelation.kbEnhanced ? 'KB data integrated' : 'Pattern-based analysis'}\n\n### üéØ RESOLUTION STRATEGY\n**Approach**: ${alertCorrelation.explanation?.en?.solution || 'Multi-phase approach required'}\n\n<div style=\"border: 2px solid #d32f2f; border-radius: 8px; margin: 15px 0; background: #ffebee;\">\n  <div style=\"background: #d32f2f; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n    üî• PHASE 1 - IMMEDIATE SERVICE RECOVERY\n  </div>\n  <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n    <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n      <tr><td style=\"font-weight: bold; width: 150px; padding: 5px;\">Actionability Score:</td><td style=\"padding: 5px;\"><span style=\"font-weight: bold; color: ${alertCorrelation.actionabilityScore > 0.8 ? '#4caf50' : '#ff9800'};\">${(alertCorrelation.actionabilityScore * 100).toFixed(0)}% - ${alertCorrelation.actionabilityScore > 0.8 ? 'Highly Actionable' : 'Moderately Actionable'}</span></td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Alert Priority:</td><td style=\"padding: 5px;\">${finalAlertCategory.priority} level remediation</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">KB Guidance:</td><td style=\"padding: 5px;\">${finalAlertCategory.hasKBEntry ? '<span style=\"color: #4caf50;\">üìö Available</span>' : 'Pattern-based approach'}</td></tr>\n    </table>\n  </div>\n</div>\n</div>\n\n<div style=\"border: 2px solid #f57c00; border-radius: 8px; margin: 15px 0; background: #fff3e0;\">\n  <div style=\"background: #f57c00; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n    üîß PHASE 2 - ROOT CAUSE RESOLUTION\n  </div>\n  <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n    <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n      <tr><td style=\"font-weight: bold; width: 120px; padding: 5px;\">Target:</td><td style=\"padding: 5px;\">${originalAlert} (${originalAlertCategory?.category} level)</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">Priority Level:</td><td style=\"padding: 5px;\">${originalAlertCategory?.priority || 'Unknown'}</td></tr>\n      <tr><td style=\"font-weight: bold; padding: 5px;\">KB Guidance:</td><td style=\"padding: 5px;\">${originalAlertCategory?.hasKBEntry ? '<span style=\"color: #4caf50;\">üìö Available</span>' : 'Manual analysis required'}</td></tr>\n    </table>\n  </div>\n</div>\n` : ''}\n\n---\n\n<h2 style=\"color: #4caf50; margin-top: 25px;\">üìö KNOWLEDGE BASE INTELLIGENCE</h2>\n\n<div style=\"border: 1px solid #4caf50; border-radius: 6px; margin: 10px 0; overflow: hidden;\">\n  <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n    <tr style=\"background: #e8f5e8;\">\n      <td style=\"padding: 10px; font-weight: bold; border-bottom: 1px solid #4caf50;\">KB Metric</td>\n      <td style=\"padding: 10px; font-weight: bold; border-bottom: 1px solid #4caf50;\">Value</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; font-weight: bold; border-bottom: 1px solid #f0f0f0;\">Original Alert KB Entry</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">${originalAlertCategory?.hasKBEntry ? '<span style=\"color: #4caf50;\">‚úÖ Found</span>' : '<span style=\"color: #f44336;\">‚ùå Not Found</span>'}</td>\n    </tr>\n    <tr style=\"background: #fafafa;\">\n      <td style=\"padding: 8px; font-weight: bold; border-bottom: 1px solid #f0f0f0;\">Final Alert KB Entry</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">${finalAlertCategory?.hasKBEntry ? '<span style=\"color: #4caf50;\">‚úÖ Found</span>' : '<span style=\"color: #f44336;\">‚ùå Not Found</span>'}</td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; font-weight: bold; border-bottom: 1px solid #f0f0f0;\">KB Enhanced Correlation</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\">${alertCorrelation.kbEnhanced ? '<span style=\"color: #4caf50;\">‚úÖ Yes</span>' : '<span style=\"color: #f44336;\">‚ùå No</span>'}</td>\n    </tr>\n    <tr style=\"background: #fafafa;\">\n      <td style=\"padding: 8px; font-weight: bold; border-bottom: 1px solid #f0f0f0;\">Enhanced KB Matches</td>\n      <td style=\"padding: 8px; border-bottom: 1px solid #f0f0f0;\"><strong>${enhancedKBMatches.length}</strong></td>\n    </tr>\n    <tr>\n      <td style=\"padding: 8px; font-weight: bold;\">KB-Guided Actions</td>\n      <td style=\"padding: 8px;\"><strong>${allStageData.stage5?.remediation_plan?.immediate_actions?.filter(a => a.source === \"Alert Knowledge Base\").length || 0}</strong></td>\n    </tr>\n  </table>\n</div>\n\n---\n\n## üîç ISSUE IDENTIFICATION\n\n### ${identifiedIssue}\n\n**Confidence Level**: ${(issueConfidence * 100).toFixed(0)}%\n\n**Business Impact**: ${issueImpact}\n\n### üìä EVIDENCE SUMMARY\n${formatEvidence(issueEvidence)}\n\n---\n\n## üïê INCIDENT TIMELINE\n\n| Time | Stage | Finding | Status |\n|------|-------|---------|--------|\n${analysisTimeline.map(entry => \n  `| ${entry.time} | ${entry.stage} | ${entry.finding} | ${\n    entry.severity === 'critical' ? 'üî¥ Critical' : \n    entry.severity === 'warning' ? 'üü° Warning' : \n    entry.severity === 'success' ? '‚úÖ Ready' : \n    'üîµ Info'\n  } |`\n).join('\\n')}\n\n---\n\n## üöÄ ACTION PLAN\n\n${alertCorrelation.hasCorrelation ? `\n### üéØ **IMPORTANT: KB-Enhanced Multi-Phase Remediation**\n\n**Phase 1 (Immediate)**: Address ${topAlert} for service recovery (${(alertCorrelation.actionabilityScore * 100).toFixed(0)}% actionable${finalAlertCategory.hasKBEntry ? ', üìö KB guidance available' : ''})\n**Phase 2 (Follow-up)**: Address ${originalAlert} for long-term stability${originalAlertCategory?.hasKBEntry ? ' (üìö KB guidance available)' : ''}\n` : ''}\n\n### üî¥ IMMEDIATE ACTIONS (Execute NOW)\n\n#### 1. Service Recovery Action\n\n**Command to execute:**\n\\`\\`\\`bash\nkubectl rollout undo deployment/${deployment} -n ${namespace}\n\\`\\`\\`\n\n**Verification command:**\n\\`\\`\\`bash\nkubectl get pods -n ${namespace} | grep ${deployment}\nkubectl rollout status deployment/${deployment} -n ${namespace}\n\\`\\`\\`\n\n- **Risk Level**: Low\n- **Estimated Time**: 2-5 minutes\n- **Expected Outcome**: Restore service to previous stable version\n- **KB Enhancement**: ${finalAlertCategory.hasKBEntry ? 'KB guidance available' : 'Standard recovery approach'}\n\n---\n\n## üìé Additional Information\n\n- **Analysis Context ID**: ${masterContext.contextId}\n- **Alert Source**: ${topAlert}\n${alertCorrelation.hasCorrelation ? `- **Original Alert**: ${originalAlert}\n- **Correlation Applied**: ‚úÖ ${alertCorrelation.correlationType}\n- **Correlation Confidence**: ${(alertCorrelation.confidence * 100).toFixed(0)}%\n- **Actionability Score**: ${(alertCorrelation.actionabilityScore * 100).toFixed(0)}%\n- **KB Enhancement**: ${alertCorrelation.kbEnhanced ? '‚úÖ Enhanced with KB data' : '‚ùå Pattern-based analysis'}` : ''}\n- **Analysis Completed**: ${new Date().toISOString()}\n- **Total Analysis Time**: ${durationMinutes} minutes\n- **System**: KB-Aware Universal Correlation Engine v1.0 (Hybrid)\n- **KB Integration**: ${Object.keys(alertKnowledgeBase).length} alerts in knowledge base\n\n---\n\n*This report was automatically generated by the KB-Aware Universal Correlation System*\n*Enhanced with existing Knowledge Base integration and 320+ alert pattern support*\n*Report Version: 4.0 - KB-Aware Correlation (Hybrid) | Generated: ${new Date().toISOString()}*\n`;\n\n// ============= GENERATE ONCALL-FRIENDLY TICKET =============\nconst oncallFriendlyTicket = generateOncallFriendlyTicket(\n  issueEvidence, \n  allStageData, \n  podName, \n  deployment, \n  namespace, \n  topAlert, \n  alertCorrelation, \n  masterContext,\n  alertType,\n  nodeName\n);\n\n// ============= RETURN ENHANCED SCHEMA (HYBRID OLD + NEW) =============\nreturn {\n  alert: topAlert,\n  identifiedIssue: identifiedIssue,\n  confidence: issueConfidence,\n  severity: issueSeverity,\n  impact: issueImpact,\n  evidence: issueEvidence,\n  timeline: analysisTimeline,\n  metrics: collectedMetrics,\n  actions: generateOncallActions(allStageData, deployment, namespace, podName, issueEvidence, alertType, nodeName),\n  markdownReport: jiraTicketHtml,\n  \n  // NEW: ONCALL-FRIENDLY JIRA TICKET (Simple format for oncall personnel)\n  oncallTicket: {\n    title: getOncallTitle(topAlert, deployment, namespace, podName, issueEvidence, nodeName),\n    description: oncallFriendlyTicket,\n    priority: getOncallPriority(topAlert, issueSeverity, issueEvidence),\n    labels: [\n      topAlert, \n      getOncallSeverity(topAlert, issueEvidence).replace('üî¥ ', '').replace('üü† ', '').replace('üü° ', '').replace('üîµ ', ''),\n      namespace || 'cluster', \n      alertType === 'NODE' ? `Node-${nodeName}` : (deployment || 'infrastructure'),\n      \"Oncall-Ready\", \n      \"English-Format\",\n      topAlert.includes('Node') ? 'Infrastructure' : 'Application',\n      topAlert.includes('etcd') || topAlert.includes('APIServer') ? 'Critical-Infrastructure' : 'Service-Level'\n    ].filter(Boolean),\n    components: alertType === 'NODE' ? [`Node-${nodeName}`] : (deployment ? [deployment] : [namespace || 'cluster']),\n    issueType: \"Incident\",\n    customFields: {\n      contextId: masterContext.contextId,\n      oncallFriendly: true,\n      language: \"English\",\n      symptoms: extractBusinessSymptoms(issueEvidence, podName, deployment, topAlert, allStageData).length,\n      rootCause: extractSimpleRootCause(issueEvidence, allStageData, topAlert, alertCorrelation)\n    }\n  },\n  \n  // TECHNICAL JIRA TICKET (Detailed format for technical teams)\n  jiraTicket: {\n    title: alertCorrelation.hasCorrelation ? \n      `[${originalAlert} ‚Üí ${topAlert}] ${alertType === 'NODE' ? `Node ${nodeName}` : deployment} - ${identifiedIssue}${alertCorrelation.kbEnhanced ? ' (KB-Enhanced)' : ''}` :\n      `[${topAlert}] ${alertType === 'NODE' ? `Node ${nodeName}` : deployment} - ${identifiedIssue}${finalAlertCategory?.hasKBEntry ? ' (KB-Available)' : ''}`,\n    description: jiraTicketHtml,\n    priority: issueSeverity === \"critical\" ? \"Critical\" : \"High\",\n    labels: [topAlert, issueSeverity, namespace, alertType === 'NODE' ? `Node-${nodeName}` : deployment, \"Auto-Detected\", \"KB-Aware-Correlation\"]\n      .concat(alertCorrelation.hasCorrelation ? [\"Alert-Correlation\", originalAlert, alertCorrelation.correlationType] : [])\n      .concat(alertCorrelation.kbEnhanced ? [\"KB-Enhanced\"] : [])\n      .concat(originalAlertCategory?.hasKBEntry ? [\"Original-KB-Available\"] : [])\n      .concat(finalAlertCategory?.hasKBEntry ? [\"Final-KB-Available\"] : []),\n    components: alertType === 'NODE' ? [`Node-${nodeName}`] : [deployment],\n    issueType: \"Incident\",\n    customFields: {\n      contextId: masterContext.contextId,\n      analysisTime: durationMinutes,\n      automationConfidence: issueConfidence,\n      ...(alertCorrelation.hasCorrelation && {\n        originalAlert: originalAlert,\n        correlatedAlert: topAlert,\n        correlationType: alertCorrelation.correlationType,\n        correlationConfidence: alertCorrelation.confidence,\n        actionabilityScore: alertCorrelation.actionabilityScore,\n        correlationApplied: true,\n        correlationEngine: \"KB-Aware Universal Correlation Engine (Hybrid)\",\n        kbEnhanced: alertCorrelation.kbEnhanced,\n        kbOriginalEntry: originalAlertCategory?.hasKBEntry || false,\n        kbFinalEntry: finalAlertCategory?.hasKBEntry || false\n      })\n    }\n  },\n  executiveSummary: {\n    contextId: masterContext.contextId,\n    issue: identifiedIssue,\n    severity: issueSeverity,\n    immediateAction: allStageData.stage5?.remediation_plan?.immediate_actions?.[0]?.action || \n                    (alertType === 'NODE' ? `Check and diagnose node ${nodeName}` : `Investigate and restart ${podName}`),\n    command: allStageData.stage5?.remediation_plan?.immediate_actions?.[0]?.command || \n            (alertType === 'NODE' ? `kubectl describe node ${nodeName}` : `kubectl describe pod ${podName} -n ${namespace} && kubectl delete pod ${podName} -n ${namespace}`),\n    risk: allStageData.stage5?.remediation_plan?.immediate_actions?.[0]?.risk_level || \"medium\",\n    estimatedTime: allStageData.stage5?.remediation_plan?.immediate_actions?.[0]?.estimated_time || \"2-5 minutes\",\n    stagesCompleted: 5,\n    timestamp: new Date().toISOString(),\n    ...(alertCorrelation.hasCorrelation && {\n      alertCorrelation: {\n        original: originalAlert,\n        final: topAlert,\n        pattern: alertCorrelation.correlationType,\n        confidence: alertCorrelation.confidence,\n        actionabilityScore: alertCorrelation.actionabilityScore,\n        reason: alertCorrelation.explanation?.en?.rootCause,\n        kbEnhanced: alertCorrelation.kbEnhanced,\n        kbEntries: {\n          originalAvailable: originalAlertCategory?.hasKBEntry || false,\n          finalAvailable: finalAlertCategory?.hasKBEntry || false\n        }\n      }\n    }),\n    quickActions: alertType === 'NODE' ? {\n      describe: `kubectl describe node ${nodeName}`,\n      monitor: `watch kubectl get nodes ${nodeName}`,\n      logs: `kubectl get events --field-selector involvedObject.name=${nodeName} --sort-by='.lastTimestamp'`,\n      drain: `kubectl drain ${nodeName} --ignore-daemonsets --delete-emptydir-data`\n    } : {\n      rollback: `kubectl rollout undo deployment/${deployment} -n ${namespace}`,\n      monitor: `watch kubectl get pods -n ${namespace} | grep ${deployment}`,\n      logs: `kubectl logs -f deployment/${deployment} -n ${namespace}`,\n      scale: `kubectl scale deployment/${deployment} --replicas=3 -n ${namespace}`\n    }\n  },\n  \n  knowledgeBaseInsights: {\n    kbIntegrationEnabled: true,\n    kbEnhanced: kbEnhancementActive || stage3KBStats.kbEnhanced === true, // KB Enhancement flag (FIXED)\n    alertCategory: stage3KBStats.alertCategory || kbAlertCategory, // From Stage 3 or Alert Categories Mapper\n    urgencyLevel: stage3KBStats.urgencyLevel || kbUrgencyLevel, // From Stage 3 or Alert Categories Mapper  \n    cascadeRisk: stage3KBStats.cascadeRisk || kbCascadeRisk, // From Stage 3 or Alert Categories Mapper\n    existingKBAlerts: Object.keys(alertKnowledgeBase).length,\n    enhancedKBMatches: enhancedKBMatches,\n    correlationKBEnhanced: alertCorrelation.kbEnhanced,\n    originalAlertKB: originalAlertCategory?.hasKBEntry ? originalAlertCategory.kbEntry : null,\n    finalAlertKB: finalAlertCategory?.hasKBEntry ? finalAlertCategory.kbEntry : null,\n    \n    kbUtilization: {\n      utilizationRate: enhancedKBMatches.length > 0 ? `${((enhancedKBMatches.length / Math.max(1, Object.keys(alertKnowledgeBase).length)) * 100).toFixed(1)}%` : \"0%\",\n      matchedEntries: enhancedKBMatches.length,\n      enhancedDiagnostics: enhancedKBMatches.filter(m => m.correlation_enhanced).length,\n      appliedRemediations: allStageData.stage5?.remediation_plan?.immediate_actions?.filter(a => a.source === \"Alert Knowledge Base\").length || 0\n    },\n    \n    // KB Enhancement Statistics\n    kbEnhancementStats: {\n      categoriesSupported: kbEnhancedStats.totalCategories,\n      alertMappings: kbEnhancedStats.totalMappings,\n      kbEntriesLoaded: kbEnhancedStats.kbEntriesLoaded,\n      enhancementSource: \"KB Node Integration v1.0\"\n    }\n  },\n  \n  _debug: {\n    contextId: masterContext.contextId,\n    hasStage1Data: !!allStageData.stage1,\n    hasStage2Data: !!allStageData.stage2,\n    hasStage3Data: !!allStageData.stage3,\n    hasStage4Data: !!allStageData.stage4,\n    hasStage5Data: !!allStageData.stage5,\n    podName: podName,\n    namespace: namespace,\n    deployment: deployment,\n    topAlert: topAlert,\n    originalAlert: originalAlert,\n    evidenceFormatted: !!issueEvidence,\n    dataAccessPattern: \"hybrid-old-new\",\n    \n    kbAwareCorrelation: {\n      engine: \"KB-Aware Universal Correlation Engine\",\n      version: \"1.0-HYBRID\",\n      hasCorrelation: alertCorrelation.hasCorrelation,\n      correlationType: alertCorrelation.correlationType,\n      confidence: alertCorrelation.confidence,\n      actionabilityScore: alertCorrelation.actionabilityScore,\n      kbEnhanced: alertCorrelation.kbEnhanced,\n      originalCategory: originalAlertCategory,\n      finalCategory: finalAlertCategory,\n      alertSelectionProcess: {\n        stage1Alert: allStageData.stage1?.alerts?.top_alerts?.[0] || null,\n        stage3CorrelatedAlert: allStageData.stage3?.active_alerts?.[0]?.name || null,\n        stage3RecommendedAlert: allStageData.stage3?.recommended_actions?.[0]?.alert || null,\n        defaultFallback: realAlertName,\n        selectionReason: topAlert === realAlertName ? \"Using real alert from input payload\" : \"Selected from stage data or fallback\"\n      },\n      existingKBAlertsCount: Object.keys(alertKnowledgeBase).length,\n      enhancedKBMatchesCount: enhancedKBMatches.length\n    }\n  }\n};\n\n// ================ KB ENHANCEMENT SUMMARY ================\nconsole.log(\"\\n===== KB-ENHANCED FINAL REPORT GENERATED =====\");\nconsole.log(\"KB Enhancement Active:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Loaded:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"Confidence Boost Applied:\", directKBEntry ? \"+10%\" : \"0%\");\nconsole.log(\"Categories Supported:\", kbEnhancedStats.totalCategories || 12);\nconsole.log(\"Alert Mappings:\", kbEnhancedStats.totalMappings || \"320+\");\nconsole.log(\"Enhancement Version:\", \"KB-Enhanced-Full-v1.0\");\nconsole.log(\"================================================\\n\");\n"
      },
      "id": "cde032d1-4668-4497-b82b-a072b425d8ca",
      "name": "Generate Final Report",
      "type": "n8n-nodes-base.code",
      "position": [
        1072,
        384
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "content": "## üöÄ Prometheus Ultimate AI Agent System\n\n### 6-Stage Intelligent Analysis & Remediation\n\n1. **Stage 1: Health Snapshot** (5s)\n   - Quick cluster health check\n   - Active alerts count\n   - Go/No-go decision\n\n2. **Stage 2: Deep Analysis** (30s)\n   - 3-phase investigation\n   - Instant ‚Üí Trend ‚Üí Anomaly\n   - Root cause identification\n\n3. **Stage 3: Alert Intelligence** (20s)\n   - Alert correlation\n   - Knowledge base matching\n   - SLO impact assessment\n\n4. **Stage 4: Automated Diagnosis** (20s)\n   - Execute diagnostic commands\n   - Enrich context\n   - Confirm root cause\n\n5. **Stage 5: Smart Remediation** (30s)\n   - Safe auto-fixes\n   - Approval workflow\n   - Verification loops\n\n6. **Stage 6: Prevention** (20s)\n   - Update monitoring\n   - Document learnings\n   - Prevent recurrence\n\n### Features:\n- Alert correlation engine\n- Knowledge base integration\n- Auto-remediation (safe actions)\n- Predictive analysis\n- Learning system\n- ChatOps commands\n- SLO tracking\n- Runbook automation\n\n### Triggers:\n- Manual\n- Scheduled (5 min)\n- Chat commands\n- AlertManager webhooks",
        "height": 600,
        "width": 400,
        "color": 5
      },
      "id": "b1ed0a75-3b38-4f2a-a884-b85bec1f3095",
      "name": "System Overview",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        0,
        0
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "etiya-gpt-4o",
          "mode": "list",
          "cachedResultName": "etiya-gpt-4o"
        },
        "options": {
          "responseFormat": "json_object",
          "temperature": 0.1,
          "maxRetries": 2
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -816,
        176
      ],
      "id": "06a3c990-91df-47f9-9097-1e56545e16b9",
      "name": "OpenAI Chat Model",
      "credentials": {
        "openAiApi": {
          "id": "rYdB8nNsS7m67tcr",
          "name": "OpenAi account 5"
        }
      }
    },
    {
      "parameters": {
        "content": "# Prometheus AI Agent - Chat Komutlarƒ±\n\n## üéØ Desteklenen Komutlar\n\n### 1. Derin Analiz Komutlarƒ±\nT√ºm 6 a≈üamayƒ± zorla √ßalƒ±≈ütƒ±rƒ±r, cluster saƒülƒ±klƒ± olsa bile:\n\n```\ndeep analysis\nderin analiz\nfull scan\ndetailed check\nanalyze everything\nforce check\n```\n\n**√ñrnekler:**\n- \"run deep analysis on the cluster\"\n- \"force a detailed check\"\n- \"analyze everything even if healthy\"\n\n### 2. Hƒ±zlƒ± Kontrol\nSadece Stage 1 √ßalƒ±≈üƒ±r:\n\n```\nquick check\nquick analysis\nhƒ±zlƒ± kontrol\nstatus\n```\n\n**√ñrnekler:**\n- \"quick check cluster health\"\n- \"give me a status update\"\n\n### 3. Servis Bazlƒ± Analiz\nBelirli bir servise odaklanƒ±r:\n\n```\ncheck service: <service-name>\nanalyze service: <service-name>\n```\n\n**√ñrnekler:**\n- \"check service: payment-api\"\n- \"analyze service: user-auth\"\n\n### 4. Alert Odaklƒ± Analiz\nAlert'lere odaklanarak derin analiz:\n\n```\ncheck alerts\nalert analysis\nanalyze all alerts\n```\n\n### 5. Namespace Analizi\nBelirli namespace'e odaklanƒ±r:\n\n```\nnamespace: <namespace-name>\ncheck namespace: <namespace-name>\n```\n\n**√ñrnekler:**\n- \"deep analysis namespace: etiyamobile-production\"\n- \"check namespace: staging\"\n\n### 6. Zaman Aralƒ±ƒüƒ± Belirtme\nAnaliz i√ßin zaman aralƒ±ƒüƒ±:\n\n```\nlast hour\nlast day\nlast week\n```\n\n**√ñrnekler:**\n- \"deep analysis for last hour\"\n- \"check alerts from last day\"\n\n## üìù Kombinasyon √ñrnekleri\n\n```\n# Namespace + Derin analiz\n\"run deep analysis on namespace: etiyamobile-production\"\n\n# Servis + Zaman aralƒ±ƒüƒ±\n\"check service: payment-api for last hour\"\n\n# Alert + Derin analiz\n\"deep analysis of all alerts\"\n\n# Zorla derin analiz + zaman\n\"force detailed check for last day\"\n```",
        "height": 760,
        "width": 400
      },
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        -5488,
        224
      ],
      "typeVersion": 1,
      "id": "41073c2c-6bd9-429f-80ab-9e60d9a0cea3",
      "name": "Chat Commands Guide"
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `(kubelet_volume_stats_used_bytes{namespace=\\\"${ns}\\\", persistentvolumeclaim=~\\\".*${svc}.*\\\"} / kubelet_volume_stats_capacity_bytes{namespace=\\\"${ns}\\\", persistentvolumeclaim=~\\\".*${svc}.*\\\"} > 0.8) * on(namespace, persistentvolumeclaim) group_left(storageclass, volumename) kube_persistentvolumeclaim_info{namespace=\\\"${ns}\\\", persistentvolumeclaim=~\\\".*${svc}.*\\\"} or kube_persistentvolumeclaim_status_phase{namespace=\\\"${ns}\\\", persistentvolumeclaim=~\\\".*${svc}.*\\\", phase!=\\\"Bound\\\"} == 1`;\n  } else {\n    baseQuery = `(kubelet_volume_stats_used_bytes{namespace=\\\"${ns}\\\"} / kubelet_volume_stats_capacity_bytes{namespace=\\\"${ns}\\\"} > 0.8) * on(namespace, persistentvolumeclaim) group_left(storageclass, volumename) kube_persistentvolumeclaim_info{namespace=\\\"${ns}\\\"} or kube_persistentvolumeclaim_status_phase{namespace=\\\"${ns}\\\", phase!=\\\"Bound\\\"} == 1`;\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        -928,
        1072
      ],
      "id": "4195c61b-2250-414d-8417-ffb503491558",
      "name": "Kubernetes PVC Status"
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{(() => {\n  const ns = $json.namespace || 'etiyamobile-production';\n  const svc = $json.service || '';\n  let baseQuery;\n  if (svc) {\n    baseQuery = `(kube_horizontalpodautoscaler_status_current_replicas{namespace=\\\"${ns}\\\", horizontalpodautoscaler=~\\\".*${svc}.*\\\"} / kube_horizontalpodautoscaler_spec_max_replicas{namespace=\\\"${ns}\\\", horizontalpodautoscaler=~\\\".*${svc}.*\\\"}) > 0.9 or kube_horizontalpodautoscaler_status_condition{namespace=\\\"${ns}\\\", horizontalpodautoscaler=~\\\".*${svc}.*\\\", condition=\\\"ScalingLimited\\\", status=\\\"true\\\"} == 1`;\n  } else {\n    baseQuery = `(kube_horizontalpodautoscaler_status_current_replicas{namespace=\\\"${ns}\\\"} / kube_horizontalpodautoscaler_spec_max_replicas{namespace=\\\"${ns}\\\"}) > 0.9 or (kube_horizontalpodautoscaler_status_current_replicas{namespace=\\\"${ns}\\\"} == kube_horizontalpodautoscaler_spec_max_replicas{namespace=\\\"${ns}\\\"}) or kube_horizontalpodautoscaler_status_condition{namespace=\\\"${ns}\\\", condition=\\\"ScalingLimited\\\", status=\\\"true\\\"} == 1`;\n  }\n  return `topk(5, ${baseQuery})`;\n})()}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "type": "n8n-nodes-base.httpRequestTool",
      "typeVersion": 4.2,
      "position": [
        -848,
        1168
      ],
      "id": "1cb04d69-7ec9-4eaf-8945-ab3e52bc5508",
      "name": "Kubernetes HPA Status"
    },
    {
      "parameters": {
        "jsCode": "// Force Deep Analysis Override - Prometheus Agent - CONTEXT ENHANCED\nconst stage1Result = $input.first().json;\n\n// Unified Entry Point'ten gelen orijinal veriyi al\nconst unifiedData = $node[\"Unified Entry Point\"].json;\n\n// Context'i al - Stage 2 Decision'dan veya Stage 1'den\nlet masterContext = stage1Result._context || {\n  contextId: `ctx-override-${Date.now()}`,\n  createdAt: new Date().toISOString(),\n  stageResults: {},\n  decisions: {},\n  debug: { warnings: ['Context recreated in Force Deep Analysis Override'] }\n};\n\n// forceDeepAnalysis kontrol√º\nconst forceDeepAnalysis = \n  unifiedData.forceDeepAnalysis || \n  unifiedData.priority === 'critical' ||\n  unifiedData.stageConfig?.forceDeepAnalysis ||\n  false;\n\n// Stage 1 sonucunu kopyala\nlet output = { ...stage1Result };\n\n// Override decision'ƒ± context'e kaydet\nconst overrideDecision = {\n  timestamp: new Date().toISOString(),\n  originalDecision: stage1Result.proceed_to_stage2,\n  forceDeepAnalysis: forceDeepAnalysis,\n  overrideApplied: false,\n  reason: null\n};\n\n// Eƒüer forceDeepAnalysis aktif ve Stage 1 proceed_to_stage2=false yapmƒ±≈üsa override et\nif (forceDeepAnalysis && !stage1Result.proceed_to_stage2) {\n  console.log('üî• PROMETHEUS - Force Deep Analysis Override Applied');\n  console.log('Original priority:', unifiedData.priority);\n  console.log('Original decision:', stage1Result.proceed_to_stage2);\n  console.log('Context ID:', masterContext.contextId);\n  \n  output.proceed_to_stage2 = true;\n  output.overridden = true;\n  output.forceDeepAnalysisApplied = true;\n  output.overrideReason = `Deep analysis forced due to ${unifiedData.priority} priority from ${unifiedData.source.type}`;\n  \n  // Override decision'ƒ± g√ºncelle\n  overrideDecision.overrideApplied = true;\n  overrideDecision.reason = output.overrideReason;\n}\n\n// Context'e override decision'ƒ± ekle\nmasterContext.decisions.forceDeepAnalysisOverride = overrideDecision;\n\n// Override node'unun √ßƒ±ktƒ±sƒ±nƒ± context'e kaydet\nmasterContext.stageResults.forceDeepAnalysisOverride = {\n  output: {\n    overrideApplied: overrideDecision.overrideApplied,\n    reason: overrideDecision.reason,\n    originalPriority: unifiedData.priority,\n    originalSource: unifiedData.source\n  },\n  completedAt: new Date().toISOString()\n};\n\n// Orijinal context'i de ta≈üƒ± ve zenginle≈ütir\noutput.originalContext = {\n  source: unifiedData.source,\n  priority: unifiedData.priority,\n  stageConfig: unifiedData.stageConfig,\n  analysisParams: unifiedData.analysisParams\n};\n\n// YENƒ∞: Context'i g√ºncelle ve ta≈üƒ±\noutput._context = masterContext;\n\n// YENƒ∞: Stage 2'ye gidecek veriyi hazƒ±rla\noutput.stage2Input = {\n  proceed: output.proceed_to_stage2,\n  priority: unifiedData.priority,\n  analysisParams: unifiedData.analysisParams,\n  timeRange: {\n    start: unifiedData.analysisParams.startTime,\n    end: unifiedData.analysisParams.endTime\n  },\n  namespaces: unifiedData.analysisParams.namespaces,\n  focusAreas: unifiedData.analysisParams.focusAreas || []\n};\n\n// YENƒ∞: Debug bilgisi\noutput._debug = {\n  nodeType: 'Force Deep Analysis Override',\n  processedAt: new Date().toISOString(),\n  contextId: masterContext.contextId,\n  contextPreserved: true,\n  overrideApplied: overrideDecision.overrideApplied,\n  stageSequence: ['Unified Entry Point', 'Stage 1', 'Stage 2 Decision', 'Force Deep Analysis Override']\n};\n\n// Critical durumlar i√ßin stage config'i g√ºncelle\nif (output.overall_status === 'critical' || output.urgency === 'critical') {\n  console.log('üî• CRITICAL STATUS DETECTED - Updating stage config');\n  \n  if (output._context && output._context.stageConfig) {\n    // √ñnceki deƒüerleri logla\n    console.log('Previous maxStages:', output._context.stageConfig.maxStages);\n    \n    // Stage config'i g√ºncelle\n    output._context.stageConfig.maxStages = 6;\n    output._context.stageConfig.enablePatternAnalysis = true;\n    output._context.stageConfig.enableAnomalyDetection = true;\n    output._context.stageConfig.enablePredictiveAnalysis = true;\n    \n    console.log('Updated maxStages to:', output._context.stageConfig.maxStages);\n    console.log('‚úÖ Stage config updated for critical situation');\n  }\n  \n  // Priority'yi de critical yap\n  if (output._context) {\n    output._context.priority = 'critical';\n    output._context.updatedDueToCriticalStatus = true;\n  }\n}\n\n// Stage 2 input'a da critical bilgisini ekle\nif (output.stage2Input && (output.overall_status === 'critical' || output.urgency === 'critical')) {\n  output.stage2Input.priority = 'critical';\n  output.stage2Input.criticalStatusDetected = true;\n}\n\n// YENI: Stage 1 verilerini koru\noutput.stage1Data = {\n  overall_status: stage1Result.overall_status || stage1Result.stage1Results?.overall_status,\n  alerts: stage1Result.alerts || stage1Result.stage1Results?.alerts,\n  scores: stage1Result.scores || stage1Result.stage1Results?.scores,\n  quick_findings: stage1Result.quick_findings || stage1Result.stage1Results?.quick_findings\n};\n\n// Stage 2 i√ßin service parametresini hazƒ±rla\nconst requestedService = unifiedData.analysisParams?.services?.[0] || \n                        stage1Result.requested_services?.[0] || \n                        '';\n\n// Stage 2'ye gidecek parametreleri root'a ekle\noutput.namespace = unifiedData.analysisParams.namespaces[0] || 'etiyamobile-production';\noutput.service = requestedService;\noutput.startTime = unifiedData.analysisParams.startTime;\noutput.endTime = unifiedData.analysisParams.endTime;\n\n// Stage 2 i√ßin a√ßƒ±k talimatlar\noutput.stage2Instructions = {\n  service: requestedService,\n  namespace: output.namespace,\n  message: requestedService ? `Focus on service: ${requestedService}` : 'General cluster analysis'\n};\n\nconsole.log('=== Stage 2 Parameters ===');\nconsole.log('Service:', output.service);\nconsole.log('Namespace:', output.namespace);\nconsole.log('=========================');\n\nconsole.log('=== Force Deep Analysis Override Complete ===');\nconsole.log('Context preserved:', !!output._context);\nconsole.log('Override applied:', overrideDecision.overrideApplied);\nconsole.log('Next stage will receive full context');\n\nreturn [{ json: output }];"
      },
      "id": "4fe2a2bc-c338-4239-ad1a-4c420083b0c4",
      "name": "Force Deep Analysis Override",
      "type": "n8n-nodes-base.code",
      "position": [
        -2128,
        432
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Prepare Stage 1 Input - Alert odaklƒ± analiz i√ßin hazƒ±rlƒ±k (Fixed)\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// Hata kontrol√º - eƒüer √∂nceki node'dan hata geldiyse dur\nif (inputData.hasError) {\n  return [{\n    hasError: true,\n    errorMessage: inputData.errorMessage || 'Previous node reported an error',\n    errorType: inputData.errorType || 'UPSTREAM_ERROR'\n  }];\n}\n\n// T√ºm gelen veriyi koru\nlet output = { ...inputData };\n\n// Alert context'i al - ZORUNLU\nconst alertContext = inputData.analysisParams?.context || {};\nconst kubernetesFilters = inputData.kubernetesFilters || {};\nconst knowledgeBase = inputData.knowledgeBase || {};\nconst priority = inputData.priority || 'normal';\n\n// Alert yoksa hata\nif (!alertContext.alertName) {\n  return [{\n    hasError: true,\n    errorMessage: 'No alert found for Stage 1 analysis',\n    errorType: 'MISSING_ALERT'\n  }];\n}\n\n// System prompt - Alert odaklƒ±, cascading kontrol√º dahil\nconst systemPrompt = 'You are a Kubernetes SRE expert analyzing a SPECIFIC ALERT and its cascading effects.\\n\\n' +\n  'ALERT INFORMATION:\\n' +\n  '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n' +\n  'Alert: ' + alertContext.alertName + '\\n' +\n  'Priority: ' + (alertContext.alertPriority || priority) + '\\n' +\n  'Alert ID: ' + alertContext.alertId + '\\n\\n' +\n  'AFFECTED COMPONENTS:\\n' +\n  '- Pod: ' + (kubernetesFilters.pod || 'N/A') + '\\n' +\n  '- Container: ' + (kubernetesFilters.container || 'N/A') + '\\n' +\n  '- Namespace: ' + (kubernetesFilters.namespace || 'N/A') + '\\n' +\n  '- Service: ' + (kubernetesFilters.service || 'N/A') + '\\n' +\n  '- Node: ' + (kubernetesFilters.node || 'N/A') + '\\n\\n' +\n  (knowledgeBase.alert ? \n    'KNOWLEDGE BASE INFO:\\n' +\n    '- Common Causes: ' + knowledgeBase.alert.commonCauses.join(', ') + '\\n' +\n    '- Check These Metrics: ' + knowledgeBase.alert.requiredMetrics.join(', ') + '\\n' +\n    '- Cascade Points: ' + knowledgeBase.alert.cascadeCheckPoints.join(', ') + '\\n\\n' \n    : '') +\n  'YOUR ANALYSIS TASKS:\\n' +\n  '‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\\n\\n' +\n  '1. VERIFY ALERT STATUS:\\n' +\n  '   - Confirm alert is still active\\n' +\n  '   - Check current severity\\n' +\n  '   - Determine duration\\n\\n' +\n  '2. ANALYZE AFFECTED COMPONENT:\\n' +\n  '   - Current status of ' + (kubernetesFilters.pod || kubernetesFilters.node || 'the component') + '\\n' +\n  '   - Resource usage (CPU, Memory)\\n' +\n  '   - Recent errors or restarts\\n' +\n  '   - Health check status\\n\\n' +\n  '3. DETECT CASCADING EFFECTS:\\n' +\n  '   - Check other pods in same namespace\\n' +\n  '   - Check other pods on same node (if applicable)\\n' +\n  '   - Check dependent services\\n' +\n  '   - Identify spread pattern\\n\\n' +\n  '4. ASSESS OVERALL IMPACT:\\n' +\n  '   - Service availability\\n' +\n  '   - User impact\\n' +\n  '   - Data integrity risk\\n' +\n  '   - Performance degradation\\n\\n' +\n  'AVAILABLE TOOLS:\\n' +\n  '- List Kubernetes Services: Use to see all services in cluster\\n' +\n  '- Quick Cluster Health: Use to get overall health context\\n' +\n  '- Active Alerts Count: Will show alerts in affected namespace\\n' +\n  '- Pod Status Check: Will focus on the alert pod\\n' +\n  '- Plus other dynamic tools that adapt to the alert context\\n\\n' +\n  'IMPORTANT: Check both the specific alert AND potential cascading failures.\\n\\n' +\n  'Output a structured JSON with your findings.';\n\n// User message - Context korunmasƒ± i√ßin g√ºncellendi\nconst contextString = JSON.stringify(inputData._context || {});\nconst userMessage = 'Analyze the ' + alertContext.alertName + ' alert affecting ' + \n  (kubernetesFilters.pod || kubernetesFilters.node || 'the system') + \n  ' in namespace ' + kubernetesFilters.namespace + '. ' +\n  'Use all available tools to verify the alert, check the affected component\\'s health, ' +\n  'detect any cascading effects, and determine if deeper analysis is needed.\\n\\n' +\n  'CRITICAL OUTPUT REQUIREMENTS:\\n' +\n  '1. Your response MUST be valid JSON\\n' +\n  '2. Include real timestamp using new Date().toISOString()\\n' +\n  '3. Use cluster name: ' + kubernetesFilters.namespace + '\\n' +\n  '4. Include pod: ' + (kubernetesFilters.pod || 'unknown') + '\\n' +\n  '5. MUST include this exact _context field in your JSON response:\\n' +\n  '\"_context\": ' + contextString + '\\n\\n' +\n  'Never use placeholder dates like 2024-04-27 or default-cluster.';\n\n// Enhanced system prompt - Context preservation i√ßin\nconst enhancedSystemPrompt = systemPrompt + '\\n\\n' +\n  'OUTPUT FORMAT RULES:\\n' +\n  '- You MUST return valid JSON only\\n' +\n  '- You MUST include the _context object exactly as provided\\n' +\n  '- Use current timestamp: new Date().toISOString()\\n' +\n  '- Actual namespace: ' + kubernetesFilters.namespace + '\\n' +\n  '- Never use mock data or placeholder values';\n\n// Output'a ekle kƒ±smƒ±nƒ± g√ºncelle (var olan output.systemPrompt yerine):\noutput.systemPrompt = enhancedSystemPrompt;\n\n// Output'a ekle\noutput.systemPrompt = enhancedSystemPrompt;\noutput.userMessage = userMessage;\n\n// Stage context - t√ºm bilgileri ekle\noutput.stageContext = {\n  stage: 'Stage 1: Alert and Cascading Analysis',\n  stageNumber: 1,\n  timestamp: new Date().toISOString(),\n  alertContext: alertContext,\n  kubernetesFilters: kubernetesFilters,\n  prometheusQueries: inputData.prometheusQueries || [],\n  knowledgeBase: knowledgeBase,\n  priority: priority,\n  analysisType: 'alert-driven-with-cascading',\n  namespaces: inputData.analysisParams?.namespaces || [kubernetesFilters.namespace],\n  services: inputData.analysisParams?.services || [],\n  focusAreas: ['alert-verification', 'cascading-detection', 'impact-assessment'],\n  requiredMetrics: inputData._context?.requiredMetrics || [],\n  cascadeCheckPoints: inputData._context?.cascadeCheckPoints || []\n};\n\nconsole.log('Stage 1 Prepared:', {\n  alertName: alertContext.alertName,\n  priority: priority,\n  pod: kubernetesFilters.pod,\n  namespace: kubernetesFilters.namespace,\n  hasKnowledgeBase: !!knowledgeBase.alert\n});\n\nreturn [output];"
      },
      "id": "03c3c577-5e47-4240-9f85-b60e88da1888",
      "name": "Prepare Stage 1 Input",
      "type": "n8n-nodes-base.code",
      "position": [
        -3488,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED FIX STAGE 1 CONTEXT ================\n// This file preserves ALL original 138 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes (safely with error handling)\nlet alertCategoriesMapper = {};\nlet loadAlertKB = {};\nlet categoryMetricsBuilder = {};\n\ntry {\n  alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\n} catch(e) {\n  console.log(\"Alert Categories Mapper node not available yet\");\n}\n\ntry {\n  loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\n} catch(e) {\n  console.log(\"Load Alert Knowledge Base node not available yet\");\n}\n\ntry {\n  categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\n} catch(e) {\n  console.log(\"Category Based Metrics Builder node not available yet\");\n}\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS)\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst kbUrgencyLevel = deriveUrgencyLevel(alertCategoriesMapper.calculatedSeverityScore || 0);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || {};\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== STAGE 1 KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"==========================================\");\n\n// Fix Stage 1 Context - Correct the context after AI Agent output\nconst stage1Output = $input.first().json;\nconst unifiedData = $node[\"Unified Entry Point\"].json;\nconst preparedData = $node[\"Prepare Stage 1 Input\"].json;\n\nconsole.log(\"=== FIXING STAGE 1 CONTEXT ===\");\nconsole.log(\"Stage 1 output structure:\", stage1Output.output ? \"Has output wrapper\" : \"Direct output\");\nconsole.log(\"Expected context ID:\", unifiedData._context.contextId);\n\n// Deep copy to avoid mutations\nlet fixedOutput = JSON.parse(JSON.stringify(stage1Output));\n\n// Output wrapper kontrol√º\nconst hasOutputWrapper = !!fixedOutput.output;\nconst actualOutput = hasOutputWrapper ? fixedOutput.output : fixedOutput;\n\n// Context'i kontrol et ve d√ºzelt\nif (actualOutput._context) {\n  const contextString = JSON.stringify(actualOutput._context);\n  const hasTemplates = contextString.includes(\"{{\") || contextString.includes(\"}}\");\n  const hasJsonReference = contextString.includes(\"$json\");\n  \n  console.log(\"Context has templates:\", hasTemplates);\n  console.log(\"Context has $json references:\", hasJsonReference);\n  \n  if (hasTemplates || hasJsonReference || \n      !actualOutput._context.contextId || \n      actualOutput._context.contextId === \"{{ $json.contextId }}\" ||\n      actualOutput._context.contextId === \"12345\" ||\n      actualOutput._context.contextId === \"abc-123\") {\n    \n    console.log(\"‚ùå Invalid context detected, fixing...\");\n    \n    // Doƒüru context'i koy - deep copy ile\n    actualOutput._context = JSON.parse(JSON.stringify(unifiedData._context));\n    \n    console.log(\"‚úÖ Context replaced with correct one\");\n  }\n} else {\n  console.log(\"‚ùå No context found, adding...\");\n  actualOutput._context = JSON.parse(JSON.stringify(unifiedData._context));\n}\n\n// Debug'ƒ± da d√ºzelt\nif (actualOutput._debug) {\n  const debugString = JSON.stringify(actualOutput._debug);\n  if (debugString.includes(\"{{\") || debugString.includes(\"$json\") || \n      actualOutput._debug.contextId !== unifiedData._context.contextId) {\n    \n    actualOutput._debug.contextId = unifiedData._context.contextId;\n    actualOutput._debug.contextFixed = true;\n    actualOutput._debug.fixedAt = new Date().toISOString();\n    actualOutput._debug.receivedFromSource = unifiedData.source.type;\n    actualOutput._debug.priority = unifiedData.priority;\n  }\n}\n\n// Context'i ba≈ülat\nif (!actualOutput._context.stageResults) {\n  actualOutput._context.stageResults = {};\n}\n\n// Stage 1 sonu√ßlarƒ±nƒ± context'e kaydet - sadece bu stage'in verisi\nactualOutput._context.stageResults.stage1 = {\n  output: {\n    overall_status: actualOutput.overall_status,\n    alerts: actualOutput.alerts,\n    scores: actualOutput.scores,\n    quick_findings: actualOutput.quick_findings,\n    active_services: actualOutput.active_services,\n    requested_services: actualOutput.requested_services,\n    proceed_to_stage2: actualOutput.proceed_to_stage2,\n    urgency: actualOutput.urgency,\n    reason: actualOutput.reason,\n    forceDeepAnalysis: actualOutput.forceDeepAnalysis,\n    overridden: actualOutput.overridden\n  },\n  completedAt: actualOutput._debug?.processedAt || new Date().toISOString(),\n  decision: actualOutput.proceed_to_stage2,\n  status: actualOutput.overall_status,\n  alerts: actualOutput.alerts?.total || 0\n};\n\n// Root level'a context bilgilerini ekle\nfixedOutput._context = JSON.parse(JSON.stringify(actualOutput._context));\nfixedOutput.contextId = unifiedData._context.contextId;\nfixedOutput._contextFixed = true;\nfixedOutput._fixedAt = new Date().toISOString();\n\n// ============= KB ENHANCEMENT INTEGRATION (NEW) =============\n// Add KB information to the context\nfixedOutput.knowledgeBase = {\n  alertCategory: kbAlertCategory,\n  urgencyLevel: kbUrgencyLevel,\n  cascadeRisk: kbCascadeRisk,\n  kbEntriesAvailable: kbEnhancedStats.kbEntriesLoaded,\n  categoriesSupported: kbEnhancedStats.totalCategories,\n  alertMappings: kbEnhancedStats.totalMappings,\n  enhancementVersion: \"KB-Enhanced-Full-v1.0\"\n};\n\n// Add KB to stage results\nif (!fixedOutput._context.stageResults) {\n  fixedOutput._context.stageResults = {};\n}\n\nfixedOutput._context.stageResults.stage1 = {\n  ...fixedOutput._context.stageResults.stage1,\n  kbEnhanced: kbEnhancedStats.kbEntriesLoaded > 0,\n  alertCategory: kbAlertCategory,\n  urgencyLevel: kbUrgencyLevel\n};\n\n// Stage 1 verilerini root'a ekle (kolay eri≈üim i√ßin)\nfixedOutput.stage1Data = {\n  overall_status: actualOutput.overall_status,\n  alerts: JSON.parse(JSON.stringify(actualOutput.alerts)),\n  scores: JSON.parse(JSON.stringify(actualOutput.scores)),\n  quick_findings: JSON.parse(JSON.stringify(actualOutput.quick_findings)),\n  active_services: JSON.parse(JSON.stringify(actualOutput.active_services || [])),\n  requested_services: JSON.parse(JSON.stringify(actualOutput.requested_services || [])),\n  proceed_to_stage2: actualOutput.proceed_to_stage2,\n  urgency: actualOutput.urgency,\n  reason: actualOutput.reason\n};\n\n// Validation\nconst contextFixed = actualOutput._context?.contextId === unifiedData._context.contextId;\nconst rootContextFixed = fixedOutput._context?.contextId === unifiedData._context.contextId;\n\nconsole.log(\"==============================\");\nconsole.log(\"Stage 1 Fix Summary:\");\nconsole.log(\"- Context ID:\", actualOutput._context?.contextId);\nconsole.log(\"- Proceed to stage 2:\", actualOutput.proceed_to_stage2);\nconsole.log(\"- Overall status:\", actualOutput.overall_status);\nconsole.log(\"- Total alerts:\", actualOutput.alerts?.total);\nconsole.log(\"- Context fixed:\", contextFixed && rootContextFixed);\n\nif (contextFixed && rootContextFixed) {\n  console.log(\"‚úÖ Context successfully fixed in both locations!\");\n} else {\n  console.error(\"‚ö†Ô∏è Context fix validation failed!\");\n}\n\n// ============= KB ENHANCEMENT SUMMARY (NEW) =============\nconsole.log(\"\\n===== STAGE 1 KB ENHANCEMENT SUMMARY =====\");\nconsole.log(\"KB Enhanced:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Loaded:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"Categories Supported:\", kbEnhancedStats.totalCategories);\nconsole.log(\"Alert Mappings:\", kbEnhancedStats.totalMappings);\nconsole.log(\"============================================\\n\");\n\n// Debug info for next stage\nfixedOutput._debugInfo = {\n  fromNode: \"Fix Stage 1 Context\",\n  contextFixed: true,\n  originalHadTemplates: JSON.stringify(stage1Output).includes(\"{{\"),\n  stage1Decision: actualOutput.proceed_to_stage2,\n  stage1Status: actualOutput.overall_status,\n  stage1Alerts: actualOutput.alerts?.total,\n  timestamp: new Date().toISOString()\n};\n\n// Pass the output wrapper if it existed\nif (hasOutputWrapper) {\n  fixedOutput.output = actualOutput;\n}\n\nreturn [{\n  json: fixedOutput\n}];"
      },
      "id": "e43739fa-f46d-4653-b168-2e007a45e84c",
      "name": "Fix Stage 1 Context",
      "type": "n8n-nodes-base.code",
      "position": [
        -2672,
        576
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED FIX STAGE 2 CONTEXT ================\n// This file preserves ALL original 814 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes (safely with error handling)\nlet alertCategoriesMapper = {};\nlet loadAlertKB = {};\nlet categoryMetricsBuilder = {};\n\ntry {\n  alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\n} catch(e) {\n  console.log(\"Alert Categories Mapper node not available yet\");\n}\n\ntry {\n  loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\n} catch(e) {\n  console.log(\"Load Alert Knowledge Base node not available yet\");\n}\n\ntry {\n  categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\n} catch(e) {\n  console.log(\"Category Based Metrics Builder node not available yet\");\n}\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS)\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst kbUrgencyLevel = deriveUrgencyLevel(alertCategoriesMapper.calculatedSeverityScore || 0);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || {};\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== STAGE 2 KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"==========================================\");\n\n// Fix Stage 2 Context - EXTENDED Root Cause Analysis for 150+ Alert Types\n// PRESERVES all existing logic, ADDS category-based root cause patterns\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// T√úm veriyi koru - deep copy ile circular reference √∂nleme\nlet output = JSON.parse(JSON.stringify(inputData));\n\n// Stage 2 output'u al (Fix Stage2 Json'dan gelen)\nconst stage2Output = output.output || {};\n\n// Force Deep Analysis Override'dan gelen orijinal data'yƒ± al\nlet previousData = null;\ntry {\n  previousData = $node[\"Force Deep Analysis Override\"].json;\n} catch(e) {\n  console.log(\"Previous data not found, using input context\");\n}\n\n// Previous context'i g√ºvenli ≈üekilde al\nconst previousContext = previousData?._context || output._context || {};\n\n// Alert category ve knowledge base bilgilerini al\nconst alertCategory = previousData?.alertCategory || output.alertCategory || 'UNKNOWN';\nconst alertName = previousContext.alertContext?.alertName || 'unknown';\nconst knowledgeBase = previousData?.knowledgeBase || output.knowledgeBase || {};\nconst categoryRootCausePatterns = previousData?.categoryRootCausePatterns || [];\n\nconsole.log(\"=== FIX STAGE 2 CONTEXT - EXTENDED ===\");\nconsole.log(\"Alert:\", alertName);\nconsole.log(\"Category:\", alertCategory);\nconsole.log(\"KB Enhanced:\", !!knowledgeBase.alert);\n\n// Stage 1 verilerini koru\nconst stage1Data = previousData?.stage1Data || {};\nconst stage1Results = previousData?.stage1Results || {};\n\n// ============= EXTENDED ROOT CAUSE EXTRACTION =============\nlet rootCause = {\n  identified: false,\n  component: \"\",\n  issue: \"\",\n  evidence: [],\n  confidence: 0,\n  category: alertCategory,\n  pattern_matched: null\n};\n\n// Stage 2 verilerinden temel analiz\nconst criticalPods = stage2Output.execution_phases?.instant?.findings?.critical_pods || [];\nconst resourcePressure = stage2Output.execution_phases?.instant?.findings?.resource_pressure || [];\nconst trendFindings = stage2Output.execution_phases?.trend?.findings || {};\nconst anomalies = stage2Output.execution_phases?.anomaly?.findings?.anomalies || [];\n\n// EXISTING ROOT CAUSE LOGIC (PRESERVED)\nif (criticalPods.length > 0) {\n  const pod = criticalPods[0];\n  \n  // Memory exhaustion pattern kontrol√º (EXISTING)\n  if (pod.resource_usage) {\n    let memoryBytes = 0;\n    let memoryDisplay = \"Unknown\";\n    \n    if (pod.resource_usage.memory_bytes && typeof pod.resource_usage.memory_bytes === 'number') {\n      memoryBytes = pod.resource_usage.memory_bytes;\n      memoryDisplay = `${(memoryBytes / 1073741824).toFixed(1)}GB`;\n    } else if (pod.resource_usage.memory && typeof pod.resource_usage.memory === 'string') {\n      const memoryStr = pod.resource_usage.memory;\n      if (memoryStr.includes(\"Gi\")) {\n        const memoryGB = parseFloat(memoryStr.replace(\"Gi\", \"\"));\n        memoryBytes = memoryGB * 1073741824;\n        memoryDisplay = `${memoryGB}GB`;\n      } else if (memoryStr.includes(\"Mi\")) {\n        const memoryMB = parseFloat(memoryStr.replace(\"Mi\", \"\"));\n        memoryBytes = memoryMB * 1048576;\n        memoryDisplay = `${(memoryMB / 1024).toFixed(1)}GB`;\n      }\n    }\n    \n    // EXISTING: Memory exhaustion pattern (5GB √ºzeri)\n    if (memoryBytes > 5000000000) {\n      rootCause = {\n        identified: true,\n        component: pod.pod_name,\n        issue: `Memory exhaustion causing OOMKilled - pod using ${memoryDisplay} memory`,\n        evidence: [\n          `Pod restart count: ${pod.restarts}`,\n          `Memory usage: ${memoryDisplay}`,\n          `Pod status: ${pod.status}`,\n          `Memory trend: ${trendFindings.memory_growth || 'increasing'}`,\n          `Restart pattern: ${trendFindings.restart_pattern || 'frequent restarts'}`\n        ],\n        confidence: 0.85,\n        category: alertCategory,\n        pattern_matched: 'memory_exhaustion',\n        kb_enhanced: false // Will be updated by KB validation\n      };\n    }\n    // EXISTING: CrashLoopBackOff pattern\n    else if (pod.status === \"CrashLoopBackOff\" && pod.restarts > 5) {\n      rootCause = {\n        identified: true,\n        component: pod.pod_name,\n        issue: `Pod in CrashLoopBackOff with ${pod.restarts} restarts - likely configuration or dependency issue`,\n        evidence: [\n          `Restart count: ${pod.restarts}`,\n          `Pod status: ${pod.status}`,\n          `Memory usage: ${memoryDisplay}`,\n          `CPU usage: ${pod.resource_usage?.cpu || 'Unknown'}`,\n          `Namespace: ${pod.namespace}`\n        ],\n        confidence: 0.75,\n        category: alertCategory,\n        pattern_matched: 'crashloop_backoff'\n      };\n    }\n  }\n}\n\n// ============= NEW: CATEGORY-SPECIFIC ROOT CAUSE PATTERNS =============\nif (!rootCause.identified && alertCategory !== 'UNKNOWN') {\n  console.log(\"Applying category-specific root cause patterns for:\", alertCategory);\n  \n  // Category-specific pattern matching\n  switch(alertCategory) {\n    case 'INFRASTRUCTURE':\n      rootCause = analyzeInfrastructureIssues(stage2Output, resourcePressure, anomalies);\n      break;\n      \n    case 'POD':\n      rootCause = analyzePodIssues(criticalPods, trendFindings, alertName);\n      break;\n      \n    case 'WORKLOAD':\n      rootCause = analyzeWorkloadIssues(stage2Output, trendFindings);\n      break;\n      \n    case 'RESOURCE':\n      rootCause = analyzeResourceIssues(stage2Output, resourcePressure, anomalies);\n      break;\n      \n    case 'NETWORK':\n      rootCause = analyzeNetworkIssues(stage2Output, anomalies);\n      break;\n      \n    case 'ETCD':\n      rootCause = analyzeEtcdIssues(stage2Output, trendFindings);\n      break;\n      \n    case 'CERTIFICATE':\n      rootCause = analyzeCertificateIssues(stage2Output);\n      break;\n      \n    case 'CLUSTER':\n      rootCause = analyzeClusterIssues(stage2Output, anomalies);\n      break;\n      \n    case 'MONITORING':\n      rootCause = analyzeMonitoringIssues(stage2Output);\n      break;\n      \n    case 'APPLICATION':\n      rootCause = analyzeApplicationIssues(stage2Output, trendFindings, anomalies);\n      break;\n  }\n}\n\n// ============= KB VALIDATION AND ENHANCEMENT (NEW) =============\n// Validate root cause against Knowledge Base and enhance confidence\nconst currentAlert = alertName || previousContext.alertContext?.alertName || 'unknown';\nconst kbEntry = kbAlertKnowledgeBase[currentAlert];\n\nif (kbEntry && rootCause.identified) {\n  // Check if the identified root cause matches KB common causes\n  const kbCauses = kbEntry.commonCauses || [];\n  const rootCauseText = rootCause.issue.toLowerCase();\n  \n  // Look for KB pattern matches\n  const hasKBMatch = kbCauses.some(cause => \n    rootCauseText.includes(cause.toLowerCase()) || \n    cause.toLowerCase().includes(rootCause.pattern_matched || '')\n  );\n  \n  if (hasKBMatch) {\n    // Boost confidence when KB validates the root cause\n    rootCause.confidence = Math.min(rootCause.confidence + 0.1, 0.95);\n    rootCause.kb_enhanced = true;\n    rootCause.kb_validation = \"KB confirmed root cause pattern\";\n    \n    console.log(\"‚úÖ KB validated root cause:\", rootCause.issue);\n    console.log(\"KB causes matched:\", kbCauses.filter(c => \n      rootCauseText.includes(c.toLowerCase()) || \n      c.toLowerCase().includes(rootCause.pattern_matched || '')\n    ));\n  }\n  \n  // Add KB troubleshooting steps as additional evidence\n  if (kbEntry.troubleshootingSteps && kbEntry.troubleshootingSteps.length > 0) {\n    rootCause.evidence.push(`KB recommends: ${kbEntry.troubleshootingSteps[0]}`);\n  }\n}\n\n// ============= CATEGORY-SPECIFIC ANALYSIS FUNCTIONS =============\n\nfunction analyzeInfrastructureIssues(stage2Data, resourcePressure, anomalies) {\n  // Check for node pressure conditions\n  if (resourcePressure.length > 0) {\n    const node = resourcePressure[0];\n    if (node.memory_usage && parseFloat(node.memory_usage) > 90) {\n      return {\n        identified: true,\n        component: node.node,\n        issue: `Node memory pressure - ${node.memory_usage} usage`,\n        evidence: [\n          `Node: ${node.node}`,\n          `Memory usage: ${node.memory_usage}`,\n          `CPU usage: ${node.cpu_usage || 'Unknown'}`,\n          `Pod count: ${node.pod_count || 'Unknown'}`,\n          `Anomalies: ${anomalies.join(', ') || 'None'}`\n        ],\n        confidence: 0.9,\n        category: 'INFRASTRUCTURE',\n        pattern_matched: 'node_memory_pressure'\n      };\n    }\n    if (node.disk_usage && parseFloat(node.disk_usage) > 85) {\n      return {\n        identified: true,\n        component: node.node,\n        issue: `Node disk pressure - ${node.disk_usage} usage`,\n        evidence: [\n          `Node: ${node.node}`,\n          `Disk usage: ${node.disk_usage}`,\n          `Available space: ${node.disk_available || 'Unknown'}`,\n          `Filesystem: ${node.filesystem || '/'}`\n        ],\n        confidence: 0.9,\n        category: 'INFRASTRUCTURE',\n        pattern_matched: 'node_disk_pressure'\n      };\n    }\n  }\n  \n  // Check for network issues\n  const networkIssues = stage2Data.execution_phases?.instant?.findings?.network_issues || [];\n  if (networkIssues.length > 0) {\n    return {\n      identified: true,\n      component: networkIssues[0].node || 'cluster',\n      issue: 'Node network connectivity issues detected',\n      evidence: networkIssues.map(n => `${n.node}: ${n.issue}`),\n      confidence: 0.8,\n      category: 'INFRASTRUCTURE',\n      pattern_matched: 'network_connectivity'\n    };\n  }\n  \n  return { identified: false, category: 'INFRASTRUCTURE' };\n}\n\nfunction analyzePodIssues(criticalPods, trendFindings, alertName) {\n  if (criticalPods.length === 0) {\n    return { identified: false, category: 'POD' };\n  }\n  \n  const pod = criticalPods[0];\n  \n  // Image pull issues\n  if (pod.status === 'ImagePullBackOff' || pod.status === 'ErrImagePull') {\n    return {\n      identified: true,\n      component: pod.pod_name,\n      issue: `Image pull failure - ${pod.status}`,\n      evidence: [\n        `Pod: ${pod.pod_name}`,\n        `Status: ${pod.status}`,\n        `Image: ${pod.image || 'Unknown'}`,\n        `Error: ${pod.error_message || 'Check pod events'}`\n      ],\n      confidence: 0.95,\n      category: 'POD',\n      pattern_matched: 'image_pull_error'\n    };\n  }\n  \n  // Init container failures\n  if (pod.init_container_status === 'Failed' || alertName.includes('InitContainer')) {\n    return {\n      identified: true,\n      component: pod.pod_name,\n      issue: 'Init container failure preventing pod startup',\n      evidence: [\n        `Pod: ${pod.pod_name}`,\n        `Init container status: ${pod.init_container_status || 'Failed'}`,\n        `Exit code: ${pod.init_exit_code || 'Unknown'}`\n      ],\n      confidence: 0.9,\n      category: 'POD',\n      pattern_matched: 'init_container_failure'\n    };\n  }\n  \n  // Liveness probe failures\n  if (pod.liveness_probe_failures > 3 || pod.status === 'Unhealthy') {\n    return {\n      identified: true,\n      component: pod.pod_name,\n      issue: 'Liveness probe failures causing restarts',\n      evidence: [\n        `Pod: ${pod.pod_name}`,\n        `Liveness probe failures: ${pod.liveness_probe_failures || 'Multiple'}`,\n        `Restart count: ${pod.restarts || 0}`,\n        `Last probe result: ${pod.last_probe_result || 'Failed'}`\n      ],\n      confidence: 0.85,\n      category: 'POD',\n      pattern_matched: 'liveness_probe_failure'\n    };\n  }\n  \n  return { identified: false, category: 'POD' };\n}\n\nfunction analyzeWorkloadIssues(stage2Data, trendFindings) {\n  const workloadFindings = stage2Data.execution_phases?.instant?.findings?.workload_issues || [];\n  \n  // HPA maxed out\n  const hpaStatus = workloadFindings.find(w => w.type === 'hpa_maxed');\n  if (hpaStatus) {\n    return {\n      identified: true,\n      component: hpaStatus.deployment || 'unknown-deployment',\n      issue: 'HPA at maximum replicas - cannot scale further',\n      evidence: [\n        `Deployment: ${hpaStatus.deployment}`,\n        `Current replicas: ${hpaStatus.current_replicas}`,\n        `Max replicas: ${hpaStatus.max_replicas}`,\n        `CPU utilization: ${hpaStatus.cpu_utilization || 'Unknown'}`,\n        `Scaling trend: ${trendFindings.scaling_pattern || 'Unknown'}`\n      ],\n      confidence: 0.9,\n      category: 'WORKLOAD',\n      pattern_matched: 'hpa_maxed_out'\n    };\n  }\n  \n  // Replica mismatch\n  const replicaIssue = workloadFindings.find(w => w.type === 'replica_mismatch');\n  if (replicaIssue) {\n    return {\n      identified: true,\n      component: replicaIssue.deployment || 'unknown-deployment',\n      issue: `Deployment replica mismatch - ${replicaIssue.available}/${replicaIssue.desired} available`,\n      evidence: [\n        `Deployment: ${replicaIssue.deployment}`,\n        `Desired replicas: ${replicaIssue.desired}`,\n        `Available replicas: ${replicaIssue.available}`,\n        `Reason: ${replicaIssue.reason || 'Unknown'}`\n      ],\n      confidence: 0.85,\n      category: 'WORKLOAD',\n      pattern_matched: 'replica_mismatch'\n    };\n  }\n  \n  return { identified: false, category: 'WORKLOAD' };\n}\n\nfunction analyzeResourceIssues(stage2Data, resourcePressure, anomalies) {\n  const resourceFindings = stage2Data.execution_phases?.instant?.findings?.resource_issues || [];\n  \n  // PVC filling up\n  const pvcIssue = resourceFindings.find(r => r.type === 'pvc_filling');\n  if (pvcIssue) {\n    return {\n      identified: true,\n      component: pvcIssue.pvc_name || 'unknown-pvc',\n      issue: `Persistent volume filling up - ${pvcIssue.usage_percent}% used`,\n      evidence: [\n        `PVC: ${pvcIssue.pvc_name}`,\n        `Usage: ${pvcIssue.usage_percent}%`,\n        `Available: ${pvcIssue.available_space || 'Unknown'}`,\n        `Growth rate: ${pvcIssue.growth_rate || 'Unknown'}`\n      ],\n      confidence: 0.9,\n      category: 'RESOURCE',\n      pattern_matched: 'pvc_filling_up'\n    };\n  }\n  \n  // Quota exceeded\n  const quotaIssue = resourceFindings.find(r => r.type === 'quota_exceeded');\n  if (quotaIssue) {\n    return {\n      identified: true,\n      component: quotaIssue.namespace || 'unknown-namespace',\n      issue: `Resource quota exceeded in namespace`,\n      evidence: [\n        `Namespace: ${quotaIssue.namespace}`,\n        `Resource: ${quotaIssue.resource_type}`,\n        `Used: ${quotaIssue.used}`,\n        `Limit: ${quotaIssue.limit}`\n      ],\n      confidence: 0.95,\n      category: 'RESOURCE',\n      pattern_matched: 'quota_exceeded'\n    };\n  }\n  \n  return { identified: false, category: 'RESOURCE' };\n}\n\nfunction analyzeNetworkIssues(stage2Data, anomalies) {\n  const networkFindings = stage2Data.execution_phases?.instant?.findings?.network_issues || [];\n  \n  // Service endpoint down\n  const endpointIssue = networkFindings.find(n => n.type === 'endpoint_down');\n  if (endpointIssue) {\n    return {\n      identified: true,\n      component: endpointIssue.service || 'unknown-service',\n      issue: 'Service endpoints unavailable',\n      evidence: [\n        `Service: ${endpointIssue.service}`,\n        `Available endpoints: ${endpointIssue.available_endpoints || 0}`,\n        `Expected endpoints: ${endpointIssue.expected_endpoints || 'Unknown'}`,\n        `Last seen: ${endpointIssue.last_seen || 'Never'}`\n      ],\n      confidence: 0.9,\n      category: 'NETWORK',\n      pattern_matched: 'endpoint_down'\n    };\n  }\n  \n  // DNS issues\n  const dnsIssue = networkFindings.find(n => n.type === 'dns_failure');\n  if (dnsIssue) {\n    return {\n      identified: true,\n      component: 'coredns',\n      issue: 'DNS resolution failures detected',\n      evidence: [\n        `Failed queries: ${dnsIssue.failed_queries || 'Multiple'}`,\n        `Error rate: ${dnsIssue.error_rate || 'Unknown'}`,\n        `Affected services: ${dnsIssue.affected_services?.join(', ') || 'Unknown'}`\n      ],\n      confidence: 0.85,\n      category: 'NETWORK',\n      pattern_matched: 'dns_failure'\n    };\n  }\n  \n  return { identified: false, category: 'NETWORK' };\n}\n\nfunction analyzeEtcdIssues(stage2Data, trendFindings) {\n  const etcdFindings = stage2Data.execution_phases?.instant?.findings?.etcd_status || {};\n  \n  // No leader\n  if (etcdFindings.has_leader === false || etcdFindings.leader_changes > 5) {\n    return {\n      identified: true,\n      component: 'etcd-cluster',\n      issue: 'ETCD cluster leadership issues',\n      evidence: [\n        `Has leader: ${etcdFindings.has_leader || 'false'}`,\n        `Leader changes: ${etcdFindings.leader_changes || 'Multiple'}`,\n        `Member count: ${etcdFindings.member_count || 'Unknown'}`,\n        `Cluster ID: ${etcdFindings.cluster_id || 'Unknown'}`\n      ],\n      confidence: 0.95,\n      category: 'ETCD',\n      pattern_matched: 'etcd_no_leader'\n    };\n  }\n  \n  // High fsync duration\n  if (etcdFindings.fsync_duration_ms > 100) {\n    return {\n      identified: true,\n      component: 'etcd-cluster',\n      issue: `ETCD disk latency issues - fsync ${etcdFindings.fsync_duration_ms}ms`,\n      evidence: [\n        `Fsync duration: ${etcdFindings.fsync_duration_ms}ms`,\n        `Backend commit duration: ${etcdFindings.backend_commit_ms || 'Unknown'}ms`,\n        `WAL fsync duration: ${etcdFindings.wal_fsync_ms || 'Unknown'}ms`\n      ],\n      confidence: 0.9,\n      category: 'ETCD',\n      pattern_matched: 'etcd_disk_latency'\n    };\n  }\n  \n  return { identified: false, category: 'ETCD' };\n}\n\nfunction analyzeCertificateIssues(stage2Data) {\n  const certFindings = stage2Data.execution_phases?.instant?.findings?.certificate_status || {};\n  \n  if (certFindings.expiring_soon || certFindings.days_until_expiry < 30) {\n    return {\n      identified: true,\n      component: certFindings.certificate_name || 'cluster-certificate',\n      issue: `Certificate expiring in ${certFindings.days_until_expiry || 'Unknown'} days`,\n      evidence: [\n        `Certificate: ${certFindings.certificate_name || 'Unknown'}`,\n        `Days until expiry: ${certFindings.days_until_expiry || 'Unknown'}`,\n        `Issuer: ${certFindings.issuer || 'Unknown'}`,\n        `Auto-rotation: ${certFindings.auto_rotation_enabled || 'Unknown'}`\n      ],\n      confidence: 0.99,\n      category: 'CERTIFICATE',\n      pattern_matched: 'cert_expiring'\n    };\n  }\n  \n  return { identified: false, category: 'CERTIFICATE' };\n}\n\nfunction analyzeClusterIssues(stage2Data, anomalies) {\n  const clusterFindings = stage2Data.execution_phases?.instant?.findings?.cluster_status || {};\n  \n  // API server issues\n  if (clusterFindings.api_latency_ms > 1000 || clusterFindings.api_errors > 100) {\n    return {\n      identified: true,\n      component: 'kube-apiserver',\n      issue: 'API server performance degradation',\n      evidence: [\n        `API latency: ${clusterFindings.api_latency_ms || 'Unknown'}ms`,\n        `Error count: ${clusterFindings.api_errors || 'Unknown'}`,\n        `Request rate: ${clusterFindings.request_rate || 'Unknown'}/s`,\n        `Throttled requests: ${clusterFindings.throttled_requests || 'Unknown'}`\n      ],\n      confidence: 0.85,\n      category: 'CLUSTER',\n      pattern_matched: 'api_server_degradation'\n    };\n  }\n  \n  // Scheduler issues\n  if (clusterFindings.unschedulable_pods > 0) {\n    return {\n      identified: true,\n      component: 'kube-scheduler',\n      issue: `Scheduler unable to place ${clusterFindings.unschedulable_pods} pods`,\n      evidence: [\n        `Unschedulable pods: ${clusterFindings.unschedulable_pods}`,\n        `Scheduling attempts: ${clusterFindings.scheduling_attempts || 'Unknown'}`,\n        `Binding failures: ${clusterFindings.binding_failures || 'Unknown'}`\n      ],\n      confidence: 0.9,\n      category: 'CLUSTER',\n      pattern_matched: 'scheduler_failure'\n    };\n  }\n  \n  return { identified: false, category: 'CLUSTER' };\n}\n\nfunction analyzeMonitoringIssues(stage2Data) {\n  const monitoringFindings = stage2Data.execution_phases?.instant?.findings?.monitoring_status || {};\n  \n  if (monitoringFindings.scrape_failures > 10 || monitoringFindings.targets_down > 0) {\n    return {\n      identified: true,\n      component: 'prometheus',\n      issue: 'Monitoring system degradation',\n      evidence: [\n        `Scrape failures: ${monitoringFindings.scrape_failures || 'Unknown'}`,\n        `Targets down: ${monitoringFindings.targets_down || 'Unknown'}`,\n        `TSDB errors: ${monitoringFindings.tsdb_errors || 'Unknown'}`,\n        `Rule failures: ${monitoringFindings.rule_failures || 'Unknown'}`\n      ],\n      confidence: 0.8,\n      category: 'MONITORING',\n      pattern_matched: 'monitoring_degradation'\n    };\n  }\n  \n  return { identified: false, category: 'MONITORING' };\n}\n\nfunction analyzeApplicationIssues(stage2Data, trendFindings, anomalies) {\n  const appFindings = stage2Data.execution_phases?.instant?.findings?.application_metrics || {};\n  \n  // High error rate\n  if (appFindings.error_rate > 1 || appFindings.http_5xx_rate > 0.5) {\n    return {\n      identified: true,\n      component: appFindings.service || 'application',\n      issue: `High application error rate - ${appFindings.error_rate || appFindings.http_5xx_rate}%`,\n      evidence: [\n        `Service: ${appFindings.service || 'Unknown'}`,\n        `Error rate: ${appFindings.error_rate || 'Unknown'}%`,\n        `5xx rate: ${appFindings.http_5xx_rate || 'Unknown'}%`,\n        `Request rate: ${appFindings.request_rate || 'Unknown'}/s`,\n        `Trend: ${trendFindings.error_trend || 'Unknown'}`\n      ],\n      confidence: 0.85,\n      category: 'APPLICATION',\n      pattern_matched: 'high_error_rate'\n    };\n  }\n  \n  // Latency issues\n  if (appFindings.p99_latency_ms > 1000) {\n    return {\n      identified: true,\n      component: appFindings.service || 'application',\n      issue: `High application latency - P99: ${appFindings.p99_latency_ms}ms`,\n      evidence: [\n        `Service: ${appFindings.service || 'Unknown'}`,\n        `P99 latency: ${appFindings.p99_latency_ms}ms`,\n        `P95 latency: ${appFindings.p95_latency_ms || 'Unknown'}ms`,\n        `P50 latency: ${appFindings.p50_latency_ms || 'Unknown'}ms`\n      ],\n      confidence: 0.8,\n      category: 'APPLICATION',\n      pattern_matched: 'high_latency'\n    };\n  }\n  \n  return { identified: false, category: 'APPLICATION' };\n}\n\n// ============= KNOWLEDGE BASE ENHANCEMENT =============\nif (!rootCause.identified && knowledgeBase.alert) {\n  // Try to match with knowledge base patterns\n  const kbCauses = knowledgeBase.alert.commonCauses || [];\n  const metrics = knowledgeBase.alert.requiredMetrics || [];\n  \n  console.log(\"Attempting KB-based root cause identification\");\n  \n  // Look for KB pattern matches in Stage 2 findings\n  if (kbCauses.includes('Memory leak in application') && criticalPods.length > 0) {\n    const pod = criticalPods[0];\n    if (trendFindings.memory_growth === 'increasing' || pod.restarts > 3) {\n      rootCause = {\n        identified: true,\n        component: pod.pod_name,\n        issue: 'Suspected memory leak based on KB pattern',\n        evidence: [\n          `KB Pattern: Memory leak in application`,\n          `Memory trend: ${trendFindings.memory_growth || 'increasing'}`,\n          `Pod restarts: ${pod.restarts || 0}`,\n          `Alert: ${alertName}`\n        ],\n        confidence: 0.7,\n        category: alertCategory,\n        pattern_matched: 'kb_memory_leak'\n      };\n    }\n  }\n}\n\n// ============= AFFECTED SERVICES UPDATE =============\nconst stage1Services = previousContext.initialParams?.services || [];\nconst stage2Services = stage2Output.correlation_matrix?.affected_services || [];\nconst allAffectedServices = [...new Set([...stage1Services, ...stage2Services])];\n\n// ============= CASCADING EFFECT ANALYSIS (ENHANCED) =============\nconst cascadingEffects = {\n  hasCascadingFailures: false,\n  affectedComponents: [],\n  spreadPattern: \"isolated\",\n  cascadeCategory: alertCategory\n};\n\n// Category-based cascade risk assessment\nconst CASCADE_RISK_MATRIX = {\n  'INFRASTRUCTURE': { risk: 'CRITICAL', spread: 'node-wide' },\n  'ETCD': { risk: 'CRITICAL', spread: 'cluster-wide' },\n  'CERTIFICATE': { risk: 'CRITICAL', spread: 'cluster-wide' },\n  'NETWORK': { risk: 'HIGH', spread: 'service-mesh' },\n  'CLUSTER': { risk: 'HIGH', spread: 'cluster-wide' },\n  'RESOURCE': { risk: 'MEDIUM', spread: 'namespace' },\n  'WORKLOAD': { risk: 'MEDIUM', spread: 'deployment' },\n  'POD': { risk: 'LOW', spread: 'pod-local' },\n  'APPLICATION': { risk: 'LOW', spread: 'service' },\n  'MONITORING': { risk: 'LOW', spread: 'monitoring-only' },\n  'UNKNOWN': { risk: 'MEDIUM', spread: 'unknown' }\n};\n\nconst cascadeRisk = CASCADE_RISK_MATRIX[alertCategory] || CASCADE_RISK_MATRIX['UNKNOWN'];\n\nif (cascadeRisk.risk === 'CRITICAL' || cascadeRisk.risk === 'HIGH') {\n  cascadingEffects.hasCascadingFailures = true;\n  cascadingEffects.spreadPattern = cascadeRisk.spread;\n  cascadingEffects.affectedComponents = allAffectedServices;\n}\n\n// Check Stage 1 findings for cascade indicators\nconst quickFindings = stage1Data.quick_findings || stage1Results.quick_findings || [];\nif (quickFindings.some(f => f.includes(\"cluster degraded\") || f.includes(\"multiple\"))) {\n  cascadingEffects.hasCascadingFailures = true;\n  if (cascadingEffects.spreadPattern === \"isolated\") {\n    cascadingEffects.spreadPattern = \"spreading\";\n  }\n}\n\n// ============= PROCEED DECISION (ENHANCED) =============\nconst priority = previousContext.priority || output._context?.priority || 'normal';\nconst shouldProceedToStage3 = \n  rootCause.identified || \n  priority === 'critical' ||\n  priority === 'high' ||\n  cascadingEffects.hasCascadingFailures ||\n  (previousContext.stageConfig?.maxStages || 0) >= 3 ||\n  stage1Results.alerts?.total > 10 ||\n  alertCategory === 'ETCD' ||\n  alertCategory === 'INFRASTRUCTURE' ||\n  alertCategory === 'CERTIFICATE';\n\n// ============= OUTPUT PREPARATION (ENHANCED) =============\nconst updatedStage2Output = {\n  stage: stage2Output.stage || \"deep_analysis\",\n  investigation_id: stage2Output.investigation_id,\n  execution_phases: JSON.parse(JSON.stringify(stage2Output.execution_phases || {})),\n  correlation_matrix: {\n    primary_chain: stage2Output.correlation_matrix?.primary_chain || cascadeRisk.spread,\n    affected_services: allAffectedServices,\n    blast_radius: stage2Output.correlation_matrix?.blast_radius || cascadeRisk.spread,\n    kubernetes_impact: {\n      evicted_pods: stage2Output.correlation_matrix?.kubernetes_impact?.evicted_pods || 0,\n      pending_pods: stage2Output.correlation_matrix?.kubernetes_impact?.pending_pods || 0,\n      failed_schedules: stage2Output.correlation_matrix?.kubernetes_impact?.failed_schedules || 0\n    }\n  },\n  root_cause: rootCause,\n  cascading_effects: cascadingEffects,\n  proceed_to_stage3: shouldProceedToStage3,\n  alert_correlation_needed: shouldProceedToStage3,\n  triggered_by: `Stage 1: ${stage1Results.alerts?.total || 0} alerts, Status: ${stage1Results.overall_status || 'unknown'}`,\n  alert_category: alertCategory,\n  knowledge_base_enhanced: !!knowledgeBase.alert\n};\n\n// Debug bilgisini g√ºncelle\nupdatedStage2Output._debug = {\n  nodeType: \"Stage 2: Deep Analysis\",\n  processedAt: new Date().toISOString(),\n  contextId: previousContext.contextId || output._context?.contextId,\n  contextPreserved: true,\n  receivedFromStage: \"Fix Stage2 Json\",\n  stageSequence: [\n    ...(previousData?._debug?.stageSequence || []),\n    \"Fix Stage 2 Context\"\n  ],\n  rootCauseExtracted: rootCause.identified,\n  cascadingDetected: cascadingEffects.hasCascadingFailures,\n  alertCategory: alertCategory,\n  patternMatched: rootCause.pattern_matched,\n  timeRangeUsed: {\n    start: previousContext.initialParams?.startTime || 0,\n    end: previousContext.initialParams?.endTime || 0\n  }\n};\n\n// Context'i g√ºncelle\nconst updatedContext = {\n  contextId: previousContext.contextId,\n  createdAt: previousContext.createdAt,\n  source: previousContext.source,\n  initialParams: JSON.parse(JSON.stringify(previousContext.initialParams || {})),\n  kubernetesFilters: JSON.parse(JSON.stringify(previousContext.kubernetesFilters || {})),\n  alertContext: JSON.parse(JSON.stringify(previousContext.alertContext || {})),\n  stageConfig: JSON.parse(JSON.stringify(previousContext.stageConfig || {})),\n  priority: priority,\n  forceDeepAnalysis: previousContext.forceDeepAnalysis,\n  workflowMetadata: JSON.parse(JSON.stringify(previousContext.workflowMetadata || {})),\n  alertCategory: alertCategory,\n  alertEnrichment: previousContext.alertEnrichment,\n  stageResults: {\n    ...JSON.parse(JSON.stringify(previousContext.stageResults || {})),\n    stage2: {\n      output: {\n        root_cause: rootCause,\n        affected_services: allAffectedServices,\n        cascading_effects: cascadingEffects,\n        critical_pods: criticalPods.length,\n        kubernetes_impact: updatedStage2Output.correlation_matrix.kubernetes_impact,\n        alert_category: alertCategory\n      },\n      completedAt: new Date().toISOString(),\n      decision: shouldProceedToStage3,\n      rootCauseIdentified: rootCause.identified\n    }\n  },\n  decisions: {\n    ...JSON.parse(JSON.stringify(previousContext.decisions || {})),\n    stage3Proceed: {\n      timestamp: new Date().toISOString(),\n      shouldProceed: shouldProceedToStage3,\n      reason: rootCause.identified ? \"Root cause identified\" : \n              cascadingEffects.hasCascadingFailures ? \"Cascading failures detected\" :\n              \"Priority or category requires full analysis\"\n    }\n  }\n};\n\n// Final output\noutput = {\n  output: updatedStage2Output,\n  _context: updatedContext,\n  \n  // Stage verilerini koru (Stage 3 i√ßin)\n  stage1Data: JSON.parse(JSON.stringify(stage1Data)),\n  stage2Data: {\n    root_cause: rootCause,\n    affected_services: allAffectedServices,\n    critical_pods: criticalPods,\n    cascading_effects: cascadingEffects,\n    correlation_matrix: updatedStage2Output.correlation_matrix,\n    alert_category: alertCategory\n  },\n  \n  // Alert bilgilerini aktar\n  alertInfo: {\n    alertName: previousContext.alertContext?.alertName,\n    pod: previousContext.kubernetesFilters?.pod,\n    namespace: previousContext.kubernetesFilters?.namespace,\n    priority: priority,\n    category: alertCategory\n  },\n  \n  // ============= KB ENHANCEMENT DATA (NEW) =============\n  knowledgeBase: {\n    alertCategory: kbAlertCategory,\n    urgencyLevel: kbUrgencyLevel,\n    cascadeRisk: kbCascadeRisk,\n    kbEntriesAvailable: kbEnhancedStats.kbEntriesLoaded,\n    rootCauseKBValidated: rootCause.kb_enhanced || false,\n    enhancementVersion: \"KB-Enhanced-Full-v1.0\"\n  },\n  \n  // Category analysis metadata\n  categoryAnalysis: {\n    category: alertCategory,\n    cascadeRisk: cascadeRisk,\n    patternMatched: rootCause.pattern_matched,\n    confidence: rootCause.confidence\n  },\n  \n  // Proceed flag\n  proceedToStage3: shouldProceedToStage3\n};\n\n// Logging\nconsole.log(\"=== FIX STAGE 2 CONTEXT - EXTENDED COMPLETE ===\");\nconsole.log(\"Alert Category:\", alertCategory);\nconsole.log(\"Root Cause Identified:\", rootCause.identified);\nconsole.log(\"Pattern Matched:\", rootCause.pattern_matched);\nconsole.log(\"Issue:\", rootCause.issue);\nconsole.log(\"Cascade Risk:\", cascadeRisk.risk);\nconsole.log(\"Affected Services:\", allAffectedServices.length);\nconsole.log(\"Proceed to Stage 3:\", shouldProceedToStage3);\nconsole.log(\"Context Preserved:\", !!updatedContext.contextId);\n\n// ============= KB ENHANCEMENT SUMMARY (NEW) =============\nconsole.log(\"\\n===== STAGE 2 KB ENHANCEMENT SUMMARY =====\");\nconsole.log(\"KB Enhanced:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category (KB):\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"Root Cause KB Validated:\", rootCause.kb_enhanced || false);\nconsole.log(\"Root Cause Confidence:\", `${Math.round((rootCause.confidence || 0) * 100)}%`);\nconsole.log(\"KB Validation:\", rootCause.kb_validation || \"No KB match\");\nconsole.log(\"============================================\\n\");\n\nreturn [output];"
      },
      "id": "ba714712-caf9-4612-987c-6f171ad68479",
      "name": "Fix Stage 2 Context",
      "type": "n8n-nodes-base.code",
      "position": [
        -1088,
        560
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED FIX STAGE 4 CONTEXT ================\n// This file preserves ALL original 980 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes (safely with error handling)\nlet alertCategoriesMapper = {};\nlet loadAlertKB = {};\nlet categoryMetricsBuilder = {};\n\ntry {\n  alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\n} catch(e) {\n  console.log(\"Alert Categories Mapper node not available yet\");\n}\n\ntry {\n  loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\n} catch(e) {\n  console.log(\"Load Alert Knowledge Base node not available yet\");\n}\n\ntry {\n  categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\n} catch(e) {\n  console.log(\"Category Based Metrics Builder node not available yet\");\n}\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS)\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst kbUrgencyLevel = deriveUrgencyLevel(alertCategoriesMapper.calculatedSeverityScore || 0);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || {};\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== STAGE 4 KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"==========================================\");\n\n// Fix Stage 4 Context - EXTENDED Diagnostic Commands for 150+ Alert Types\n// PRESERVES all existing logic, ADDS category-based diagnostic enhancements\n\nconst stage4Output = $input.first().json;\n\n// Stage 3'ten gelen context'i al\nlet stage3Data;\nlet previousContext;\n\ntry {\n  stage3Data = $node[\"Fix Stage 3 Context1\"].json;\n  previousContext = stage3Data._context;\n  \n  console.log(\"‚úÖ Got context from Stage 3:\", previousContext?.contextId);\n  console.log(\"Stage 1 data available:\", !!stage3Data.stage1Data);\n  console.log(\"Stage 2 data available:\", !!stage3Data.stage2Data);\n  console.log(\"Stage 3 data available:\", !!stage3Data.stage3Data);\n} catch (e) {\n  console.error(\"‚ùå Error getting Stage 3 data:\", e);\n  previousContext = stage4Output._context || {\n    contextId: \"ctx-emergency-\" + Date.now()\n  };\n}\n\n// Get alert category and other metadata\nconst alertCategory = stage3Data?.alertInfo?.category || \n                      stage3Data?.stage2Data?.alert_category || \n                      stage3Data?.stage3Data?.alert_category || \n                      'UNKNOWN';\n\nconst alertName = stage3Data?.alertInfo?.alertName || \n                 previousContext?.alertContext?.alertName || \n                 'unknown';\n\nconst rootCause = stage3Data?.stage2Data?.root_cause || {};\nconst correlationGroups = stage3Data?.stage3Data?.alert_groups || [];\n\nconsole.log(\"=== FIXING STAGE 4 CONTEXT - EXTENDED ===\");\nconsole.log(\"Alert:\", alertName);\nconsole.log(\"Category:\", alertCategory);\nconsole.log(\"Root Cause:\", rootCause.identified ? rootCause.issue : 'Not identified');\nconsole.log(\"Previous context ID:\", previousContext?.contextId);\n\n// Deep copy\nlet fixedOutput = JSON.parse(JSON.stringify(stage4Output));\n\n// Output wrapper kontrol√º\nconst hasOutputWrapper = !!fixedOutput.output;\nconst actualOutput = hasOutputWrapper ? fixedOutput.output : fixedOutput;\n\nconsole.log(\"Has output wrapper:\", hasOutputWrapper);\n\n// ============= CATEGORY-BASED DIAGNOSTIC COMMANDS =============\nconst CATEGORY_DIAGNOSTICS = {\n  'INFRASTRUCTURE': {\n    commands: [\n      {\n        name: 'node_status',\n        command: (filters) => `kubectl get node ${filters.node || '$(kubectl get nodes -o name | head -1)'} -o yaml`,\n        parser: 'parseNodeStatus',\n        priority: 1\n      },\n      {\n        name: 'node_describe',\n        command: (filters) => `kubectl describe node ${filters.node || '$(kubectl get nodes -o name | head -1)'}`,\n        parser: 'parseNodeDescribe',\n        priority: 1\n      },\n      {\n        name: 'node_metrics',\n        command: (filters) => `kubectl top node ${filters.node || ''}`,\n        parser: 'parseNodeMetrics',\n        priority: 2\n      },\n      {\n        name: 'node_pods',\n        command: (filters) => `kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=${filters.node || '$(kubectl get nodes -o name | head -1)'}`,\n        parser: 'parseNodePods',\n        priority: 2\n      },\n      {\n        name: 'system_logs',\n        command: (filters) => `kubectl logs -n kube-system -l component=kubelet --tail=50`,\n        parser: 'parseSystemLogs',\n        priority: 3\n      }\n    ],\n    focus: 'node health and resource utilization'\n  },\n  \n  'POD': {\n    commands: [\n      {\n        name: 'pod_describe',\n        command: (filters) => `kubectl describe pod ${filters.pod} -n ${filters.namespace || 'default'}`,\n        parser: 'parsePodDescribe',\n        priority: 1\n      },\n      {\n        name: 'pod_logs',\n        command: (filters) => `kubectl logs ${filters.pod} -n ${filters.namespace || 'default'} --tail=100`,\n        parser: 'parsePodLogs',\n        priority: 1\n      },\n      {\n        name: 'pod_logs_previous',\n        command: (filters) => `kubectl logs ${filters.pod} -n ${filters.namespace || 'default'} --previous --tail=100`,\n        parser: 'parsePodLogs',\n        priority: 2\n      },\n      {\n        name: 'pod_events',\n        command: (filters) => `kubectl get events -n ${filters.namespace || 'default'} --field-selector involvedObject.name=${filters.pod} --sort-by='.lastTimestamp'`,\n        parser: 'parsePodEvents',\n        priority: 1\n      },\n      {\n        name: 'pod_metrics',\n        command: (filters) => `kubectl top pod ${filters.pod} -n ${filters.namespace || 'default'}`,\n        parser: 'parsePodMetrics',\n        priority: 2\n      }\n    ],\n    focus: 'pod lifecycle and container status'\n  },\n  \n  'WORKLOAD': {\n    commands: [\n      {\n        name: 'deployment_status',\n        command: (filters) => `kubectl get deployment ${filters.deployment || filters.pod?.split('-')[0]} -n ${filters.namespace || 'default'} -o yaml`,\n        parser: 'parseDeploymentStatus',\n        priority: 1\n      },\n      {\n        name: 'deployment_rollout',\n        command: (filters) => `kubectl rollout status deployment/${filters.deployment || filters.pod?.split('-')[0]} -n ${filters.namespace || 'default'}`,\n        parser: 'parseRolloutStatus',\n        priority: 1\n      },\n      {\n        name: 'replica_sets',\n        command: (filters) => `kubectl get rs -n ${filters.namespace || 'default'} -l app=${filters.deployment || filters.service}`,\n        parser: 'parseReplicaSets',\n        priority: 2\n      },\n      {\n        name: 'hpa_status',\n        command: (filters) => `kubectl get hpa -n ${filters.namespace || 'default'}`,\n        parser: 'parseHPAStatus',\n        priority: 2\n      },\n      {\n        name: 'deployment_events',\n        command: (filters) => `kubectl get events -n ${filters.namespace || 'default'} --field-selector involvedObject.kind=Deployment`,\n        parser: 'parseDeploymentEvents',\n        priority: 3\n      }\n    ],\n    focus: 'deployment and scaling status'\n  },\n  \n  'RESOURCE': {\n    commands: [\n      {\n        name: 'resource_quota',\n        command: (filters) => `kubectl describe resourcequota -n ${filters.namespace || 'default'}`,\n        parser: 'parseResourceQuota',\n        priority: 1\n      },\n      {\n        name: 'limit_ranges',\n        command: (filters) => `kubectl describe limitrange -n ${filters.namespace || 'default'}`,\n        parser: 'parseLimitRanges',\n        priority: 2\n      },\n      {\n        name: 'pvc_status',\n        command: (filters) => `kubectl get pvc -n ${filters.namespace || 'default'} -o wide`,\n        parser: 'parsePVCStatus',\n        priority: 1\n      },\n      {\n        name: 'pv_status',\n        command: (filters) => `kubectl get pv -o wide`,\n        parser: 'parsePVStatus',\n        priority: 2\n      },\n      {\n        name: 'namespace_resources',\n        command: (filters) => `kubectl top pods -n ${filters.namespace || 'default'} --sum`,\n        parser: 'parseNamespaceResources',\n        priority: 1\n      }\n    ],\n    focus: 'resource quotas and persistent volumes'\n  },\n  \n  'NETWORK': {\n    commands: [\n      {\n        name: 'service_endpoints',\n        command: (filters) => `kubectl get endpoints ${filters.service || ''} -n ${filters.namespace || 'default'} -o yaml`,\n        parser: 'parseEndpoints',\n        priority: 1\n      },\n      {\n        name: 'service_status',\n        command: (filters) => `kubectl get service ${filters.service || ''} -n ${filters.namespace || 'default'} -o yaml`,\n        parser: 'parseServiceStatus',\n        priority: 1\n      },\n      {\n        name: 'network_policies',\n        command: (filters) => `kubectl get networkpolicies -n ${filters.namespace || 'default'} -o yaml`,\n        parser: 'parseNetworkPolicies',\n        priority: 2\n      },\n      {\n        name: 'ingress_status',\n        command: (filters) => `kubectl get ingress -n ${filters.namespace || 'default'} -o wide`,\n        parser: 'parseIngressStatus',\n        priority: 2\n      },\n      {\n        name: 'dns_test',\n        command: (filters) => `kubectl run -it --rm debug-dns --image=busybox --restart=Never -- nslookup kubernetes.default`,\n        parser: 'parseDNSTest',\n        priority: 3\n      }\n    ],\n    focus: 'service connectivity and network policies'\n  },\n  \n  'ETCD': {\n    commands: [\n      {\n        name: 'etcd_member_list',\n        command: () => `kubectl exec -n kube-system etcd-0 -- etcdctl member list`,\n        parser: 'parseEtcdMembers',\n        priority: 1\n      },\n      {\n        name: 'etcd_endpoint_health',\n        command: () => `kubectl exec -n kube-system etcd-0 -- etcdctl endpoint health`,\n        parser: 'parseEtcdHealth',\n        priority: 1\n      },\n      {\n        name: 'etcd_endpoint_status',\n        command: () => `kubectl exec -n kube-system etcd-0 -- etcdctl endpoint status --write-out=table`,\n        parser: 'parseEtcdStatus',\n        priority: 1\n      },\n      {\n        name: 'etcd_alarm_list',\n        command: () => `kubectl exec -n kube-system etcd-0 -- etcdctl alarm list`,\n        parser: 'parseEtcdAlarms',\n        priority: 2\n      },\n      {\n        name: 'etcd_metrics',\n        command: () => `kubectl exec -n kube-system etcd-0 -- etcdctl check perf`,\n        parser: 'parseEtcdPerf',\n        priority: 3\n      }\n    ],\n    focus: 'etcd cluster health and consensus'\n  },\n  \n  'CERTIFICATE': {\n    commands: [\n      {\n        name: 'certificate_list',\n        command: () => `kubectl get csr -o wide`,\n        parser: 'parseCSRList',\n        priority: 1\n      },\n      {\n        name: 'certificate_details',\n        command: () => `kubectl get csr -o yaml`,\n        parser: 'parseCSRDetails',\n        priority: 1\n      },\n      {\n        name: 'kubeadm_certs',\n        command: () => `kubectl exec -n kube-system -it $(kubectl get pods -n kube-system -l component=kube-apiserver -o name | head -1) -- kubeadm certs check-expiration`,\n        parser: 'parseKubeadmCerts',\n        priority: 1\n      },\n      {\n        name: 'secret_certs',\n        command: (filters) => `kubectl get secrets -n ${filters.namespace || 'kube-system'} -o json | jq '.items[] | select(.type==\"kubernetes.io/tls\") | {name: .metadata.name, cert: .data.\"tls.crt\"}'`,\n        parser: 'parseSecretCerts',\n        priority: 2\n      }\n    ],\n    focus: 'certificate expiration and rotation'\n  },\n  \n  'CLUSTER': {\n    commands: [\n      {\n        name: 'component_status',\n        command: () => `kubectl get cs`,\n        parser: 'parseComponentStatus',\n        priority: 1\n      },\n      {\n        name: 'api_server_health',\n        command: () => `kubectl get --raw /healthz?verbose`,\n        parser: 'parseAPIHealth',\n        priority: 1\n      },\n      {\n        name: 'cluster_info',\n        command: () => `kubectl cluster-info dump --output-directory=/tmp/cluster-dump && cat /tmp/cluster-dump/kube-system/kube-apiserver*/kube-apiserver.log | tail -50`,\n        parser: 'parseClusterInfo',\n        priority: 2\n      },\n      {\n        name: 'scheduler_logs',\n        command: () => `kubectl logs -n kube-system -l component=kube-scheduler --tail=50`,\n        parser: 'parseSchedulerLogs',\n        priority: 2\n      },\n      {\n        name: 'controller_logs',\n        command: () => `kubectl logs -n kube-system -l component=kube-controller-manager --tail=50`,\n        parser: 'parseControllerLogs',\n        priority: 2\n      }\n    ],\n    focus: 'control plane components health'\n  },\n  \n  'MONITORING': {\n    commands: [\n      {\n        name: 'prometheus_targets',\n        command: () => `kubectl port-forward -n monitoring svc/prometheus 9090:9090 & sleep 2 && curl -s http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job: .job, health: .health}'`,\n        parser: 'parsePrometheusTargets',\n        priority: 1\n      },\n      {\n        name: 'prometheus_config',\n        command: () => `kubectl get configmap -n monitoring prometheus-config -o yaml`,\n        parser: 'parsePrometheusConfig',\n        priority: 2\n      },\n      {\n        name: 'alertmanager_status',\n        command: () => `kubectl logs -n monitoring -l app=alertmanager --tail=50`,\n        parser: 'parseAlertmanagerLogs',\n        priority: 2\n      },\n      {\n        name: 'monitoring_pods',\n        command: () => `kubectl get pods -n monitoring -o wide`,\n        parser: 'parseMonitoringPods',\n        priority: 1\n      }\n    ],\n    focus: 'monitoring stack health'\n  },\n  \n  'APPLICATION': {\n    commands: [\n      {\n        name: 'app_logs',\n        command: (filters) => `kubectl logs -n ${filters.namespace || 'default'} -l app=${filters.service || filters.deployment} --tail=100`,\n        parser: 'parseAppLogs',\n        priority: 1\n      },\n      {\n        name: 'app_describe',\n        command: (filters) => `kubectl describe deployment ${filters.deployment || filters.service} -n ${filters.namespace || 'default'}`,\n        parser: 'parseAppDescribe',\n        priority: 1\n      },\n      {\n        name: 'app_configmap',\n        command: (filters) => `kubectl get configmap -n ${filters.namespace || 'default'} -l app=${filters.service || filters.deployment}`,\n        parser: 'parseAppConfig',\n        priority: 2\n      },\n      {\n        name: 'app_secrets',\n        command: (filters) => `kubectl get secrets -n ${filters.namespace || 'default'} -l app=${filters.service || filters.deployment} -o name`,\n        parser: 'parseAppSecrets',\n        priority: 3\n      },\n      {\n        name: 'app_metrics',\n        command: (filters) => `kubectl top pods -n ${filters.namespace || 'default'} -l app=${filters.service || filters.deployment}`,\n        parser: 'parseAppMetrics',\n        priority: 2\n      }\n    ],\n    focus: 'application logs and configuration'\n  },\n  \n  'UNKNOWN': {\n    commands: [\n      {\n        name: 'general_pod_status',\n        command: (filters) => `kubectl get pods -n ${filters.namespace || 'default'} -o wide`,\n        parser: 'parseGeneralPodStatus',\n        priority: 1\n      },\n      {\n        name: 'general_events',\n        command: (filters) => `kubectl get events -n ${filters.namespace || 'default'} --sort-by='.lastTimestamp' | tail -20`,\n        parser: 'parseGeneralEvents',\n        priority: 1\n      },\n      {\n        name: 'general_describe',\n        command: (filters) => filters.pod ? `kubectl describe pod ${filters.pod} -n ${filters.namespace || 'default'}` : `kubectl get all -n ${filters.namespace || 'default'}`,\n        parser: 'parseGeneralDescribe',\n        priority: 2\n      }\n    ],\n    focus: 'general diagnostics'\n  }\n};\n\n// ============= BUILD DIAGNOSTIC COMMANDS =============\nfunction buildDiagnosticCommands(category, filters, rootCause, correlationGroups) {\n  const categoryDiagnostics = CATEGORY_DIAGNOSTICS[category] || CATEGORY_DIAGNOSTICS['UNKNOWN'];\n  const commands = [];\n  \n  // ============= KB DIAGNOSTIC COMMANDS (NEW) =============\n  // Add KB diagnostic commands if available\n  const currentAlert = filters.alertName || previousContext?.alertContext?.alertName || 'unknown';\n  const kbEntry = kbAlertKnowledgeBase[currentAlert];\n  \n  if (kbEntry && kbEntry.troubleshootingSteps && kbEntry.troubleshootingSteps.length > 0) {\n    console.log(\"‚úÖ Adding KB diagnostic commands for\", currentAlert);\n    \n    kbEntry.troubleshootingSteps.slice(0, 3).forEach((step, index) => {\n      // Replace placeholders in KB commands\n      let command = step;\n      if (filters.namespace && command.includes('{namespace}')) {\n        command = command.replace(/{namespace}/g, filters.namespace);\n      }\n      if (filters.deployment && command.includes('{deployment}')) {\n        command = command.replace(/{deployment}/g, filters.deployment);\n      }\n      if (filters.pod && command.includes('{pod}')) {\n        command = command.replace(/{pod}/g, filters.pod);\n      }\n      \n      commands.push({\n        command: command,\n        parser: 'kubectl_output',\n        type: `KB_DIAGNOSTIC_${index + 1}`,\n        priority: 'high',\n        source: 'Knowledge Base',\n        kb_enhanced: true,\n        description: `KB recommended diagnostic: ${step.substring(0, 50)}...`\n      });\n    });\n  }\n  \n  // Add category-specific commands\n  categoryDiagnostics.commands.forEach(cmd => {\n    commands.push({\n      command: typeof cmd.command === 'function' ? cmd.command(filters) : cmd.command,\n      parser: cmd.parser,\n      type: cmd.name,\n      priority: cmd.priority,\n      category: category\n    });\n  });\n  \n  // Add root cause specific commands\n  if (rootCause.identified) {\n    const rootCauseCommands = getRootCauseSpecificCommands(rootCause, filters);\n    commands.push(...rootCauseCommands);\n  }\n  \n  // Add correlation-based commands\n  if (correlationGroups.length > 0) {\n    const correlationCommands = getCorrelationCommands(correlationGroups, filters);\n    commands.push(...correlationCommands);\n  }\n  \n  // Sort by priority\n  commands.sort((a, b) => (a.priority || 99) - (b.priority || 99));\n  \n  // Limit to top 10 commands to avoid overload\n  return commands.slice(0, 10);\n}\n\n// Helper function - Root cause specific commands\nfunction getRootCauseSpecificCommands(rootCause, filters) {\n  const commands = [];\n  \n  if (rootCause.pattern_matched === 'memory_exhaustion' || rootCause.pattern_matched === 'oom_killed') {\n    commands.push({\n      command: `kubectl exec ${filters.pod} -n ${filters.namespace || 'default'} -- cat /proc/meminfo 2>/dev/null || echo \"Cannot access container\"`,\n      parser: 'parseMemInfo',\n      type: 'memory_analysis',\n      priority: 1,\n      category: 'ROOT_CAUSE'\n    });\n  }\n  \n  if (rootCause.pattern_matched === 'crashloop_backoff') {\n    commands.push({\n      command: `kubectl get pod ${filters.pod} -n ${filters.namespace || 'default'} -o jsonpath='{.status.containerStatuses[*].lastState.terminated}'`,\n      parser: 'parseTerminationReason',\n      type: 'crash_analysis',\n      priority: 1,\n      category: 'ROOT_CAUSE'\n    });\n  }\n  \n  if (rootCause.pattern_matched === 'node_pressure') {\n    commands.push({\n      command: `kubectl get nodes -o jsonpath='{range .items[*]}{.metadata.name}{\" \"}{.status.conditions[?(@.type==\"MemoryPressure\")].status}{\" \"}{.status.conditions[?(@.type==\"DiskPressure\")].status}{\"\\\\n\"}{end}'`,\n      parser: 'parseNodePressure',\n      type: 'pressure_analysis',\n      priority: 1,\n      category: 'ROOT_CAUSE'\n    });\n  }\n  \n  return commands;\n}\n\n// Helper function - Correlation-based commands\nfunction getCorrelationCommands(correlationGroups, filters) {\n  const commands = [];\n  \n  correlationGroups.forEach(group => {\n    if (group.category === 'ROOT_CAUSE_CORRELATION' && group.shared_labels?.component) {\n      commands.push({\n        command: `kubectl get pods --all-namespaces -o wide | grep ${group.shared_labels.component}`,\n        parser: 'parseRelatedPods',\n        type: 'correlation_check',\n        priority: 3,\n        category: 'CORRELATION'\n      });\n    }\n  });\n  \n  return commands;\n}\n\n// ============= MOCK DATA DETECTION AND CLEANUP =============\nif (actualOutput.diagnostics_executed && actualOutput.diagnostics_executed.length > 0) {\n  const diagnostic = actualOutput.diagnostics_executed[0];\n  \n  if (diagnostic.target && \n      (diagnostic.target.includes('payment-service') || \n       diagnostic.target === 'pod-abc123' ||\n       diagnostic.target.includes('user-auth-service'))) {\n    \n    console.warn(\"‚ö†Ô∏è MOCK DATA DETECTED! Replacing with actual data...\");\n    \n    const actualRootCause = stage3Data?.stage2Data?.root_cause || {};\n    const actualAffectedServices = stage3Data?.stage2Data?.affected_services || [];\n    const criticalPods = stage3Data?.stage2Data?.critical_pods || [];\n    \n    let actualTarget = criticalPods[0] || actualRootCause.component || \"unknown-pod\";\n    \n    if (typeof actualTarget === 'object' && actualTarget.name) {\n      actualTarget = actualTarget.name;\n    }\n    \n    const actualNamespace = stage3Data?.namespaces?.[0] || \n                           previousContext?.initialParams?.namespaces?.[0] || \n                           'etiyamobile-production';\n    \n    // Get filters for diagnostic commands\n    const kubernetesFilters = previousContext?.kubernetesFilters || {\n      namespace: actualNamespace,\n      pod: actualTarget,\n      service: actualAffectedServices[0] || '',\n      deployment: actualTarget.split('-').slice(0, -2).join('-') || '',\n      node: criticalPods[0]?.node || ''\n    };\n    \n    // Build category-specific diagnostic commands\n    const diagnosticCommands = buildDiagnosticCommands(\n      alertCategory,\n      kubernetesFilters,\n      actualRootCause,\n      correlationGroups\n    );\n    \n    actualOutput.diagnostics_executed = [{\n      target: actualTarget,\n      type: \"comprehensive\",\n      category: alertCategory,\n      commands_run: diagnosticCommands.map(cmd => cmd.command),\n      command_details: diagnosticCommands,\n      findings: {\n        pod_status: {\n          phase: actualRootCause.issue?.includes('CrashLoopBackOff') ? 'CrashLoopBackOff' : \n                 actualRootCause.issue?.includes('restart') ? 'Running' : 'Unknown',\n          restart_count: parseInt(actualRootCause.evidence?.[1]?.match(/\\d+/)?.[0]) || 5,\n          last_termination: {\n            reason: actualRootCause.issue?.includes('OOM') ? 'OOMKilled' : \n                   actualRootCause.issue?.includes('CrashLoopBackOff') ? 'Error' : 'Unknown',\n            exit_code: actualRootCause.issue?.includes('OOM') ? 137 : 1,\n            finished_at: new Date().toISOString()\n          }\n        },\n        error_logs: [],\n        events: [{\n          type: \"Warning\",\n          reason: actualRootCause.issue?.includes('OOM') ? 'OOMKilled' : 'BackOff',\n          message: actualRootCause.evidence?.[0] || \"Container failing\",\n          timestamp: new Date().toISOString()\n        }],\n        resource_usage: {\n          memory_request: \"512Mi\",\n          memory_limit: \"1024Mi\",\n          memory_used: \"950Mi\",\n          cpu_used: \"0.85\"\n        },\n        category_specific: {\n          category: alertCategory,\n          focus: CATEGORY_DIAGNOSTICS[alertCategory]?.focus || 'general diagnostics',\n          commands_executed: diagnosticCommands.length,\n          priority_commands: diagnosticCommands.filter(c => c.priority === 1).length\n        }\n      }\n    }];\n    \n    actualOutput.enriched_context = {\n      ...actualOutput.enriched_context,\n      deployment_info: {\n        name: actualTarget.split('-').slice(0, -2).join('-') || \"unknown-deployment\",\n        namespace: actualNamespace,\n        version: \"unknown\",\n        replicas: \"unknown\",\n        last_update: new Date().toISOString(),\n        update_strategy: \"RollingUpdate\"\n      },\n      dependencies: {\n        upstream: [],\n        downstream: actualAffectedServices.filter(s => s !== actualNamespace),\n        databases: [],\n        external: []\n      },\n      diagnostic_metadata: {\n        category: alertCategory,\n        total_commands: diagnosticCommands.length,\n        command_categories: [...new Set(diagnosticCommands.map(c => c.category))],\n        root_cause_specific: diagnosticCommands.filter(c => c.category === 'ROOT_CAUSE').length > 0,\n        correlation_based: diagnosticCommands.filter(c => c.category === 'CORRELATION').length > 0\n      }\n    };\n    \n    actualOutput.diagnostic_summary = {\n      confirmed_issues: [{\n        issue: actualRootCause.issue || \"Resource exhaustion leading to pod restarts\",\n        evidence: actualRootCause.evidence || [\n          \"Pod restart count: 5\",\n          \"Memory usage: 950Mi out of 1024Mi limit\",\n          \"Container instability detected\"\n        ],\n        severity: \"critical\",\n        impact: `Service ${actualTarget} is experiencing issues`,\n        namespace: actualNamespace,\n        category: alertCategory,\n        diagnostic_focus: CATEGORY_DIAGNOSTICS[alertCategory]?.focus\n      }],\n      secondary_issues: [],\n      diagnostic_coverage: {\n        commands_executed: diagnosticCommands.length,\n        categories_covered: [...new Set(diagnosticCommands.map(c => c.category))],\n        priority_1_commands: diagnosticCommands.filter(c => c.priority === 1).length,\n        root_cause_targeted: diagnosticCommands.some(c => c.category === 'ROOT_CAUSE')\n      }\n    };\n    \n    console.log(\"‚úÖ Mock data replaced with actual data and category-specific diagnostics\");\n  }\n} else {\n  // No diagnostics executed yet, build them now\n  console.log(\"Building diagnostic commands for category:\", alertCategory);\n  \n  const kubernetesFilters = previousContext?.kubernetesFilters || {\n    namespace: stage3Data?.namespaces?.[0] || 'default',\n    pod: stage3Data?.stage2Data?.critical_pods?.[0]?.pod_name || '',\n    service: stage3Data?.stage2Data?.affected_services?.[0] || '',\n    deployment: '',\n    node: stage3Data?.stage2Data?.critical_pods?.[0]?.node || ''\n  };\n  \n  const diagnosticCommands = buildDiagnosticCommands(\n    alertCategory,\n    kubernetesFilters,\n    rootCause,\n    correlationGroups\n  );\n  \n  actualOutput.diagnostics_executed = [{\n    target: kubernetesFilters.pod || kubernetesFilters.node || 'cluster',\n    type: \"category-based\",\n    category: alertCategory,\n    commands_run: diagnosticCommands.map(cmd => cmd.command),\n    command_details: diagnosticCommands,\n    findings: {\n      diagnostic_metadata: {\n        category: alertCategory,\n        focus: CATEGORY_DIAGNOSTICS[alertCategory]?.focus,\n        commands_prepared: diagnosticCommands.length\n      }\n    }\n  }];\n}\n\n// ============= KB DIAGNOSTIC INTEGRATION (ENHANCED) =============\nconst stage3KBMatches = stage3Data?.stage3Data?.knowledge_base_matches || [];\nconst stage3Alerts = stage3Data?.stage3Data?.active_alerts || [];\n\nif (stage3KBMatches.length > 0 && actualOutput.diagnostics_executed) {\n  console.log(\"=== KB DIAGNOSTIC INTEGRATION ===\");\n  console.log(\"KB matches:\", stage3KBMatches.length);\n  \n  stage3KBMatches.forEach((kbMatch, idx) => {\n    if (idx < actualOutput.diagnostics_executed.length) {\n      const diagnosticEntry = actualOutput.diagnostics_executed[idx];\n      \n      diagnosticEntry.kb_enhanced = true;\n      diagnosticEntry.kb_severity = kbMatch.kb_entry?.severity || \"Medium\";\n      diagnosticEntry.kb_category = kbMatch.category || alertCategory;\n      \n      // Add KB diagnostic commands if available\n      if (kbMatch.kb_entry?.diagnostic_commands && Array.isArray(kbMatch.kb_entry.diagnostic_commands)) {\n        const kbCommands = kbMatch.kb_entry.diagnostic_commands.map(cmd => ({\n          command: cmd,\n          parser: 'parseKBCommand',\n          type: 'kb_diagnostic',\n          priority: 2,\n          category: 'KB_RECOMMENDED'\n        }));\n        \n        // Merge with existing commands\n        if (diagnosticEntry.command_details) {\n          diagnosticEntry.command_details.push(...kbCommands);\n        } else {\n          diagnosticEntry.command_details = kbCommands;\n        }\n        \n        diagnosticEntry.commands_run.push(...kbCommands.map(c => c.command));\n      }\n      \n      if (!diagnosticEntry.findings.kb_analysis) {\n        diagnosticEntry.findings.kb_analysis = {\n          alert_type: kbMatch.alert,\n          severity: kbMatch.kb_entry?.severity,\n          category: kbMatch.category,\n          possible_root_causes: kbMatch.kb_entry?.root_causes || [],\n          diagnostic_guidance: kbMatch.kb_entry?.diagnostic_commands || [],\n          immediate_actions: kbMatch.kb_entry?.immediate_actions || []\n        };\n      }\n    }\n  });\n  \n  console.log(\"‚úÖ KB diagnostic enhancement complete\");\n}\n\n// Update enriched context KB analysis\nif (!actualOutput.enriched_context.kb_analysis) {\n  actualOutput.enriched_context.kb_analysis = {\n    alerts_matched: stage3KBMatches.map(m => ({\n      alert: m.alert,\n      severity: m.kb_entry?.severity || \"Unknown\",\n      category: m.category || alertCategory\n    })),\n    diagnostic_coverage: stage3KBMatches.length,\n    remediation_available: stage3KBMatches.filter(m => \n      m.kb_entry?.immediate_actions?.length > 0).length,\n    highest_severity: stage3KBMatches.reduce((max, m) => {\n      const severityOrder = { \"Blocker\": 5, \"Critical\": 4, \"High\": 3, \"Medium\": 2, \"Low\": 1 };\n      return severityOrder[m.kb_entry?.severity] > severityOrder[max] ? \n             m.kb_entry?.severity : max;\n    }, \"Low\"),\n    categories_covered: [...new Set(stage3KBMatches.map(m => m.category || alertCategory))]\n  };\n}\n\n// ============= CONTEXT FIX =============\nconst expectedContextId = previousContext?.contextId;\n\nif (!actualOutput._context || \n    actualOutput._context.contextId !== expectedContextId ||\n    actualOutput._context.contextId === \"abc123\") {\n    \n  console.log(\"‚ùå Invalid or missing context, fixing...\");\n  \n  const contextCopy = JSON.parse(JSON.stringify(previousContext));\n  \n  if (!contextCopy.stageResults) {\n    contextCopy.stageResults = {};\n  }\n  \n  actualOutput._context = contextCopy;\n  console.log(\"‚úÖ Context replaced\");\n}\n\n// Ensure stageResults exists\nif (!actualOutput._context.stageResults) {\n  actualOutput._context.stageResults = {};\n}\n\n// Add Stage 4 results\nactualOutput._context.stageResults.stage4 = {\n  output: {\n    diagnostics_executed: JSON.parse(JSON.stringify(actualOutput.diagnostics_executed)),\n    enriched_context: JSON.parse(JSON.stringify(actualOutput.enriched_context)),\n    diagnostic_summary: JSON.parse(JSON.stringify(actualOutput.diagnostic_summary)),\n    proceed_to_stage5: actualOutput.proceed_to_stage5,\n    remediation_confidence: actualOutput.remediation_confidence,\n    alert_category: alertCategory,\n    diagnostic_category: alertCategory\n  },\n  completedAt: new Date().toISOString(),\n  decision: actualOutput.proceed_to_stage5,\n  primaryIssue: actualOutput.diagnostic_summary?.confirmed_issues?.[0]?.issue\n};\n\n// Update debug info\nactualOutput._debug = {\n  nodeType: \"Stage 4: Automated Diagnosis\",\n  processedAt: actualOutput._debug?.processedAt || new Date().toISOString(),\n  contextId: expectedContextId,\n  contextPreserved: true,\n  receivedFromStage: \"Fix Stage 3 Context\",\n  priority: previousContext?.priority || \"normal\",\n  alertCategory: alertCategory,\n  stageSequence: [\n    \"Unified Entry Point\",\n    \"Stage 1: Health Snapshot\", \n    \"Fix Stage 1 Context\",\n    \"Stage 2 Decision\",\n    \"Force Deep Analysis Override\",\n    \"Wait 3s\",\n    \"Stage 2: Deep Analysis\",\n    \"Fix Stage 2 Context\",\n    \"Stage 3: Alert Intelligence\",\n    \"Fix Stage 3 Context\",\n    \"Stage 4: Automated Diagnosis\",\n    \"Fix Stage 4 Context\"\n  ],\n  diagnosticsCount: actualOutput.diagnostics_executed?.length || 0,\n  diagnosticCommands: actualOutput.diagnostics_executed?.[0]?.commands_run?.length || 0,\n  diagnosticCategories: [...new Set(actualOutput.diagnostics_executed?.[0]?.command_details?.map(c => c.category) || [])],\n  autoRemediationEnabled: true,\n  categoryDiagnostics: alertCategory,\n  timeRangeUsed: {\n    start: previousContext?.initialParams?.startTime || 0,\n    end: previousContext?.initialParams?.endTime || 0\n  }\n};\n\n// Update root level context\nfixedOutput._context = JSON.parse(JSON.stringify(actualOutput._context));\nfixedOutput.contextId = expectedContextId;\n\n// Stage 4 summary data\nfixedOutput.stage4Data = {\n  diagnostics_executed: JSON.parse(JSON.stringify(actualOutput.diagnostics_executed)),\n  enriched_context: JSON.parse(JSON.stringify(actualOutput.enriched_context)),\n  diagnostic_summary: JSON.parse(JSON.stringify(actualOutput.diagnostic_summary)),\n  confirmed_issues: actualOutput.diagnostic_summary?.confirmed_issues || [],\n  secondary_issues: actualOutput.diagnostic_summary?.secondary_issues || [],\n  remediation_confidence: actualOutput.remediation_confidence || 0,\n  proceed_to_stage5: actualOutput.proceed_to_stage5 || false,\n  kb_enhanced: actualOutput.diagnostics_executed?.some(d => d.kb_enhanced) || false,\n  primary_diagnosis: actualOutput.diagnostic_summary?.confirmed_issues?.[0] || null,\n  diagnostic_metadata: {\n    category: alertCategory,\n    total_commands: actualOutput.diagnostics_executed?.[0]?.commands_run?.length || 0,\n    kb_commands: actualOutput.diagnostics_executed?.[0]?.command_details?.filter(c => c.category === 'KB_RECOMMENDED').length || 0,\n    root_cause_commands: actualOutput.diagnostics_executed?.[0]?.command_details?.filter(c => c.category === 'ROOT_CAUSE').length || 0,\n    correlation_commands: actualOutput.diagnostics_executed?.[0]?.command_details?.filter(c => c.category === 'CORRELATION').length || 0\n  }\n};\n\n// Update decisions\nif (!actualOutput._context.decisions) {\n  actualOutput._context.decisions = previousContext?.decisions || {};\n}\n\nactualOutput._context.decisions.stage5Proceed = {\n  timestamp: new Date().toISOString(),\n  shouldProceed: actualOutput.proceed_to_stage5,\n  remediationConfidence: actualOutput.remediation_confidence,\n  confirmedIssuesCount: actualOutput.diagnostic_summary?.confirmed_issues?.length || 0,\n  primaryIssue: actualOutput.diagnostic_summary?.confirmed_issues?.[0]?.issue || \"unknown\",\n  diagnosticCategory: alertCategory\n};\n\n// Preserve all previous stage data\nif (stage3Data?.stage1Data) {\n  fixedOutput.stage1Data = JSON.parse(JSON.stringify(stage3Data.stage1Data));\n  console.log(\"‚úÖ Stage 1 data preserved (full copy)\");\n}\n\nif (stage3Data?.stage2Data) {\n  fixedOutput.stage2Data = JSON.parse(JSON.stringify(stage3Data.stage2Data));\n  console.log(\"‚úÖ Stage 2 data preserved (full copy)\");\n}\n\nif (stage3Data?.stage3Data) {\n  fixedOutput.stage3Data = JSON.parse(JSON.stringify(stage3Data.stage3Data));\n  console.log(\"‚úÖ Stage 3 data preserved (full copy)\");\n}\n\n// Consolidated findings for final summary\nfixedOutput.consolidatedFindings = {\n  healthStatus: fixedOutput.stage1Data?.overall_status || \"unknown\",\n  alertCount: fixedOutput.stage1Data?.alerts?.total || 0,\n  rootCause: fixedOutput.stage2Data?.root_cause || {},\n  affectedServices: fixedOutput.stage2Data?.affected_services || [],\n  activeAlerts: fixedOutput.stage3Data?.active_alerts || [],\n  confirmedIssues: actualOutput.diagnostic_summary?.confirmed_issues || [],\n  primaryDiagnosis: actualOutput.diagnostic_summary?.confirmed_issues?.[0] || null,\n  remediationConfidence: actualOutput.remediation_confidence || 0,\n  alertCategory: alertCategory,\n  diagnosticCoverage: fixedOutput.stage4Data.diagnostic_metadata\n};\n\n// Primary diagnosis for easy access\nif (actualOutput.diagnostic_summary?.confirmed_issues?.[0]) {\n  fixedOutput.primaryDiagnosis = {\n    ...actualOutput.diagnostic_summary.confirmed_issues[0],\n    stage: \"Stage 4\",\n    timestamp: new Date().toISOString(),\n    category: alertCategory\n  };\n}\n\n// Namespaces and time range\nfixedOutput.namespaces = previousContext?.initialParams?.namespaces || ['etiyamobile-production'];\nfixedOutput.timeRange = {\n  start: previousContext?.initialParams?.startTime || 0,\n  end: previousContext?.initialParams?.endTime || 0\n};\n\n// Alert category metadata\nfixedOutput.alertCategoryAnalysis = {\n  category: alertCategory,\n  diagnosticFocus: CATEGORY_DIAGNOSTICS[alertCategory]?.focus || 'general diagnostics',\n  commandsAvailable: CATEGORY_DIAGNOSTICS[alertCategory]?.commands.length || 0,\n  rootCausePattern: rootCause.pattern_matched || 'none',\n  correlationGroups: correlationGroups.length\n};\n\nconsole.log(\"==============================\");\nconsole.log(\"Stage 4 Fix Summary:\");\nconsole.log(\"- Context ID:\", actualOutput._context?.contextId);\nconsole.log(\"- Alert Category:\", alertCategory);\nconsole.log(\"- Diagnostics executed:\", actualOutput.diagnostics_executed?.length);\nconsole.log(\"- Total commands:\", actualOutput.diagnostics_executed?.[0]?.commands_run?.length);\nconsole.log(\"- Command categories:\", [...new Set(actualOutput.diagnostics_executed?.[0]?.command_details?.map(c => c.category) || [])]);\nconsole.log(\"- Confirmed issues:\", actualOutput.diagnostic_summary?.confirmed_issues?.length);\nconsole.log(\"- KB enhanced:\", fixedOutput.stage4Data?.kb_enhanced);\nconsole.log(\"- Proceed to Stage 5:\", actualOutput.proceed_to_stage5);\nconsole.log(\"- Previous stage data preserved:\");\nconsole.log(\"  * Stage 1:\", !!fixedOutput.stage1Data);\nconsole.log(\"  * Stage 2:\", !!fixedOutput.stage2Data);\nconsole.log(\"  * Stage 3:\", !!fixedOutput.stage3Data);\nconsole.log(\"  * Stage 4:\", !!fixedOutput.stage4Data);\nconsole.log(\"- All data is FULL COPY (no summarization)\");\n\n// Validation\nconst validationPassed = \n  actualOutput._context?.contextId === expectedContextId &&\n  !!fixedOutput.stage1Data &&\n  !!fixedOutput.stage2Data &&\n  !!fixedOutput.stage3Data &&\n  !!fixedOutput.stage4Data;\n\nif (validationPassed) {\n  console.log(\"‚úÖ Stage 4 context successfully fixed and validated!\");\n} else {\n  console.error(\"‚ö†Ô∏è Stage 4 validation warnings\");\n}\n\n// ============= KB ENHANCEMENT SUMMARY (NEW) =============\nconsole.log(\"\\n===== STAGE 4 KB ENHANCEMENT SUMMARY =====\");\nconsole.log(\"KB Enhanced:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category (KB):\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconst kbCommands = (actualOutput.diagnostics_executed?.[0]?.commands_run || []).filter(c => c.kb_enhanced);\nconsole.log(\"KB Diagnostic Commands:\", kbCommands.length, \"/\", actualOutput.diagnostics_executed?.[0]?.commands_run?.length || 0);\nconsole.log(\"KB Entries Loaded:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"============================================\\n\");\n\n// Debug info for next stage\nfixedOutput._debugInfo = {\n  fromNode: \"Fix Stage 4 Context\",\n  contextFixed: true,\n  validationPassed: validationPassed,\n  stage4DiagnosticsCount: actualOutput.diagnostics_executed?.length || 0,\n  stage4CommandsCount: actualOutput.diagnostics_executed?.[0]?.commands_run?.length || 0,\n  stage4Decision: actualOutput.proceed_to_stage5,\n  remediationConfidence: actualOutput.remediation_confidence,\n  primaryIssue: actualOutput.diagnostic_summary?.confirmed_issues?.[0]?.issue || \"unknown\",\n  alertCategory: alertCategory,\n  diagnosticCategories: [...new Set(actualOutput.diagnostics_executed?.[0]?.command_details?.map(c => c.category) || [])],\n  allStagesDataPresent: !!(fixedOutput.stage1Data && fixedOutput.stage2Data && \n                           fixedOutput.stage3Data && fixedOutput.stage4Data),\n  timestamp: new Date().toISOString()\n};\n\n// Pass the output wrapper if needed\nif (hasOutputWrapper) {\n  fixedOutput.output = actualOutput;\n}\n\nreturn [{\n  json: fixedOutput\n}];"
      },
      "id": "ee5d3b05-9afb-4f60-a54b-99d0a9bfcf74",
      "name": "Fix Stage 4 Context",
      "type": "n8n-nodes-base.code",
      "position": [
        0,
        544
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED FIX STAGE 5 CONTEXT ================\n// This file preserves ALL original 1156 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes (safely with error handling)\nlet alertCategoriesMapper = {};\nlet loadAlertKB = {};\nlet categoryMetricsBuilder = {};\n\ntry {\n  alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\n} catch(e) {\n  console.log(\"Alert Categories Mapper node not available yet\");\n}\n\ntry {\n  loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\n} catch(e) {\n  console.log(\"Load Alert Knowledge Base node not available yet\");\n}\n\ntry {\n  categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\n} catch(e) {\n  console.log(\"Category Based Metrics Builder node not available yet\");\n}\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS)\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst kbUrgencyLevel = deriveUrgencyLevel(alertCategoriesMapper.calculatedSeverityScore || 0);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || {};\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== STAGE 5 KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"==========================================\");\n\n// Fix Stage 5 Context - Optimized with Category-Based Remediation Templates\nconst stage5Output = $input.first().json;\n\n// √ñnceki stage'den context ve data'yƒ± al\nlet previousContext;\nlet stage4Data;\n\ntry {\n  stage4Data = $node[\"Fix Stage 4 Context\"].json;\n  previousContext = stage4Data._context;\n  \n  console.log(\"‚úÖ Got context from Stage 4:\", previousContext?.contextId);\n  console.log(\"Stage 1 data available:\", !!stage4Data.stage1Data);\n  console.log(\"Stage 2 data available:\", !!stage4Data.stage2Data);\n  console.log(\"Stage 3 data available:\", !!stage4Data.stage3Data);\n  console.log(\"Stage 4 data available:\", !!stage4Data.stage4Data);\n} catch (e) {\n  console.error(\"‚ùå Error getting Stage 4 data:\", e);\n  previousContext = {\n    contextId: \"ctx-emergency-\" + Date.now(),\n    createdAt: new Date().toISOString(),\n    stageResults: {},\n    decisions: {},\n    initialParams: {\n      startTime: Math.floor(Date.now() / 1000) - 3600,\n      endTime: Math.floor(Date.now() / 1000)\n    }\n  };\n}\n\n// Validate previousContext\nif (!previousContext || typeof previousContext !== 'object') {\n  console.error(\"‚ùå Invalid previousContext, creating new one\");\n  previousContext = {\n    contextId: \"ctx-recovery-\" + Date.now(),\n    createdAt: new Date().toISOString(),\n    stageResults: {},\n    decisions: {},\n    initialParams: {\n      startTime: Math.floor(Date.now() / 1000) - 3600,\n      endTime: Math.floor(Date.now() / 1000)\n    }\n  };\n}\n\n// Ensure stageResults exists\nif (!previousContext.stageResults) {\n  previousContext.stageResults = {};\n}\n\nconsole.log(\"=== FIXING STAGE 5 CONTEXT ===\");\nconsole.log(\"Previous context ID:\", previousContext?.contextId);\n\n// Deep copy\nlet fixedOutput = JSON.parse(JSON.stringify(stage5Output));\n\n// Output wrapper kontrol√º\nconst hasOutputWrapper = !!fixedOutput.output;\nlet actualOutput = hasOutputWrapper ? fixedOutput.output : fixedOutput;\n\nconsole.log(\"Has output wrapper:\", hasOutputWrapper);\n\n// String output handling\nif (typeof actualOutput === 'string') {\n  console.log(\"‚ö†Ô∏è Stage 5 output is string, attempting to parse...\");\n  \n  try {\n    let cleanOutput = actualOutput;\n    if (cleanOutput.includes('```json')) {\n      cleanOutput = cleanOutput.replace(/```json\\s*\\n?/g, '');\n      cleanOutput = cleanOutput.replace(/```\\s*$/g, '');\n    }\n    \n    if (cleanOutput.includes('{{') || cleanOutput.includes('$json')) {\n      console.log(\"‚ö†Ô∏è Stage 5 output contains templates, resolving...\");\n      \n      const context = previousContext;\n      const stage4Results = stage4Data?.stage4Data || {};\n      const primaryDiagnosis = stage4Data?.primaryDiagnosis || {};\n      \n      cleanOutput = cleanOutput\n        .replace(/\\{\\{ \\$json\\._context\\.contextId \\}\\}/g, context.contextId || 'unknown')\n        .replace(/\\{\\{ \\$json\\.stage4Results\\.enriched_context\\.deployment_info\\.name \\}\\}/g, \n          stage4Results?.enriched_context?.deployment_info?.name || 'unknown-deployment')\n        .replace(/\\{\\{ \\$json\\.primaryDiagnosis\\.namespace \\}\\}/g, \n          primaryDiagnosis?.namespace || 'default')\n        .replace(/\\{\\{ JSON\\.stringify\\(\\$json\\._context\\) \\}\\}/g, \n          JSON.stringify(context))\n        .replace(/\\{\\{ \\$json\\._context\\.initialParams\\.startTime \\}\\}/g, \n          context.initialParams?.startTime || 0)\n        .replace(/\\{\\{ \\$json\\._context\\.initialParams\\.endTime \\}\\}/g, \n          context.initialParams?.endTime || 0)\n        .replace(/<use new Date\\(\\)\\.toISOString\\(\\)>/g, new Date().toISOString())\n        .replace(/<current ISO timestamp>/g, new Date().toISOString());\n    }\n    \n    actualOutput = JSON.parse(cleanOutput);\n    console.log(\"‚úÖ Successfully parsed Stage 5 output\");\n  } catch (e) {\n    console.error(\"‚ùå Failed to parse Stage 5 output:\", e.message);\n    actualOutput = {\n      stage: \"ai_powered_analysis\",\n      analysis_id: previousContext.contextId + \"-stage5\",\n      error: \"Failed to parse output\",\n      remediation_plan: {\n        immediate_actions: [],\n        short_term_fixes: [],\n        long_term_solutions: [],\n        preventive_measures: []\n      },\n      risk_assessment: {\n        overall_risk: \"unknown\",\n        factors: [],\n        mitigation_steps: []\n      },\n      implementation_order: [],\n      success_metrics: {\n        immediate: [],\n        short_term: [],\n        long_term: []\n      },\n      rollback_plan: {\n        trigger_conditions: [],\n        steps: [],\n        validation: \"\"\n      }\n    };\n  }\n}\n\n// Validate actualOutput\nif (!actualOutput || typeof actualOutput !== 'object') {\n  console.error(\"‚ùå Invalid actualOutput, creating default structure\");\n  actualOutput = {\n    stage: \"ai_powered_analysis\",\n    analysis_id: previousContext.contextId + \"-stage5\",\n    remediation_plan: {\n      immediate_actions: [],\n      short_term_fixes: [],\n      long_term_solutions: [],\n      preventive_measures: []\n    },\n    risk_assessment: {\n      overall_risk: \"unknown\",\n      factors: [],\n      mitigation_steps: []\n    }\n  };\n}\n\n// ============= MOCK DATA DETECTION VE TEMƒ∞ZLEME =============\nif (actualOutput.remediation_plan && actualOutput.remediation_plan.immediate_actions) {\n  const immediateActions = actualOutput.remediation_plan.immediate_actions;\n  \n  immediateActions.forEach((action, index) => {\n    if (action.command && action.command.includes('payment-service')) {\n      console.warn(\"‚ö†Ô∏è MOCK COMMAND DETECTED! Replacing with actual data...\");\n      \n      const actualRootCause = stage4Data?.stage2Data?.root_cause || {};\n      let actualComponent = actualRootCause.component || \n                           stage4Data?.primaryDiagnosis?.component || \n                           \"unknown-component\";\n      const actualNamespace = stage4Data?.primaryDiagnosis?.namespace || \n                             stage4Data?.stage2Data?.affected_services?.[0]?.split('-')?.[0] || \n                             \"etiyamobile-production\";\n      const actualIssue = actualRootCause.issue || \n                         stage4Data?.primaryDiagnosis?.issue || \n                         \"Unknown issue\";\n      \n      const criticalPods = stage4Data?.stage2Data?.critical_pods || [];\n      if (criticalPods.length > 0 && actualComponent === \"unknown-component\") {\n        const firstPod = criticalPods[0];\n        actualComponent = typeof firstPod === 'string' ? firstPod : firstPod.name || firstPod;\n        console.log(`‚úÖ Using actual pod: ${actualComponent}`);\n      }\n      \n      if (actualIssue.includes('CrashLoopBackOff')) {\n        immediateActions[index] = {\n          action: `Delete and recreate pod ${actualComponent}`,\n          command: `kubectl delete pod ${actualComponent} -n ${actualNamespace}`,\n          risk: \"low\",\n          estimated_time: \"1-2 minutes\",\n          expected_outcome: \"Pod will be recreated with fresh state\"\n        };\n      } else if (actualIssue.includes('restart')) {\n        const deploymentName = actualComponent.split('-').slice(0, -2).join('-') || actualComponent;\n        immediateActions[index] = {\n          action: `Scale down and up deployment for ${actualComponent}`,\n          command: `kubectl scale deployment ${deploymentName} --replicas=0 -n ${actualNamespace} && kubectl scale deployment ${deploymentName} --replicas=1 -n ${actualNamespace}`,\n          risk: \"medium\",\n          estimated_time: \"2-3 minutes\",\n          expected_outcome: \"Deployment will be refreshed\"\n        };\n      } else {\n        immediateActions[index] = {\n          action: `Investigate and restart ${actualComponent}`,\n          command: `kubectl describe pod ${actualComponent} -n ${actualNamespace} && kubectl delete pod ${actualComponent} -n ${actualNamespace}`,\n          risk: \"low\",\n          estimated_time: \"2-5 minutes\",\n          expected_outcome: \"Component will be restarted after investigation\"\n        };\n      }\n      \n      console.log(\"‚úÖ Replaced mock command with actual component\");\n    }\n    \n    if (action.action && action.action.includes('payment-service')) {\n      const actualComponent = stage4Data?.stage2Data?.root_cause?.component || \"component\";\n      action.action = action.action.replace(/payment-service/g, actualComponent);\n    }\n  });\n  \n  if (actualOutput.remediation_plan.short_term_fixes) {\n    actualOutput.remediation_plan.short_term_fixes.forEach((fix) => {\n      if (fix.details && fix.details.includes('payment')) {\n        const actualService = stage4Data?.stage2Data?.affected_services?.[0] || \"service\";\n        fix.details = fix.details.replace(/payment processing/g, actualService + \" processing\");\n      }\n    });\n  }\n  \n  if (actualOutput.remediation_plan.long_term_solutions) {\n    actualOutput.remediation_plan.long_term_solutions.forEach((solution) => {\n      if (solution.details && (solution.details.includes('TransactionHandler') || solution.details.includes('payment'))) {\n        const actualComponent = stage4Data?.stage2Data?.root_cause?.component || \"component\";\n        solution.action = `Fix issues in ${actualComponent}`;\n        solution.details = `Review and fix the root cause in ${actualComponent} component`;\n      }\n    });\n  }\n}\n\n// ============= KB REMEDIATION ENHANCEMENT =============\nconst stage4DiagnosticSummary = stage4Data?.stage4Data?.diagnostic_summary || {};\nconst stage4KBAnalysis = stage4Data?.stage4Data?.enriched_context?.kb_analysis || {};\nconst confirmedIssuesWithKB = stage4DiagnosticSummary.confirmed_issues?.filter(i => i.kb_enhanced) || [];\n\nconsole.log(\"=== KB REMEDIATION ENHANCEMENT ===\");\nconsole.log(\"KB enhanced issues:\", confirmedIssuesWithKB.length);\n\nif (confirmedIssuesWithKB.length > 0 && actualOutput.remediation_plan) {\n  console.log(\"Enhancing remediation plan with KB actions...\");\n  \n  const kbImmediateActions = [];\n  \n  confirmedIssuesWithKB.forEach(issue => {\n    if (issue.kb_immediate_actions && Array.isArray(issue.kb_immediate_actions)) {\n      issue.kb_immediate_actions.forEach((action, idx) => {\n        const actionText = action.replace(/^\\d+\\.\\s*/, '');\n        let command = \"\";\n        let risk = \"medium\";\n        let estimatedTime = \"5-10 minutes\";\n        \n        if (actionText.toLowerCase().includes('rollback')) {\n          const component = issue.namespace || stage4Data?.primaryDiagnosis?.component || \"deployment\";\n          command = `kubectl rollout undo deployment/${component} -n ${issue.namespace || 'default'}`;\n          risk = \"low\";\n          estimatedTime = \"2-5 minutes\";\n        } else if (actionText.toLowerCase().includes('restart')) {\n          const component = issue.namespace || stage4Data?.primaryDiagnosis?.component || \"deployment\";\n          command = `kubectl rollout restart deployment/${component} -n ${issue.namespace || 'default'}`;\n          risk = \"low\";\n          estimatedTime = \"2-3 minutes\";\n        }\n        \n        kbImmediateActions.push({\n          action: actionText,\n          command: command,\n          risk: risk,\n          estimated_time: estimatedTime,\n          expected_outcome: `Resolve ${issue.issue}`,\n          source: \"Alert Knowledge Base\",\n          kb_severity: issue.kb_severity,\n          priority_score: calculateActionPriority(issue.kb_severity, idx)\n        });\n      });\n    }\n  });\n  \n  kbImmediateActions.sort((a, b) => b.priority_score - a.priority_score);\n  \n  if (actualOutput.remediation_plan.immediate_actions.length === 0 || \n      actualOutput.remediation_plan.immediate_actions.some(a => a.command?.includes('payment-service'))) {\n    actualOutput.remediation_plan.immediate_actions = kbImmediateActions.slice(0, 5);\n  }\n  \n  console.log(\"‚úÖ KB remediation enhancement complete\");\n}\n\n// Helper function\nfunction calculateActionPriority(severity, index) {\n  const severityScores = {\n    \"Blocker\": 1000,\n    \"Critical\": 800,\n    \"High\": 600,\n    \"Medium\": 400,\n    \"Low\": 200\n  };\n  return (severityScores[severity] || 100) - (index * 10);\n}\n\n// ============= KB REMEDIATION ACTIONS ENHANCEMENT (NEW) =============\n// Add KB-based remediation actions\nconst currentAlert = stage4Data?.alertInfo?.alertName || previousContext?.alertContext?.alertName || 'unknown';\nconst kbEntry = kbAlertKnowledgeBase[currentAlert];\nconst kbActions = [];\n\nif (kbEntry) {\n  console.log(\"‚úÖ Adding KB remediation actions for\", currentAlert);\n  \n  // Add immediate actions from KB\n  if (kbEntry.immediateActions && kbEntry.immediateActions.length > 0) {\n    kbEntry.immediateActions.slice(0, 3).forEach((action, index) => {\n      // Replace placeholders in KB actions\n      let command = action;\n      const filters = stage4Data?.alertInfo || {};\n      if (filters.namespace && command.includes('{namespace}')) {\n        command = command.replace(/{namespace}/g, filters.namespace);\n      }\n      if (filters.deployment && command.includes('{deployment}')) {\n        command = command.replace(/{deployment}/g, filters.deployment);\n      }\n      if (filters.pod && command.includes('{pod}')) {\n        command = command.replace(/{pod}/g, filters.pod);\n      }\n      \n      kbActions.push({\n        action: action,\n        command: command,\n        risk: kbEntry.severity === 'critical' ? 'high' : 'medium',\n        estimated_time: index === 0 ? \"1-2 minutes\" : \"5-10 minutes\",\n        expected_outcome: `${currentAlert} issue resolution`,\n        source: \"Alert Knowledge Base\",\n        kb_enhanced: true,\n        priority: calculateActionPriority(kbEntry.severity, index),\n        confidence: 0.95\n      });\n    });\n  }\n  \n  // Add long-term solutions from KB\n  if (kbEntry.longTermSolutions && kbEntry.longTermSolutions.length > 0) {\n    kbEntry.longTermSolutions.slice(0, 2).forEach(solution => {\n      kbActions.push({\n        action: solution,\n        command: `# KB Long-term solution: ${solution}`,\n        risk: \"low\",\n        estimated_time: \"1-2 weeks\",\n        expected_outcome: \"Prevent recurrence of this alert\",\n        source: \"Alert Knowledge Base - Long Term\",\n        kb_enhanced: true,\n        type: \"long_term\"\n      });\n    });\n  }\n}\n\n// ============= CATEGORY-BASED REMEDIATION TEMPLATES =============\n// Only apply if no existing remediation plan or need enhancement\nif (actualOutput.remediation_plan) {\n  const existingActions = actualOutput.remediation_plan.immediate_actions || [];\n  \n  // Only enhance if current actions are generic or insufficient\n  if (existingActions.length === 0 || \n      existingActions.some(a => a.command?.includes('payment-service')) ||\n      !existingActions.some(a => a.source === 'Alert Knowledge Base')) {\n    \n    const alertCategory = stage4Data?.alertCategoryAnalysis?.category || \n                         stage4Data?.alertInfo?.category || \n                         'UNKNOWN';\n    const rootCausePattern = stage4Data?.stage2Data?.root_cause?.pattern_matched || '';\n    const primaryDiagnosis = stage4Data?.primaryDiagnosis || {};\n    \n    console.log(\"=== CATEGORY-BASED REMEDIATION ENHANCEMENT ===\");\n    console.log(\"Category:\", alertCategory);\n    console.log(\"Root Cause Pattern:\", rootCausePattern);\n    \n    // Extended remediation templates by category and pattern\n    const CATEGORY_REMEDIATION_TEMPLATES = {\n      'INFRASTRUCTURE': {\n        'node_memory_pressure': {\n          immediate_actions: [\n            {\n              action: \"Cordon node to prevent new pod scheduling\",\n              command: `kubectl cordon ${primaryDiagnosis.component || 'node-name'}`,\n              risk: \"medium\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"No new pods will be scheduled on this node\"\n            },\n            {\n              action: \"Evict non-critical pods from node\",\n              command: `kubectl drain ${primaryDiagnosis.component || 'node-name'} --ignore-daemonsets --delete-emptydir-data`,\n              risk: \"high\",\n              estimated_time: \"2-5 minutes\",\n              expected_outcome: \"Free up memory on the node\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Increase node memory or add new nodes\",\n              timeline: \"1-2 days\",\n              details: \"Scale cluster horizontally or vertically\"\n            }\n          ],\n          long_term_solutions: [\n            {\n              action: \"Implement pod resource limits and requests\",\n              timeline: \"1 week\",\n              details: \"Ensure all pods have proper memory limits\"\n            }\n          ]\n        },\n        'node_disk_pressure': {\n          immediate_actions: [\n            {\n              action: \"Clean up docker images and logs\",\n              command: `ssh ${primaryDiagnosis.component || 'node'} 'docker system prune -af && journalctl --vacuum-time=1d'`,\n              risk: \"low\",\n              estimated_time: \"2-3 minutes\",\n              expected_outcome: \"Free up disk space\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Expand disk volume\",\n              timeline: \"4-6 hours\",\n              details: \"Increase disk size on cloud provider\"\n            }\n          ]\n        },\n        'node_network_connectivity': {\n          immediate_actions: [\n            {\n              action: \"Restart network components\",\n              command: `kubectl delete pods -n kube-system -l k8s-app=kube-proxy`,\n              risk: \"medium\",\n              estimated_time: \"1-2 minutes\",\n              expected_outcome: \"Reset network stack\"\n            }\n          ]\n        }\n      },\n      \n      'POD': {\n        'image_pull_error': {\n          immediate_actions: [\n            {\n              action: \"Verify image repository access\",\n              command: `kubectl describe pod ${primaryDiagnosis.component || 'pod-name'} -n ${primaryDiagnosis.namespace || 'default'} | grep -A 10 Events`,\n              risk: \"none\",\n              estimated_time: \"10 seconds\",\n              expected_outcome: \"Identify the exact image pull error\"\n            },\n            {\n              action: \"Check and update image pull secrets\",\n              command: `kubectl get secret -n ${primaryDiagnosis.namespace || 'default'} | grep pull`,\n              risk: \"low\",\n              estimated_time: \"1 minute\",\n              expected_outcome: \"Ensure credentials are valid\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Update deployment with correct image tag\",\n              timeline: \"30 minutes\",\n              details: \"Verify and fix image repository URL and tag\"\n            }\n          ]\n        },\n        'liveness_probe_failure': {\n          immediate_actions: [\n            {\n              action: \"Temporarily disable liveness probe\",\n              command: `kubectl patch deployment ${primaryDiagnosis.component?.split('-')[0] || 'deployment'} -n ${primaryDiagnosis.namespace || 'default'} -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"container\",\"livenessProbe\":null}]}}}}'`,\n              risk: \"medium\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"Stop container restarts for debugging\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Adjust probe thresholds\",\n              timeline: \"1 hour\",\n              details: \"Increase initialDelaySeconds and timeoutSeconds\"\n            }\n          ]\n        },\n        'init_container_failure': {\n          immediate_actions: [\n            {\n              action: \"Check init container logs\",\n              command: `kubectl logs ${primaryDiagnosis.component || 'pod-name'} -c init-container-name -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"none\",\n              estimated_time: \"10 seconds\",\n              expected_outcome: \"Identify init container failure reason\"\n            }\n          ]\n        },\n        'kb_memory_leak': {\n          immediate_actions: [\n            {\n              action: \"Restart pod with memory leak\",\n              command: `kubectl delete pod ${primaryDiagnosis.component || 'pod-name'} -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"low\",\n              estimated_time: \"1-2 minutes\",\n              expected_outcome: \"Temporary fix by restarting\"\n            },\n            {\n              action: \"Enable memory profiling\",\n              command: `kubectl set env deployment/${primaryDiagnosis.component?.split('-')[0] || 'deployment'} ENABLE_PROFILING=true -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"low\",\n              estimated_time: \"2 minutes\",\n              expected_outcome: \"Collect memory usage data\"\n            }\n          ]\n        }\n      },\n      \n      'WORKLOAD': {\n        'hpa_maxed_out': {\n          immediate_actions: [\n            {\n              action: \"Temporarily increase HPA max replicas\",\n              command: `kubectl patch hpa ${primaryDiagnosis.component || 'hpa-name'} -n ${primaryDiagnosis.namespace || 'default'} -p '{\"spec\":{\"maxReplicas\":20}}'`,\n              risk: \"medium\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"Allow more pods to handle load\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Optimize application performance\",\n              timeline: \"2-3 days\",\n              details: \"Profile and optimize CPU/memory usage\"\n            }\n          ]\n        },\n        'replica_mismatch': {\n          immediate_actions: [\n            {\n              action: \"Force deployment rollout restart\",\n              command: `kubectl rollout restart deployment/${primaryDiagnosis.component || 'deployment'} -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"medium\",\n              estimated_time: \"2-3 minutes\",\n              expected_outcome: \"Recreate all pods\"\n            }\n          ]\n        }\n      },\n      \n      'RESOURCE': {\n        'pvc_filling_up': {\n          immediate_actions: [\n            {\n              action: \"Clean up old data in PVC\",\n              command: `kubectl exec -n ${primaryDiagnosis.namespace || 'default'} ${primaryDiagnosis.component || 'pod'} -- sh -c 'find /data -mtime +7 -delete'`,\n              risk: \"medium\",\n              estimated_time: \"1-5 minutes\",\n              expected_outcome: \"Free up space in persistent volume\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Expand PVC size\",\n              timeline: \"1-2 hours\",\n              details: \"Increase PersistentVolumeClaim size\"\n            }\n          ]\n        },\n        'quota_exceeded': {\n          immediate_actions: [\n            {\n              action: \"Identify resource consumers\",\n              command: `kubectl top pods -n ${primaryDiagnosis.namespace || 'default'} --sort-by=memory`,\n              risk: \"none\",\n              estimated_time: \"5 seconds\",\n              expected_outcome: \"Find pods using most resources\"\n            },\n            {\n              action: \"Scale down non-critical deployments\",\n              command: `kubectl scale deployment non-critical-app --replicas=1 -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"low\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"Free up quota\"\n            }\n          ]\n        }\n      },\n      \n      'NETWORK': {\n        'endpoint_down': {\n          immediate_actions: [\n            {\n              action: \"Recreate service endpoints\",\n              command: `kubectl delete endpoints ${primaryDiagnosis.component || 'service'} -n ${primaryDiagnosis.namespace || 'default'} && kubectl get endpoints ${primaryDiagnosis.component || 'service'} -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"low\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"Rebuild service endpoints\"\n            }\n          ]\n        },\n        'dns_failure': {\n          immediate_actions: [\n            {\n              action: \"Restart CoreDNS pods\",\n              command: `kubectl rollout restart deployment/coredns -n kube-system`,\n              risk: \"medium\",\n              estimated_time: \"1-2 minutes\",\n              expected_outcome: \"Reset DNS resolution\"\n            }\n          ]\n        }\n      },\n      \n      'ETCD': {\n        'etcd_no_leader': {\n          immediate_actions: [\n            {\n              action: \"CRITICAL: Force etcd leader election\",\n              command: `kubectl exec -n kube-system etcd-0 -- etcdctl move-leader`,\n              risk: \"high\",\n              estimated_time: \"10-30 seconds\",\n              expected_outcome: \"Restore etcd quorum\",\n              priority: \"P0\"\n            }\n          ],\n          short_term_fixes: [\n            {\n              action: \"Add etcd member if needed\",\n              timeline: \"30 minutes\",\n              details: \"Restore etcd cluster to odd number of members\"\n            }\n          ]\n        },\n        'etcd_disk_latency': {\n          immediate_actions: [\n            {\n              action: \"Defragment etcd database\",\n              command: `kubectl exec -n kube-system etcd-0 -- etcdctl defrag`,\n              risk: \"medium\",\n              estimated_time: \"1-2 minutes\",\n              expected_outcome: \"Reduce database size and improve performance\"\n            }\n          ]\n        }\n      },\n      \n      'CERTIFICATE': {\n        'cert_expiring': {\n          immediate_actions: [\n            {\n              action: \"Rotate certificates immediately\",\n              command: `kubeadm certs renew all`,\n              risk: \"high\",\n              estimated_time: \"5-10 minutes\",\n              expected_outcome: \"Renew all certificates\",\n              priority: \"P0\"\n            }\n          ],\n          preventive_measures: [\n            \"Set up automated certificate rotation\",\n            \"Implement certificate monitoring alerts at 30, 7, and 1 day thresholds\"\n          ]\n        }\n      },\n      \n      'CLUSTER': {\n        'api_server_degradation': {\n          immediate_actions: [\n            {\n              action: \"Restart API server pods\",\n              command: `kubectl delete pods -n kube-system -l component=kube-apiserver`,\n              risk: \"high\",\n              estimated_time: \"2-3 minutes\",\n              expected_outcome: \"Reset API server state\"\n            }\n          ]\n        },\n        'scheduler_failure': {\n          immediate_actions: [\n            {\n              action: \"Restart scheduler\",\n              command: `kubectl delete pods -n kube-system -l component=kube-scheduler`,\n              risk: \"medium\",\n              estimated_time: \"1 minute\",\n              expected_outcome: \"Reset scheduler state\"\n            }\n          ]\n        }\n      },\n      \n      'MONITORING': {\n        'monitoring_degradation': {\n          immediate_actions: [\n            {\n              action: \"Restart Prometheus\",\n              command: `kubectl rollout restart deployment/prometheus -n monitoring`,\n              risk: \"low\",\n              estimated_time: \"2-3 minutes\",\n              expected_outcome: \"Reset monitoring stack\"\n            }\n          ]\n        }\n      },\n      \n      'APPLICATION': {\n        'high_error_rate': {\n          immediate_actions: [\n            {\n              action: \"Enable circuit breaker\",\n              command: `kubectl patch deployment ${primaryDiagnosis.component || 'app'} -n ${primaryDiagnosis.namespace || 'default'} -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"app\",\"env\":[{\"name\":\"CIRCUIT_BREAKER\",\"value\":\"true\"}]}]}}}}'`,\n              risk: \"low\",\n              estimated_time: \"30 seconds\",\n              expected_outcome: \"Prevent cascade failures\"\n            }\n          ]\n        },\n        'high_latency': {\n          immediate_actions: [\n            {\n              action: \"Scale up application\",\n              command: `kubectl scale deployment ${primaryDiagnosis.component || 'app'} --replicas=5 -n ${primaryDiagnosis.namespace || 'default'}`,\n              risk: \"low\",\n              estimated_time: \"1-2 minutes\",\n              expected_outcome: \"Distribute load across more pods\"\n            }\n          ]\n        }\n      }\n    };\n    \n    // Get the appropriate remediation template\n    const categoryTemplates = CATEGORY_REMEDIATION_TEMPLATES[alertCategory];\n    if (categoryTemplates) {\n      // Try to match with root cause pattern first\n      let selectedTemplate = categoryTemplates[rootCausePattern];\n      \n      // If no pattern match, try to match with primary diagnosis\n      if (!selectedTemplate && primaryDiagnosis.issue) {\n        Object.keys(categoryTemplates).forEach(pattern => {\n          if (primaryDiagnosis.issue.toLowerCase().includes(pattern.replace(/_/g, ' '))) {\n            selectedTemplate = categoryTemplates[pattern];\n          }\n        });\n      }\n      \n      // If still no match, use first available template for the category\n      if (!selectedTemplate) {\n        selectedTemplate = categoryTemplates[Object.keys(categoryTemplates)[0]];\n      }\n      \n      if (selectedTemplate) {\n        console.log(\"Applying category remediation template\");\n        \n        // Merge with existing remediation plan\n        if (!actualOutput.remediation_plan.immediate_actions || \n            actualOutput.remediation_plan.immediate_actions.length === 0) {\n          actualOutput.remediation_plan.immediate_actions = selectedTemplate.immediate_actions || [];\n        } else {\n          // Add source tag to distinguish category-based actions\n          const taggedActions = (selectedTemplate.immediate_actions || []).map(action => ({\n            ...action,\n            source: \"Category Template\",\n            category: alertCategory\n          }));\n          \n          // Merge, keeping KB actions first, then category templates\n          const kbActions = actualOutput.remediation_plan.immediate_actions.filter(a => \n            a.source === \"Alert Knowledge Base\"\n          );\n          const otherActions = actualOutput.remediation_plan.immediate_actions.filter(a => \n            a.source !== \"Alert Knowledge Base\"\n          );\n          \n          actualOutput.remediation_plan.immediate_actions = [\n            ...kbActions,\n            ...taggedActions,\n            ...otherActions\n          ].slice(0, 5); // Limit to 5 actions\n        }\n        \n        // Add short-term fixes if not present\n        if (selectedTemplate.short_term_fixes && \n            (!actualOutput.remediation_plan.short_term_fixes || \n             actualOutput.remediation_plan.short_term_fixes.length === 0)) {\n          actualOutput.remediation_plan.short_term_fixes = selectedTemplate.short_term_fixes;\n        }\n        \n        // Add long-term solutions if not present  \n        if (selectedTemplate.long_term_solutions && \n            (!actualOutput.remediation_plan.long_term_solutions || \n             actualOutput.remediation_plan.long_term_solutions.length === 0)) {\n          actualOutput.remediation_plan.long_term_solutions = selectedTemplate.long_term_solutions;\n        }\n        \n        // Add preventive measures if not present\n        if (selectedTemplate.preventive_measures && \n            (!actualOutput.remediation_plan.preventive_measures || \n             actualOutput.remediation_plan.preventive_measures.length === 0)) {\n          actualOutput.remediation_plan.preventive_measures = selectedTemplate.preventive_measures;\n        }\n        \n        console.log(\"‚úÖ Category remediation template applied\");\n        console.log(\"- Actions added:\", actualOutput.remediation_plan.immediate_actions.length);\n        console.log(\"- Category:\", alertCategory);\n        console.log(\"- Pattern:\", rootCausePattern);\n      }\n    }\n  }\n}\n\n// ============= RISK ASSESSMENT BY CATEGORY =============\nif (actualOutput.risk_assessment) {\n  const alertCategory = stage4Data?.alertCategoryAnalysis?.category || 'UNKNOWN';\n  \n  // Category-based risk levels\n  const CATEGORY_RISK_LEVELS = {\n    'ETCD': { base: 'critical', factors: ['Cluster consensus at risk', 'Potential data loss', 'Control plane failure'] },\n    'CERTIFICATE': { base: 'critical', factors: ['Authentication failure imminent', 'Service disruption', 'Security risk'] },\n    'INFRASTRUCTURE': { base: 'high', factors: ['Node failures affect all workloads', 'Potential cascade', 'Resource exhaustion'] },\n    'CLUSTER': { base: 'high', factors: ['Control plane issues', 'API degradation', 'Scheduling problems'] },\n    'NETWORK': { base: 'high', factors: ['Service connectivity issues', 'DNS failures', 'Ingress problems'] },\n    'RESOURCE': { base: 'medium', factors: ['Resource constraints', 'Quota limits', 'Storage issues'] },\n    'WORKLOAD': { base: 'medium', factors: ['Deployment issues', 'Scaling problems', 'Replica health'] },\n    'POD': { base: 'medium', factors: ['Container issues', 'Pod lifecycle problems', 'Resource limits'] },\n    'APPLICATION': { base: 'low', factors: ['Application errors', 'Performance degradation', 'Dependency issues'] },\n    'MONITORING': { base: 'low', factors: ['Observability gaps', 'Metric collection issues', 'Alert delivery problems'] },\n    'UNKNOWN': { base: 'medium', factors: ['Unclassified issue', 'Requires investigation'] }\n  };\n  \n  const categoryRisk = CATEGORY_RISK_LEVELS[alertCategory] || CATEGORY_RISK_LEVELS['UNKNOWN'];\n  \n  // Only update if not already set or if category risk is higher\n  const riskPriority = { 'critical': 4, 'high': 3, 'medium': 2, 'low': 1 };\n  const currentRiskLevel = riskPriority[actualOutput.risk_assessment.overall_risk] || 0;\n  const categoryRiskLevel = riskPriority[categoryRisk.base] || 2;\n  \n  if (categoryRiskLevel > currentRiskLevel) {\n    actualOutput.risk_assessment.overall_risk = categoryRisk.base;\n    actualOutput.risk_assessment.factors = [\n      ...actualOutput.risk_assessment.factors.filter(f => !categoryRisk.factors.includes(f)),\n      ...categoryRisk.factors\n    ];\n    actualOutput.risk_assessment.category_based = true;\n    actualOutput.risk_assessment.alert_category = alertCategory;\n  }\n  \n  // Add category-specific mitigation steps if not present\n  if (!actualOutput.risk_assessment.mitigation_steps || \n      actualOutput.risk_assessment.mitigation_steps.length === 0) {\n    const CATEGORY_MITIGATIONS = {\n      'ETCD': ['Immediate backup of etcd data', 'Prepare for cluster recovery', 'Alert senior SRE team'],\n      'CERTIFICATE': ['Prepare certificate renewal', 'Notify security team', 'Have rollback plan ready'],\n      'INFRASTRUCTURE': ['Identify affected workloads', 'Prepare node drain procedure', 'Check resource capacity'],\n      'NETWORK': ['Verify connectivity paths', 'Check firewall rules', 'Test DNS resolution'],\n      'DEFAULT': ['Monitor closely after remediation', 'Keep team on standby', 'Document all actions']\n    };\n    \n    actualOutput.risk_assessment.mitigation_steps = \n      CATEGORY_MITIGATIONS[alertCategory] || CATEGORY_MITIGATIONS['DEFAULT'];\n  }\n}\n\n// Risk assessment update for generic factors\nif (actualOutput.risk_assessment && actualOutput.risk_assessment.factors) {\n  actualOutput.risk_assessment.factors = actualOutput.risk_assessment.factors.map(factor => {\n    if (typeof factor === 'string' && factor.includes('Payment service')) {\n      const actualService = stage4Data?.stage2Data?.affected_services?.[0] || \"Service\";\n      return factor.replace('Payment service', actualService);\n    }\n    return factor;\n  });\n}\n\n// ============= SUCCESS METRICS BY CATEGORY =============\nif (actualOutput.success_metrics) {\n  const alertCategory = stage4Data?.alertCategoryAnalysis?.category || 'UNKNOWN';\n  \n  const CATEGORY_SUCCESS_METRICS = {\n    'INFRASTRUCTURE': {\n      immediate: {\n        expected: ['Node status = Ready', 'No pods in Evicted state', 'Resource pressure resolved'],\n        commands: ['kubectl get nodes', 'kubectl get pods --all-namespaces --field-selector status.phase=Failed', 'kubectl top nodes']\n      },\n      short_term: {\n        expected: ['No node failures in 24h', 'Stable resource usage', 'All workloads running'],\n        commands: ['kubectl get events --all-namespaces --field-selector type=Warning --since=24h | grep Node', 'kubectl top nodes', 'kubectl get pods --all-namespaces --field-selector status.phase!=Running']\n      },\n      long_term: {\n        expected: ['Node reliability > 99.9%', 'Capacity planning implemented'],\n        commands: ['kubectl describe nodes', 'kubectl get hpa --all-namespaces', 'kubectl get vpa --all-namespaces']\n      }\n    },\n    'POD': {\n      immediate: {\n        expected: ['Pod status = Running', 'No restart in 10 minutes', 'All containers ready'],\n        commands: ['kubectl get pods -n __NAMESPACE__ | grep __DEPLOYMENT__', 'kubectl describe pod -l app=__DEPLOYMENT__ -n __NAMESPACE__ | grep \"Restart Count\"', 'kubectl get pods -n __NAMESPACE__ -l app=__DEPLOYMENT__ -o jsonpath=\\'{.items[*].status.containerStatuses[*].ready}\\'']\n      },\n      short_term: {\n        expected: ['Stable for 24h', 'No OOM events', 'Successful health checks'],\n        commands: ['kubectl get events -n __NAMESPACE__ --field-selector reason=OOMKilling --since=24h', 'kubectl get pods -n __NAMESPACE__ -l app=__DEPLOYMENT__ --watch --timeout=60s', 'kubectl get pods -n __NAMESPACE__ -l app=__DEPLOYMENT__ -o jsonpath=\\'{.items[*].status.containerStatuses[*].restartCount}\\'']\n      },\n      long_term: {\n        expected: ['Resource limits optimized', 'Monitoring alerts configured'],\n        commands: ['kubectl describe deployment __DEPLOYMENT__ -n __NAMESPACE__ | grep -A5 Limits', 'kubectl get servicemonitor -n __NAMESPACE__', 'kubectl get prometheusrule -n __NAMESPACE__']\n      }\n    },\n    'WORKLOAD': {\n      immediate: {\n        expected: ['Desired replicas = Available replicas', 'All pods ready', 'No pending pods'],\n        commands: ['kubectl get deployment __DEPLOYMENT__ -n __NAMESPACE__', 'kubectl get pods -n __NAMESPACE__ -l app=__DEPLOYMENT__', 'kubectl get pods -n __NAMESPACE__ --field-selector status.phase=Pending']\n      },\n      short_term: {\n        expected: ['Stable replica count for 24h', 'HPA functioning normally'],\n        commands: ['kubectl get deployment __DEPLOYMENT__ -n __NAMESPACE__ --watch --timeout=60s', 'kubectl get hpa -n __NAMESPACE__', 'kubectl describe hpa -n __NAMESPACE__']\n      },\n      long_term: {\n        expected: ['Auto-scaling optimized', 'Load patterns understood'],\n        commands: ['kubectl get hpa -n __NAMESPACE__', 'kubectl get vpa -n __NAMESPACE__', 'kubectl top pods -n __NAMESPACE__']\n      }\n    },\n    'RESOURCE': {\n      immediate: {\n        expected: ['Resource usage < 80%', 'No quota violations', 'PVC available space > 20%'],\n        commands: ['kubectl top pods -n __NAMESPACE__', 'kubectl describe resourcequota -n __NAMESPACE__', 'kubectl get pvc -n __NAMESPACE__']\n      },\n      short_term: {\n        expected: ['Stable resource consumption', 'No growth anomalies'],\n        commands: ['kubectl top pods -n __NAMESPACE__ --sort-by=memory', 'kubectl get events -n __NAMESPACE__ --field-selector reason=FailedScheduling --since=24h', 'kubectl describe limitrange -n __NAMESPACE__']\n      },\n      long_term: {\n        expected: ['Resource governance implemented', 'Automated cleanup in place'],\n        commands: ['kubectl get limitrange -n __NAMESPACE__', 'kubectl get resourcequota -n __NAMESPACE__', 'kubectl get networkpolicy -n __NAMESPACE__']\n      }\n    },\n    'NETWORK': {\n      immediate: {\n        expected: ['All endpoints ready', 'Service accessible', 'DNS resolving'],\n        commands: ['kubectl get endpoints -n __NAMESPACE__', 'kubectl get svc -n __NAMESPACE__', 'kubectl exec -n __NAMESPACE__ deployment/__DEPLOYMENT__ -- nslookup kubernetes.default.svc.cluster.local']\n      },\n      short_term: {\n        expected: ['No connection errors in 24h', 'Stable latency'],\n        commands: ['kubectl get events -n __NAMESPACE__ --field-selector type=Warning --since=24h | grep -i network', 'kubectl exec -n __NAMESPACE__ deployment/__DEPLOYMENT__ -- wget --spider --timeout=5 http://kubernetes.default.svc.cluster.local:443', 'kubectl get networkpolicy -n __NAMESPACE__']\n      },\n      long_term: {\n        expected: ['Network policies optimized', 'Redundancy implemented'],\n        commands: ['kubectl get networkpolicy -n __NAMESPACE__', 'kubectl get ingress -n __NAMESPACE__', 'kubectl get service -n __NAMESPACE__ -o wide']\n      }\n    },\n    'ETCD': {\n      immediate: {\n        expected: ['Leader elected', 'All members healthy', 'Fsync < 50ms'],\n        commands: ['kubectl exec -n kube-system etcd-master -- etcdctl endpoint status --cluster', 'kubectl exec -n kube-system etcd-master -- etcdctl endpoint health --cluster', 'kubectl exec -n kube-system etcd-master -- etcdctl endpoint status --write-out=table']\n      },\n      short_term: {\n        expected: ['No leader changes in 24h', 'Stable performance'],\n        commands: ['kubectl get events -n kube-system --field-selector involvedObject.name~=etcd --since=24h', 'kubectl logs -n kube-system -l component=etcd --since=24h | grep -i leader', 'kubectl exec -n kube-system etcd-master -- etcdctl endpoint status --cluster']\n      },\n      long_term: {\n        expected: ['Backup strategy implemented', 'Monitoring enhanced'],\n        commands: ['kubectl get cronjob -n kube-system | grep etcd', 'kubectl get servicemonitor -n kube-system | grep etcd', 'kubectl describe configmap -n kube-system etcd-config']\n      }\n    },\n    'CERTIFICATE': {\n      immediate: {\n        expected: ['Certificates valid', 'TTL > 30 days', 'All components authenticated'],\n        commands: ['kubectl get csr', 'kubectl get secrets -A -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,TYPE:.type | grep tls', 'openssl x509 -in /etc/kubernetes/pki/ca.crt -text -noout | grep \"Not After\"']\n      },\n      short_term: {\n        expected: ['Rotation successful', 'No auth failures'],\n        commands: ['kubectl get events --all-namespaces --field-selector type=Warning --since=24h | grep -i cert', 'kubectl logs -n kube-system -l component=kube-apiserver --since=24h | grep -i cert', 'kubectl get certificatesigningrequest']\n      },\n      long_term: {\n        expected: ['Auto-rotation configured', 'Monitoring alerts set'],\n        commands: ['kubectl get cronjob --all-namespaces | grep cert', 'kubectl get servicemonitor --all-namespaces | grep cert', 'kubectl get prometheusrule --all-namespaces | grep cert']\n      }\n    },\n    'DEFAULT': {\n      immediate: {\n        expected: ['Issue resolved', 'Service stable', 'No error logs'],\n        commands: ['kubectl get pods -n __NAMESPACE__ | grep __DEPLOYMENT__', 'kubectl logs -n __NAMESPACE__ deployment/__DEPLOYMENT__ --tail=50', 'kubectl get events -n __NAMESPACE__ --sort-by=.metadata.creationTimestamp | tail -10']\n      },\n      short_term: {\n        expected: ['No recurrence in 24h', 'SLO met'],\n        commands: ['kubectl get events -n __NAMESPACE__ --field-selector type=Warning --since=24h', 'kubectl top pods -n __NAMESPACE__', 'kubectl get svc -n __NAMESPACE__ && curl -s -o /dev/null -w \"%{http_code}\" http://__DEPLOYMENT__.__NAMESPACE__.svc.cluster.local']\n      },\n      long_term: {\n        expected: ['Root cause fixed', 'Prevention measures in place'],\n        commands: ['kubectl describe deployment __DEPLOYMENT__ -n __NAMESPACE__', 'kubectl get hpa -n __NAMESPACE__', 'kubectl get servicemonitor -n __NAMESPACE__']\n      }\n    }\n  };\n  \n  // Extract context variables for kubectl commands\n  const namespace = actualOutput._context?.kubernetesFilters?.namespace || \n                   actualOutput._context?.alertContext?.kubernetes?.namespace || \n                   'default';\n  const deployment = actualOutput._context?.kubernetesFilters?.deployment || \n                    actualOutput._context?.alertContext?.kubernetes?.deployment ||\n                    actualOutput._context?.kubernetesFilters?.service ||\n                    'app';\n  \n  // Generate category-specific metrics with proper kubectl commands\n  function generateSuccessMetricsWithCommands(category, ns, deploy) {\n    const template = CATEGORY_SUCCESS_METRICS[category] || CATEGORY_SUCCESS_METRICS['DEFAULT'];\n    \n    // Replace placeholder strings in commands with actual values\n    const processCommands = (commands) => {\n      return commands.map(cmd => \n        cmd.replace(/__NAMESPACE__/g, ns)\n           .replace(/__DEPLOYMENT__/g, deploy)\n      );\n    };\n    \n    return {\n      immediate: {\n        expected: template.immediate.expected,\n        commands: processCommands(template.immediate.commands)\n      },\n      short_term: {\n        expected: template.short_term.expected,\n        commands: processCommands(template.short_term.commands)\n      },\n      long_term: {\n        expected: template.long_term.expected,\n        commands: processCommands(template.long_term.commands)\n      }\n    };\n  }\n  \n  const categoryMetrics = generateSuccessMetricsWithCommands(alertCategory, namespace, deployment);\n  \n  // Merge with existing metrics, preserving any that were already set\n  if (!actualOutput.success_metrics.immediate || actualOutput.success_metrics.immediate.length === 0) {\n    actualOutput.success_metrics.immediate = categoryMetrics.immediate;\n  }\n  if (!actualOutput.success_metrics.short_term || actualOutput.success_metrics.short_term.length === 0) {\n    actualOutput.success_metrics.short_term = categoryMetrics.short_term;\n  }\n  if (!actualOutput.success_metrics.long_term || actualOutput.success_metrics.long_term.length === 0) {\n    actualOutput.success_metrics.long_term = categoryMetrics.long_term;\n  }\n  \n  // Add category tag\n  actualOutput.success_metrics.category_enhanced = true;\n  actualOutput.success_metrics.alert_category = alertCategory;\n}\n\n// ============= ROLLBACK PLAN BY CATEGORY =============\nif (actualOutput.rollback_plan) {\n  const alertCategory = stage4Data?.alertCategoryAnalysis?.category || 'UNKNOWN';\n  \n  const CATEGORY_ROLLBACK_CONDITIONS = {\n    'ETCD': {\n      trigger_conditions: [\n        'etcd cluster loses quorum',\n        'Multiple member failures',\n        'Data corruption detected'\n      ],\n      steps: [\n        'Restore from etcd backup immediately',\n        'Rebuild cluster if necessary',\n        'Escalate to senior SRE'\n      ]\n    },\n    'INFRASTRUCTURE': {\n      trigger_conditions: [\n        'Node becomes completely unresponsive',\n        'Multiple pod evictions',\n        'Cascading node failures'\n      ],\n      steps: [\n        'Cordon affected nodes',\n        'Migrate workloads to healthy nodes',\n        'Request infrastructure team intervention'\n      ]\n    },\n    'POD': {\n      trigger_conditions: [\n        'Pod enters CrashLoopBackOff',\n        'OOM kills continue',\n        'Application errors increase'\n      ],\n      steps: [\n        'Roll back deployment',\n        'Restore previous pod template',\n        'Revert configuration changes'\n      ]\n    },\n    'DEFAULT': {\n      trigger_conditions: [\n        'Error rate > 5%',\n        'Multiple component failures',\n        'SLO violation continues'\n      ],\n      steps: [\n        'Revert all changes',\n        'Restore previous state',\n        'Escalate to on-call lead'\n      ]\n    }\n  };\n  \n  const categoryRollback = CATEGORY_ROLLBACK_CONDITIONS[alertCategory] || CATEGORY_ROLLBACK_CONDITIONS['DEFAULT'];\n  \n  // Only add if not already present\n  if (!actualOutput.rollback_plan.trigger_conditions || \n      actualOutput.rollback_plan.trigger_conditions.length === 0) {\n    actualOutput.rollback_plan.trigger_conditions = categoryRollback.trigger_conditions;\n  }\n  \n  if (!actualOutput.rollback_plan.steps || \n      actualOutput.rollback_plan.steps.length === 0) {\n    actualOutput.rollback_plan.steps = categoryRollback.steps;\n  }\n  \n  // Add validation if not present\n  if (!actualOutput.rollback_plan.validation) {\n    actualOutput.rollback_plan.validation = `Verify ${alertCategory} stability before proceeding`;\n  }\n}\n\n// ============= CONTEXT FIX =============\nconst expectedContextId = previousContext?.contextId;\n\nif (!actualOutput._context || \n    actualOutput._context.contextId !== expectedContextId) {\n  console.log(\"‚ùå Invalid or missing context, fixing...\");\n  \n  // Deep copy of previous context\n  const contextCopy = JSON.parse(JSON.stringify(previousContext));\n  \n  // Ensure stageResults exists\n  if (!contextCopy.stageResults) {\n    contextCopy.stageResults = {};\n  }\n  \n  actualOutput._context = contextCopy;\n  console.log(\"‚úÖ Context replaced\");\n}\n\n// Ensure stageResults exists\nif (!actualOutput._context.stageResults) {\n  actualOutput._context.stageResults = {};\n}\n\n// Add Stage 5 results - only this stage's data\nactualOutput._context.stageResults.stage5 = {\n  output: {\n    analysis_id: actualOutput.analysis_id || `${expectedContextId}-stage5`,\n    remediation_plan: JSON.parse(JSON.stringify(actualOutput.remediation_plan)),\n    risk_assessment: JSON.parse(JSON.stringify(actualOutput.risk_assessment)),\n    implementation_order: JSON.parse(JSON.stringify(actualOutput.implementation_order || [])),\n    success_metrics: JSON.parse(JSON.stringify(actualOutput.success_metrics || {})),\n    rollback_plan: JSON.parse(JSON.stringify(actualOutput.rollback_plan || {}))\n  },\n  completedAt: new Date().toISOString()\n};\n\n// Update debug info\nactualOutput._debug = {\n  nodeType: \"Stage 5: AI-Powered Analysis\",\n  processedAt: actualOutput._debug?.processedAt || new Date().toISOString(),\n  contextId: expectedContextId,\n  contextPreserved: true,\n  receivedFromStage: \"Fix Stage 4 Context\",\n  priority: previousContext?.priority || \"normal\",\n  stagesCompleted: 5,\n  stageSequence: [\n    \"Unified Entry Point\",\n    \"Stage 1: Health Snapshot\",\n    \"Fix Stage 1 Context\",\n    \"Stage 2 Decision\",\n    \"Force Deep Analysis Override\",\n    \"Wait 3s\",\n    \"Stage 2: Deep Analysis\",\n    \"Fix Stage 2 Context\",\n    \"Stage 3: Alert Intelligence\",\n    \"Fix Stage 3 Context\",\n    \"Stage 4: Automated Diagnosis\",\n    \"Fix Stage 4 Context\",\n    \"Stage 5: AI-Powered Analysis\",\n    \"Fix Stage 5 Context\"\n  ],\n  analysisTimeRange: {\n    start: previousContext?.initialParams?.startTime || 0,\n    end: previousContext?.initialParams?.endTime || 0\n  }\n};\n\n// Update root level context\nfixedOutput._context = JSON.parse(JSON.stringify(actualOutput._context));\nfixedOutput.contextId = expectedContextId;\n\n// ============= MERGE KB ACTIONS WITH EXISTING PLAN (NEW) =============\n// Enhance the remediation plan with KB actions\nlet enhancedRemediationPlan = JSON.parse(JSON.stringify(actualOutput.remediation_plan || {}));\n\nif (kbActions.length > 0) {\n  console.log(\"üîó Merging\", kbActions.length, \"KB actions with existing remediation plan\");\n  \n  // Add KB immediate actions\n  const kbImmediateActions = kbActions.filter(a => a.type !== \"long_term\");\n  if (kbImmediateActions.length > 0) {\n    if (!enhancedRemediationPlan.immediate_actions) enhancedRemediationPlan.immediate_actions = [];\n    // Prioritize KB actions at the beginning\n    enhancedRemediationPlan.immediate_actions = [\n      ...kbImmediateActions,\n      ...enhancedRemediationPlan.immediate_actions\n    ];\n  }\n  \n  // Add KB long-term solutions\n  const kbLongTermActions = kbActions.filter(a => a.type === \"long_term\");\n  if (kbLongTermActions.length > 0) {\n    if (!enhancedRemediationPlan.long_term_solutions) enhancedRemediationPlan.long_term_solutions = [];\n    enhancedRemediationPlan.long_term_solutions = [\n      ...enhancedRemediationPlan.long_term_solutions,\n      ...kbLongTermActions\n    ];\n  }\n}\n\n// Stage 5 summary data\nfixedOutput.stage5Data = {\n  analysis_id: actualOutput.analysis_id,\n  remediation_plan: enhancedRemediationPlan, // Use enhanced plan instead of original\n  risk_assessment: JSON.parse(JSON.stringify(actualOutput.risk_assessment)),\n  implementation_order: JSON.parse(JSON.stringify(actualOutput.implementation_order || [])),\n  success_metrics: JSON.parse(JSON.stringify(actualOutput.success_metrics || {})),\n  rollback_plan: JSON.parse(JSON.stringify(actualOutput.rollback_plan || {})),\n  primary_action: enhancedRemediationPlan?.immediate_actions?.[0], // Use enhanced plan\n  overall_risk: actualOutput.risk_assessment?.overall_risk,\n  kb_actions_added: kbActions.length, // Track KB enhancement\n  kb_enhanced: kbActions.length > 0\n};\n\n// Update decisions\nif (!actualOutput._context.decisions) {\n  actualOutput._context.decisions = previousContext?.decisions || {};\n}\n\nactualOutput._context.decisions.stage6Proceed = {\n  timestamp: new Date().toISOString(),\n  remediationPlanCreated: !!actualOutput.remediation_plan,\n  riskAssessed: !!actualOutput.risk_assessment,\n  primaryActionDefined: !!actualOutput.remediation_plan?.immediate_actions?.[0]\n};\n\n// Preserve ALL previous stage data\nif (stage4Data?.stage1Data) {\n  fixedOutput.stage1Data = JSON.parse(JSON.stringify(stage4Data.stage1Data));\n  console.log(\"‚úÖ Stage 1 data preserved (full copy)\");\n}\n\nif (stage4Data?.stage2Data) {\n  fixedOutput.stage2Data = JSON.parse(JSON.stringify(stage4Data.stage2Data));\n  console.log(\"‚úÖ Stage 2 data preserved (full copy)\");\n}\n\nif (stage4Data?.stage3Data) {\n  fixedOutput.stage3Data = JSON.parse(JSON.stringify(stage4Data.stage3Data));\n  console.log(\"‚úÖ Stage 3 data preserved (full copy)\");\n}\n\nif (stage4Data?.stage4Data) {\n  fixedOutput.stage4Data = JSON.parse(JSON.stringify(stage4Data.stage4Data));\n  console.log(\"‚úÖ Stage 4 data preserved (full copy)\");\n}\n\n// Preserve additional data\nif (stage4Data?.consolidatedFindings) {\n  fixedOutput.consolidatedFindings = JSON.parse(JSON.stringify(stage4Data.consolidatedFindings));\n}\n\nif (stage4Data?.primaryDiagnosis) {\n  fixedOutput.primaryDiagnosis = JSON.parse(JSON.stringify(stage4Data.primaryDiagnosis));\n}\n\n// Executive summary\nfixedOutput.executiveSummary = {\n  contextId: expectedContextId,\n  issue: fixedOutput.primaryDiagnosis?.issue || \"Unknown issue\",\n  severity: fixedOutput.primaryDiagnosis?.severity || \"medium\",\n  immediateAction: actualOutput.remediation_plan?.immediate_actions?.[0]?.action || \"No immediate action\",\n  command: actualOutput.remediation_plan?.immediate_actions?.[0]?.command || \"N/A\",\n  risk: actualOutput.risk_assessment?.overall_risk || \"unknown\",\n  estimatedTime: actualOutput.remediation_plan?.immediate_actions?.[0]?.estimated_time || \"unknown\",\n  stagesCompleted: 5,\n  timestamp: new Date().toISOString()\n};\n\n// Namespaces and time range\nfixedOutput.namespaces = previousContext?.initialParams?.namespaces || ['etiyamobile-production'];\nfixedOutput.timeRange = {\n  start: previousContext?.initialParams?.startTime || 0,\n  end: previousContext?.initialParams?.endTime || 0\n};\n\n// Summary logging\nconsole.log(\"==============================\");\nconsole.log(\"Stage 5 Fix Summary:\");\nconsole.log(\"- Context ID:\", actualOutput._context?.contextId);\nconsole.log(\"- Immediate action:\", enhancedRemediationPlan?.immediate_actions?.[0]?.action);\nconsole.log(\"- Risk level:\", fixedOutput.risk_assessment?.overall_risk);\nconsole.log(\"- Command:\", enhancedRemediationPlan?.immediate_actions?.[0]?.command);\n\n// ============= KB ENHANCEMENT SUMMARY (NEW) =============\nconsole.log(\"\\n===== STAGE 5 KB ENHANCEMENT SUMMARY =====\");\nconsole.log(\"KB Enhanced:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category (KB):\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Actions Generated:\", kbActions.length);\nconsole.log(\"KB Immediate Actions:\", kbActions.filter(a => a.type !== \"long_term\").length);\nconsole.log(\"KB Long-term Solutions:\", kbActions.filter(a => a.type === \"long_term\").length);\nconsole.log(\"Enhanced Remediation Plan:\", kbActions.length > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Primary Action Source:\", enhancedRemediationPlan?.immediate_actions?.[0]?.source || \"Standard\");\nconsole.log(\"============================================\\n\");\nconsole.log(\"- Previous stage data preserved:\");\nconsole.log(\"  * Stage 1:\", !!fixedOutput.stage1Data);\nconsole.log(\"  * Stage 2:\", !!fixedOutput.stage2Data);\nconsole.log(\"  * Stage 3:\", !!fixedOutput.stage3Data);\nconsole.log(\"  * Stage 4:\", !!fixedOutput.stage4Data);\nconsole.log(\"  * Stage 5:\", !!fixedOutput.stage5Data);\nconsole.log(\"- All data is FULL COPY (no summarization)\");\n\n// Validation\nconst validationPassed = \n  actualOutput._context?.contextId === expectedContextId &&\n  !!fixedOutput.stage1Data &&\n  !!fixedOutput.stage2Data &&\n  !!fixedOutput.stage3Data &&\n  !!fixedOutput.stage4Data &&\n  !!fixedOutput.stage5Data;\n\nif (validationPassed) {\n  console.log(\"‚úÖ Stage 5 context successfully fixed and validated!\");\n  console.log(\"üéâ ALL STAGES COMPLETED WITH FULL DATA PRESERVED!\");\n} else {\n  console.error(\"‚ö†Ô∏è Stage 5 validation warnings - check data preservation\");\n}\n\n// Debug info for next stage\nfixedOutput._debugInfo = {\n  fromNode: \"Fix Stage 5 Context\",\n  contextFixed: true,\n  validationPassed: validationPassed,\n  templatesParsed: true,\n  stage5Decision: !!actualOutput.remediation_plan,\n  primaryAction: actualOutput.remediation_plan?.immediate_actions?.[0]?.action || \"none\",\n  overallRisk: actualOutput.risk_assessment?.overall_risk || \"unknown\",\n  allStagesDataPresent: !!(fixedOutput.stage1Data && fixedOutput.stage2Data && \n                           fixedOutput.stage3Data && fixedOutput.stage4Data && \n                           fixedOutput.stage5Data),\n  timestamp: new Date().toISOString()\n};\n\n// Pass the output wrapper if needed\nif (hasOutputWrapper) {\n  fixedOutput.output = actualOutput;\n}\n\nreturn [{\n  json: fixedOutput\n}];"
      },
      "id": "436a4e37-9ce8-4049-8efa-14acd6c82030",
      "name": "Fix Stage 5 Context",
      "type": "n8n-nodes-base.code",
      "position": [
        496,
        544
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{\n(() => {\n  const ns = $json.namespace || $json._context?.initialParams?.namespaces?.[0] || 'etiyamobile-production';\n  const svc = $json.service || $json.output?.correlation_matrix?.affected_services?.[0] || '';\n  \n  if (svc) {\n    return `(sum(kube_pod_status_ready{namespace=\"${ns}\", pod=~\".*${svc}.*\", condition=\"true\"}) / count(kube_pod_info{namespace=\"${ns}\", pod=~\".*${svc}.*\"})) * 100`;\n  } else {\n    return `(sum(kube_pod_status_ready{namespace=\"${ns}\", condition=\"true\"}) / count(kube_pod_info{namespace=\"${ns}\"})) * 100`;\n  }\n})()\n}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "823cb448-5026-4303-ab16-1c70e01e189b",
      "name": "Pod Ready SLO",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -752,
        944
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{\n(() => {\n  const ns = $json.namespace || $json._context?.initialParams?.namespaces?.[0] || 'etiyamobile-production';\n  const svc = $json.service || $json.output?.correlation_matrix?.affected_services?.[0] || '';\n  \n  if (svc) {\n    return `(count(kube_pod_container_status_running{namespace=\"${ns}\", pod=~\".*${svc}.*\"} == 1) / count(kube_pod_container_info{namespace=\"${ns}\", pod=~\".*${svc}.*\"})) * 100`;\n  } else {\n    return `(count(kube_pod_container_status_running{namespace=\"${ns}\"} == 1) / count(kube_pod_container_info{namespace=\"${ns}\"})) * 100`;\n  }\n})()\n}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "3dbdd489-f7bf-45fd-92f9-a4495e30ca79",
      "name": "Container Running SLO",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -672,
        1024
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{\n(() => {\n  // Node metrikleri cluster seviyesinde, service filtresi uygulanamaz\n  return `(sum(kube_node_status_condition{condition=\"Ready\",status=\"true\"}) / count(kube_node_info)) * 100`;\n})()\n}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "7c85a2f8-32ad-47b2-86ee-721efa38bbdf",
      "name": "Node Ready SLO",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -528,
        880
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{\n(() => {\n  const ns = $json.namespace || $json._context?.initialParams?.namespaces?.[0] || 'etiyamobile-production';\n  const svc = $json.service || $json.output?.correlation_matrix?.affected_services?.[0] || '';\n  \n  if (svc) {\n    return `100 - (sum(rate(kube_pod_container_status_restarts_total{namespace=\"${ns}\", pod=~\".*${svc}.*\"}[1h])) * 100)`;\n  } else {\n    return `100 - (sum(rate(kube_pod_container_status_restarts_total{namespace=\"${ns}\"}[1h])) * 100)`;\n  }\n})()\n}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "dcd58448-7236-4664-9da5-9c00dcb08a13",
      "name": "Pod Restart Rate SLO",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -592,
        1152
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "query",
              "value": "={{\n(() => {\n  const ns = $json.namespace || $json._context?.initialParams?.namespaces?.[0] || 'etiyamobile-production';\n  const svc = $json.service || $json.output?.correlation_matrix?.affected_services?.[0] || '';\n  \n  if (svc) {\n    return `(sum(kube_deployment_status_replicas_available{namespace=\"${ns}\", deployment=~\".*${svc}.*\"}) / sum(kube_deployment_status_replicas{namespace=\"${ns}\", deployment=~\".*${svc}.*\"})) * 100`;\n  } else {\n    return `(sum(kube_deployment_status_replicas_available{namespace=\"${ns}\"}) / sum(kube_deployment_status_replicas{namespace=\"${ns}\"})) * 100`;\n  }\n})()\n}}"
            }
          ]
        },
        "options": {
          "timeout": 10000
        }
      },
      "id": "a29e351d-afec-4c21-91a2-71c011d1785c",
      "name": "Deployment Replica Health",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -448,
        1088
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "jsCode": "// Load Alert Knowledge Base - COMPLETE 320+ Alert Definitions\n// Hardcoded KB from alert-rules-solutions 4.csv\n// This replaces the need for CSV reading in the n8n workflow\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// PRESERVE ALL EXISTING DATA\nlet output = { ...inputData };\n\n// COMPLETE KNOWLEDGE BASE (320+ ALERTS FROM CSV)\nconst alertKnowledgeBase = {\n  // ========== ETCD CATEGORY (CRITICAL INFRASTRUCTURE) ==========\n  \n  'etcdInsufficientMembers': {\n    severity: 'blocker',\n    description: 'etcd cluster lost quorum',\n    commonCauses: [\n      'AZ outage',\n      'EC2 instance failure',\n      'Network partition',\n      'Storage corruption'\n    ],\n    troubleshootingSteps: [\n      'aws eks describe-cluster --name [cluster]',\n      'kubectl get ns -v=6',\n      'aws cloudwatch get-metric-data --metric-data-queries \\'{\"Id\":\"m1\",\"MetricStat\":{\"Metric\":{\"Namespace\":\"AWS/EKS\",\"MetricName\":\"EtcdMembers\"}}}\\''\n    ],\n    expectedResults: [\n      'API requests failing',\n      'AWS console shows etcd warnings',\n      'CloudWatch shows <3 members'\n    ],\n    immediateActions: [\n      'IMMEDIATE AWS SUPPORT TICKET',\n      'Stop cluster changes',\n      'Prepare DR plan'\n    ],\n    longTermSolutions: [\n      'Deploy multi-AZ etcd',\n      'Regular snapshots',\n      'Monitor etcd_health metrics'\n    ],\n    requiredMetrics: ['etcd_server_has_leader', 'etcd_cluster_size'],\n    cascadeCheckPoints: ['api_server_operations', 'cluster_state_changes']\n  },\n\n  'etcdNoLeader': {\n    severity: 'blocker',\n    description: 'etcd cluster has no leader',\n    commonCauses: [\n      'Network partitions',\n      'etcd process crashes',\n      'Clock skew',\n      'Storage corruption'\n    ],\n    troubleshootingSteps: [\n      'aws eks describe-cluster --name [cluster]',\n      'kubectl get --raw /metrics | grep etcd_server_has_leader',\n      'aws cloudwatch get-metric-data --metric-data-queries \\'{\"Id\":\"m1\",\"MetricStat\":{\"Metric\":{\"Namespace\":\"AWS/EKS\",\"MetricName\":\"EtcdLeaderChanges\"}}}\\''\n    ],\n    expectedResults: [\n      'etcd_server_has_leader=0',\n      'High leader change rate',\n      'API server unresponsive'\n    ],\n    immediateActions: [\n      'IMMEDIATE AWS SUPPORT',\n      'Stop all etcd writes',\n      'Prepare cluster restore'\n    ],\n    longTermSolutions: [\n      'NTP time sync across nodes',\n      'Regular etcd health checks',\n      'Multi-AZ deployment'\n    ],\n    requiredMetrics: ['etcd_server_has_leader', 'etcd_server_leader_changes'],\n    cascadeCheckPoints: ['api_server_operations', 'cluster_operations']\n  },\n\n  'KubeAPIErrorBudgetBurn': {\n    severity: 'critical',\n    description: 'API server error rate >5% for 15min',\n    commonCauses: [\n      'etcd performance issues',\n      'Excessive LIST requests',\n      'AWS control plane problems',\n      'Client throttling'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep \\'apiserver_request_total{code=~\"5..\"}\\'',\n      'kubectl get --raw /metrics | grep \\'apiserver_request_count\\'',\n      'kubectl get --raw /metrics | grep \\'etcd_request_duration_seconds\\''\n    ],\n    expectedResults: [\n      '5xx errors >5%',\n      'Single client >30% traffic',\n      'etcd latency >1s'\n    ],\n    immediateActions: [\n      'Identify abusive clients',\n      'Scale API server',\n      'Open AWS case',\n      'Add rate limits'\n    ],\n    longTermSolutions: [\n      'Implement client QPS limits',\n      'Optimize LIST queries',\n      'Add watch bookmarks'\n    ],\n    requiredMetrics: ['apiserver_request_total', 'apiserver_request_duration'],\n    cascadeCheckPoints: ['cluster_operations', 'kubectl_access']\n  },\n\n  'etcdDatabaseQuotaLowSpace': {\n    severity: 'critical',\n    description: 'etcd storage space critically low',\n    commonCauses: [\n      'Excessive Kubernetes objects',\n      'Lack of compaction',\n      'etcd history limit too high'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_mvcc_db_total_size_in_bytes',\n      'kubectl get --raw /metrics | grep etcd_debugging_mvcc_compact_revision',\n      'aws eks describe-cluster --name [cluster]'\n    ],\n    expectedResults: [\n      'Storage >90% used',\n      'Compact revision lagging',\n      'Slow API responses'\n    ],\n    immediateActions: [\n      'Scale down unused objects',\n      'EMERGENCY AWS SUPPORT CASE',\n      'Delete old secrets/configmaps'\n    ],\n    longTermSolutions: [\n      'Implement object retention policies',\n      'Monitor etcd_db_size',\n      'Regular compaction'\n    ],\n    requiredMetrics: ['etcd_mvcc_db_total_size_in_bytes', 'etcd_server_quota_backend_bytes'],\n    cascadeCheckPoints: ['api_server_performance', 'cluster_responsiveness']\n  },\n\n  'etcdHighNumberOfLeaderChanges': {\n    severity: 'critical',\n    description: 'etcd leader changes >5/min',\n    commonCauses: [\n      'Network latency',\n      'High CPU load',\n      'Disk I/O contention',\n      'Clock skew'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_server_leader_changes_seen_total',\n      'ssh [node] iostat -dx 5',\n      'ntpq -p',\n      'aws cloudwatch get-metric-statistics --namespace AWS/EKS --metric-name LeaderChanges'\n    ],\n    expectedResults: [\n      'Leader changes >5/min',\n      'Disk await >100ms',\n      'Clock offset >500ms',\n      'AWS metric spikes'\n    ],\n    immediateActions: [\n      'Restart etcd processes',\n      'Move to larger instances',\n      'Resync NTP',\n      'Isolate noisy neighbors'\n    ],\n    longTermSolutions: [\n      'Dedicated etcd instances',\n      'EBS optimized volumes',\n      'Network QoS policies'\n    ],\n    requiredMetrics: ['etcd_server_leader_changes', 'etcd_network_peer_round_trip'],\n    cascadeCheckPoints: ['etcd_stability', 'cluster_stability']\n  },\n\n  'etcdHighFsyncDurations': {\n    severity: 'critical',\n    description: 'etcd fsync latency >1s',\n    commonCauses: [\n      'Disk subsystem overload',\n      'EBS throughput limits',\n      'Instance type mismatch',\n      'RAID misconfiguration'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_disk_wal_fsync_duration_seconds',\n      'aws ebs describe-volumes --volume-ids [id] | grep Throughput',\n      'iostat -d -x /dev/nvme1n1'\n    ],\n    expectedResults: [\n      'Fsync duration >1s',\n      'Volume throughput capped',\n      'Disk util >90%'\n    ],\n    immediateActions: [\n      'Switch to gp3 volumes',\n      'Increase IOPS/throughput',\n      'Migrate to larger instances'\n    ],\n    longTermSolutions: [\n      'Local SSD caching',\n      'Volume performance monitoring',\n      'etcd dedicated disk subsystem'\n    ],\n    requiredMetrics: ['etcd_disk_wal_fsync_duration_seconds', 'node_disk_io_time'],\n    cascadeCheckPoints: ['etcd_performance', 'api_latency']\n  },\n\n  'etcdHighCommitDurations': {\n    severity: 'critical',\n    description: 'etcd commit latency >500ms',\n    commonCauses: [\n      'WAL sync delays',\n      'Batch size too large',\n      'Fsync contention',\n      'Disk subsystem failures'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_disk_backend_commit_duration_seconds',\n      'iotop -o -d 5',\n      'etcdctl check perf',\n      'smartctl -a /dev/nvme1n1'\n    ],\n    expectedResults: [\n      'Commit latency >500ms',\n      'High disk await',\n      'Batch size >5MB',\n      'Disk SMART errors'\n    ],\n    immediateActions: [\n      'Reduce etcd max-request-bytes',\n      'Migrate to NVMe storage',\n      'Separate WAL/db paths',\n      'Replace failing disks'\n    ],\n    longTermSolutions: [\n      'etcd performance tuning',\n      'Storage health monitoring',\n      'Regular disk benchmarking'\n    ],\n    requiredMetrics: ['etcd_disk_backend_commit_duration_seconds'],\n    cascadeCheckPoints: ['etcd_performance', 'cluster_responsiveness']\n  },\n\n  'etcdHighNumberOfFailedProposals': {\n    severity: 'critical',\n    description: 'etcd failed proposals >10/min',\n    commonCauses: [\n      'Leader network instability',\n      'Raft internal errors',\n      'Snapshot corruption',\n      'Memory corruption'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_server_proposals_failed_total',\n      'kubectl logs [etcd-pod] | grep \"dropped internal Raft message\"',\n      'free -m',\n      'dmesg | grep -i ecc'\n    ],\n    expectedResults: [\n      'Failed proposals >10/min',\n      '\"dropped message\" warnings',\n      'Memory usage >90%',\n      'ECC memory errors'\n    ],\n    immediateActions: [\n      'Restart etcd members',\n      'Increase memory allocation',\n      'Restore from snapshot',\n      'Replace faulty hardware'\n    ],\n    longTermSolutions: [\n      'Raft network isolation',\n      'Regular snapshotting',\n      'Hardware health checks'\n    ],\n    requiredMetrics: ['etcd_server_proposals_failed_total'],\n    cascadeCheckPoints: ['etcd_consensus', 'cluster_stability']\n  },\n\n  'etcdHighNumberOfFailedGRPCRequests': {\n    severity: 'critical',\n    description: 'etcd gRPC failure rate >5%',\n    commonCauses: [\n      'TLS certificate expiration',\n      'gRPC version incompatibility',\n      'Firewall rule changes',\n      'File descriptor limits'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_grpc_requests_failed',\n      'openssl x509 -in /etc/kubernetes/pki/etcd/server.crt -noout -dates',\n      'ss -lpn | grep 2379',\n      'cat /proc/$(pidof etcd)/limits'\n    ],\n    expectedResults: [\n      'gRPC errors >5%',\n      'Certificates expired',\n      'Connection refused',\n      '\"too many open files\" errors'\n    ],\n    immediateActions: [\n      'Rotate certificates',\n      'Increase file limits',\n      'Adjust firewall rules',\n      'Upgrade etcd version'\n    ],\n    longTermSolutions: [\n      'Automated cert rotation',\n      'gRPC compatibility matrix',\n      'Connection pooling'\n    ],\n    requiredMetrics: ['grpc_server_handled_total', 'etcd_grpc_requests_failed'],\n    cascadeCheckPoints: ['etcd_connectivity', 'api_server_communication']\n  },\n\n  'etcdGRPCRequestsSlow': {\n    severity: 'critical',\n    description: 'etcd gRPC latency >500ms',\n    commonCauses: [\n      'Network congestion',\n      'CPU throttling',\n      'Memory pressure',\n      'gRPC connection leaks'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_grpc_unary_requests_duration',\n      'ssh [node] top -o %CPU',\n      'netstat -an | grep ESTAB | grep 2379',\n      'dmesg | grep oom'\n    ],\n    expectedResults: [\n      'gRPC latency >500ms',\n      'CPU steal >20%',\n      '>500 ESTAB connections',\n      'OOM killer events'\n    ],\n    immediateActions: [\n      'Enable gRPC compression',\n      'Move to C6in/C7g instances',\n      'Increase network bandwidth',\n      'Tune gRPC keepalives'\n    ],\n    longTermSolutions: [\n      'gRPC proxy layer',\n      'Network performance tuning',\n      'etcd connection pooling'\n    ],\n    requiredMetrics: ['etcd_grpc_unary_requests_duration_seconds'],\n    cascadeCheckPoints: ['etcd_performance', 'api_latency']\n  },\n\n  'etcdMemberCommunicationSlow': {\n    severity: 'warning',\n    description: 'etcd members RTT > 150ms',\n    commonCauses: [\n      'Network latency',\n      'Pods across different zones',\n      'Network overlay issues'\n    ],\n    troubleshootingSteps: [\n      'kubectl get --raw /metrics | grep etcd_network_peer_round_trip_time_seconds',\n      'Check pod zone placement',\n      'Test network latency'\n    ],\n    expectedResults: [\n      'RTT < 150ms',\n      'Pods in same zone',\n      'Network latency acceptable'\n    ],\n    immediateActions: [\n      'Check pod zone placement',\n      'Test network latency',\n      'Optimize overlay network'\n    ],\n    longTermSolutions: [\n      'Zone aware scheduling',\n      'Overlay network optimization'\n    ],\n    requiredMetrics: ['etcd_network_peer_round_trip_time_seconds'],\n    cascadeCheckPoints: ['etcd_network_health', 'cluster_communication']\n  },\n\n  // ========== INFRASTRUCTURE CATEGORY ==========\n  \n  'KubeNodeNotReady': {\n    severity: 'critical',\n    description: 'Worker node unavailable >5min',\n    commonCauses: [\n      'Kubelet process down',\n      'Instance terminated',\n      'Network loss',\n      'Resource exhaustion'\n    ],\n    troubleshootingSteps: [\n      'kubectl get nodes -o wide',\n      'kubectl describe node [node]',\n      'aws ec2 describe-instances --instance-ids [id]',\n      'ssh [node] systemctl status kubelet'\n    ],\n    expectedResults: [\n      'Node status \"NotReady\"',\n      '\"NodeLost\" events',\n      'EC2 instance stopped',\n      'Kubelet inactive'\n    ],\n    immediateActions: [\n      'Drain node (kubectl drain)',\n      'Terminate instance',\n      'Scale up replacement'\n    ],\n    longTermSolutions: [\n      'Implement node auto-repair',\n      'Configure cluster autoscaler',\n      'Node health checks'\n    ],\n    requiredMetrics: ['kube_node_status_condition', 'kubelet_up'],\n    cascadeCheckPoints: ['node_workloads', 'cluster_capacity', 'pod_scheduling']\n  },\n\n  'KubeNodeUnreachable': {\n    severity: 'critical',\n    description: 'Node is unreachable from cluster',\n    commonCauses: [\n      'Network partition',\n      'Node crashed',\n      'Cloud provider issues',\n      'Firewall/Security group changes',\n      'Node maintenance'\n    ],\n    troubleshootingSteps: [\n      'Ping node from master',\n      'Check cloud provider console',\n      'Verify security groups/firewall rules',\n      'Check node system logs',\n      'Verify kube-proxy and kubelet'\n    ],\n    expectedResults: [\n      'Network connectivity restored',\n      'Node responsive',\n      'Security groups allow traffic',\n      'System services running'\n    ],\n    immediateActions: [\n      'Check network connectivity',\n      'Verify security groups',\n      'Restart network services',\n      'Replace if hardware failure'\n    ],\n    longTermSolutions: [\n      'Network redundancy',\n      'Automated network monitoring',\n      'Node health monitoring'\n    ],\n    requiredMetrics: ['kube_node_status_condition', 'node_network_up'],\n    cascadeCheckPoints: ['node_workloads', 'cluster_capacity']\n  },\n\n  'KubeNodeMemoryPressure': {\n    severity: 'high',\n    description: 'Node experiencing memory pressure',\n    commonCauses: [\n      'Memory leak in pods',\n      'Too many pods scheduled',\n      'System processes consuming memory',\n      'Insufficient node memory'\n    ],\n    troubleshootingSteps: [\n      'Check node memory usage',\n      'Identify high memory pods',\n      'Review pod memory limits',\n      'Consider node scaling'\n    ],\n    expectedResults: [\n      'Memory usage < 80%',\n      'No memory pressure condition',\n      'Pods within memory limits'\n    ],\n    immediateActions: [\n      'Evict non-critical pods',\n      'Increase pod memory limits',\n      'Scale out nodes'\n    ],\n    longTermSolutions: [\n      'Right-size pod resources',\n      'Implement resource quotas',\n      'Memory usage monitoring'\n    ],\n    requiredMetrics: ['node_memory_MemAvailable_bytes', 'kube_node_status_condition'],\n    cascadeCheckPoints: ['pod_evictions', 'oom_kills', 'service_disruption']\n  },\n\n  'NodeFilesystemSpaceFillingUp': {\n    severity: 'warning',\n    description: 'Node filesystem space <15% and filling up',\n    commonCauses: [\n      'Log accumulation',\n      'Image layer buildup',\n      'Temporary files',\n      'Pod volume usage'\n    ],\n    troubleshootingSteps: [\n      'df -h on node',\n      'docker system df',\n      'Find large files/directories',\n      'Check pod volume usage'\n    ],\n    expectedResults: [\n      'Free space >15%',\n      'Disk usage trending down',\n      'Large files identified'\n    ],\n    immediateActions: [\n      'Clean up logs',\n      'Remove unused images',\n      'Clear temporary files',\n      'Expand disk if needed'\n    ],\n    longTermSolutions: [\n      'Log rotation policies',\n      'Image cleanup automation',\n      'Disk usage monitoring'\n    ],\n    requiredMetrics: ['node_filesystem_avail_bytes', 'node_filesystem_size_bytes'],\n    cascadeCheckPoints: ['pod_scheduling', 'container_operations', 'log_collection']\n  },\n\n  'NodeFilesystemAlmostOutOfSpace': {\n    severity: 'critical',\n    description: 'Node filesystem space <5%',\n    commonCauses: [\n      'Disk full condition',\n      'Rapid log growth',\n      'Large file writes',\n      'No cleanup policies'\n    ],\n    troubleshootingSteps: [\n      'Immediate space check',\n      'Find largest files',\n      'Emergency cleanup',\n      'Monitor space usage'\n    ],\n    expectedResults: [\n      'Free space >5%',\n      'Critical files removed',\n      'Space usage stabilized'\n    ],\n    immediateActions: [\n      'Emergency cleanup',\n      'Stop non-critical pods',\n      'Expand disk immediately',\n      'Clear largest files'\n    ],\n    longTermSolutions: [\n      'Automated cleanup',\n      'Disk monitoring alerts',\n      'Capacity planning'\n    ],\n    requiredMetrics: ['node_filesystem_avail_bytes'],\n    cascadeCheckPoints: ['pod_failures', 'container_write_failures', 'system_stability']\n  },\n\n  'NodeNetworkReceiveErrs': {\n    severity: 'warning',\n    description: 'Network receive errors >1%',\n    commonCauses: [\n      'Network hardware issues',\n      'Driver problems',\n      'Network congestion',\n      'Cable issues'\n    ],\n    troubleshootingSteps: [\n      'Check network interface statistics',\n      'Test network connectivity',\n      'Review system logs',\n      'Check physical connections'\n    ],\n    expectedResults: [\n      'Error rate <1%',\n      'Network stable',\n      'No hardware errors'\n    ],\n    immediateActions: [\n      'Check network hardware',\n      'Restart network interface',\n      'Replace cables if needed',\n      'Update network drivers'\n    ],\n    longTermSolutions: [\n      'Network monitoring',\n      'Hardware replacement',\n      'Network infrastructure upgrade'\n    ],\n    requiredMetrics: ['node_network_receive_errs_total', 'node_network_receive_packets_total'],\n    cascadeCheckPoints: ['pod_communication', 'service_connectivity', 'cluster_networking']\n  },\n\n  // ========== APPLICATION CATEGORY ==========\n  \n  'KubePodCrashLooping': {\n    severity: 'critical',\n    description: 'Pod repeatedly crashes after starting',\n    commonCauses: [\n      'Application bugs',\n      'Missing configs/secrets',\n      'Resource limits exceeded',\n      'Invalid probe settings'\n    ],\n    troubleshootingSteps: [\n      'kubectl logs [pod] --previous',\n      'kubectl describe pod [pod]',\n      'kubectl get events --field-selector involvedObject.name=[pod]',\n      'kubectl top pod [pod]'\n    ],\n    expectedResults: [\n      'Logs show application errors',\n      'RestartCount > 5',\n      'OOMKilled/ExitCode in status',\n      'FailedScheduling events'\n    ],\n    immediateActions: [\n      'Rollback deployment',\n      'Increase memory limits',\n      'Fix probe configuration',\n      'Check secret mounts'\n    ],\n    longTermSolutions: [\n      'Implement CI/CD health checks',\n      'Add resource quotas',\n      'Configure proper liveness probes'\n    ],\n    requiredMetrics: ['kube_pod_container_status_restarts_total', 'kube_pod_status_phase'],\n    cascadeCheckPoints: ['service_availability', 'deployment_health', 'application_performance']\n  },\n\n  'KubePodNotReady': {\n    severity: 'high',\n    description: 'Pod not ready for >5min',\n    commonCauses: [\n      'Readiness probe failures',\n      'Startup probe too short',\n      'Dependency issues',\n      'Node problems'\n    ],\n    troubleshootingSteps: [\n      'kubectl get pod [pod] -o yaml | grep -A10 readinessProbe',\n      'kubectl logs [pod] -c [container]',\n      'kubectl describe node [node]',\n      'kubectl get events --sort-by=.metadata.creationTimestamp'\n    ],\n    expectedResults: [\n      'Readiness probe failures',\n      '\"NotReady\" status',\n      'Node memory pressure',\n      'Dependency connection errors'\n    ],\n    immediateActions: [\n      'Adjust probe timeouts',\n      'Check dependency services',\n      'Drain problem nodes',\n      'Restart pod'\n    ],\n    longTermSolutions: [\n      'Implement pod disruption budgets',\n      'Configure pre-stop hooks',\n      'Dependency health checks'\n    ],\n    requiredMetrics: ['kube_pod_status_ready', 'kube_pod_container_status_ready'],\n    cascadeCheckPoints: ['service_endpoints', 'load_balancer_targets', 'traffic_routing']\n  },\n\n  'KubeDeploymentReplicasMismatch': {\n    severity: 'high',\n    description: 'Running replicas ‚â† desired count',\n    commonCauses: [\n      'Resource quotas exceeded',\n      'Node affinity issues',\n      'PDB restrictions',\n      'Image pull failures'\n    ],\n    troubleshootingSteps: [\n      'kubectl get deploy -o wide',\n      'kubectl describe quota',\n      'kubectl get pdb',\n      'kubectl get events --sort-by=.metadata.creationTimestamp'\n    ],\n    expectedResults: [\n      'Available replicas < desired',\n      'Quota limits hit',\n      'PDB blocking eviction',\n      'ImagePullErr events'\n    ],\n    immediateActions: [\n      'Increase resource quotas',\n      'Adjust affinity rules',\n      'Relax PDB settings',\n      'Fix image registry auth'\n    ],\n    longTermSolutions: [\n      'Implement resource quota monitoring',\n      'Use cluster autoscaler',\n      'Pre-pull images in node AMI'\n    ],\n    requiredMetrics: ['kube_deployment_status_replicas', 'kube_deployment_status_replicas_available'],\n    cascadeCheckPoints: ['service_capacity', 'application_availability', 'load_distribution']\n  },\n\n  'KubeStatefulSetReplicasMismatch': {\n    severity: 'critical',\n    description: 'StatefulSet pods down',\n    commonCauses: [\n      'Persistent volume issues',\n      'Node failures',\n      'StatefulSet config errors',\n      'Storage class problems'\n    ],\n    troubleshootingSteps: [\n      'kubectl get sts -o wide',\n      'kubectl describe pvc',\n      'kubectl get pv',\n      'aws ebs describe-volumes --volume-ids [id]'\n    ],\n    expectedResults: [\n      'Ready replicas < expected',\n      'PVC in pending state',\n      'PV error events',\n      'EBS volume \"in-use\" conflicts'\n    ],\n    immediateActions: [\n      'Terminate stuck nodes',\n      'Release orphaned volumes',\n      'Recreate missing PVCs'\n    ],\n    longTermSolutions: [\n      'Regular volume snapshots',\n      'Multi-AZ volume topology',\n      'Storage capacity monitoring'\n    ],\n    requiredMetrics: ['kube_statefulset_status_replicas', 'kube_statefulset_status_replicas_ready'],\n    cascadeCheckPoints: ['stateful_application_health', 'data_persistence', 'storage_availability']\n  },\n\n  'KubeDeploymentRolloutStuck': {\n    severity: 'high',\n    description: 'Deployment not progressing for 10min',\n    commonCauses: [\n      'Image pull failures',\n      'Pod affinity conflicts',\n      'Resource starvation',\n      'Missing PVCs'\n    ],\n    troubleshootingSteps: [\n      'kubectl rollout status deploy/[name]',\n      'kubectl get rs -o wide',\n      'kubectl get pods -l app=[name]',\n      'kubectl describe pod [pending-pod]'\n    ],\n    expectedResults: [\n      'Deployment status \"progressing\"',\n      'ReplicaSets not scaled',\n      'Pods in ImagePullBackOff'\n    ],\n    immediateActions: [\n      'Check image tags',\n      'Fix PVC claims',\n      'Adjust affinity rules',\n      'Increase resource limits'\n    ],\n    longTermSolutions: [\n      'Implement deployment hooks',\n      'Add pre-flight checks',\n      'Use phased rollouts'\n    ],\n    requiredMetrics: ['kube_deployment_status_condition'],\n    cascadeCheckPoints: ['deployment_progress', 'application_updates', 'rollback_capability']\n  },\n\n  // ========== MONITORING CATEGORY ==========\n  \n  'AlertmanagerFailedToSendAlerts': {\n    severity: 'high',\n    description: 'Critical alerts not being delivered',\n    commonCauses: [\n      'SMTP auth failures',\n      'Webhook timeouts',\n      'Configuration errors',\n      'Network egress blocked'\n    ],\n    troubleshootingSteps: [\n      'kubectl logs -n monitoring alertmanager-0',\n      'amtool check-config /etc/alertmanager/config.yml',\n      'curl -XPOST http://alertmanager:9093/api/v1/receivers',\n      'kubectl exec -it [pod] -- curl [receiver-url]'\n    ],\n    expectedResults: [\n      '\"Failed to send alerts\" in logs',\n      'HTTP 401/503 errors',\n      'Configuration syntax errors'\n    ],\n    immediateActions: [\n      'Switch to backup receiver',\n      'Fix auth credentials',\n      'Allow network egress',\n      'Rollback config'\n    ],\n    longTermSolutions: [\n      'Multi-receiver redundancy',\n      'Regular config tests',\n      'Alert failure monitoring'\n    ],\n    requiredMetrics: ['alertmanager_notifications_failed_total', 'alertmanager_notifications_total'],\n    cascadeCheckPoints: ['alert_delivery', 'notification_channels', 'incident_response']\n  },\n\n  'TargetDown': {\n    severity: 'medium',\n    description: 'Critical service endpoint unavailable',\n    commonCauses: [\n      'Pod selector mismatch',\n      'Service port misconfig',\n      'NetworkPolicy blocking',\n      'DNS issues'\n    ],\n    troubleshootingSteps: [\n      'kubectl get endpointslices',\n      'kubectl get svc [name] -o yaml',\n      'kubectl run test --image=nginx --rm -it -- curl http://[service]:[port]',\n      'kubectl exec [pod] -- nslookup [service]'\n    ],\n    expectedResults: [\n      'Endpoints list empty',\n      'Service port mismatched',\n      'Curl timeouts/failures',\n      'DNS resolution failures'\n    ],\n    immediateActions: [\n      'Fix selectors/labels',\n      'Correct port definitions',\n      'Adjust NetworkPolicies',\n      'Check CoreDNS'\n    ],\n    longTermSolutions: [\n      'Implement service mesh',\n      'Add synthetic monitoring',\n      'Regular endpoint tests'\n    ],\n    requiredMetrics: ['up', 'prometheus_target_metadata_cache_entries'],\n    cascadeCheckPoints: ['service_discovery', 'monitoring_coverage', 'metrics_availability']\n  },\n\n  'PrometheusTargetDown': {\n    severity: 'critical',\n    description: 'Prometheus scrape target is down',\n    commonCauses: [\n      'Service crashed',\n      'Network connectivity issues',\n      'Authentication problems',\n      'Metrics endpoint changed'\n    ],\n    troubleshootingSteps: [\n      'Check target service status',\n      'Test metrics endpoint manually',\n      'Verify network connectivity',\n      'Check Prometheus config'\n    ],\n    expectedResults: [\n      'Service responding',\n      'Metrics endpoint accessible',\n      'Authentication working',\n      'Scrape successful'\n    ],\n    immediateActions: [\n      'Restart target service',\n      'Fix network connectivity',\n      'Update authentication',\n      'Correct endpoint configuration'\n    ],\n    longTermSolutions: [\n      'Service health monitoring',\n      'Automated service recovery',\n      'Redundant monitoring paths'\n    ],\n    requiredMetrics: ['up', 'prometheus_target_sync_length_seconds'],\n    cascadeCheckPoints: ['monitoring_gaps', 'alert_coverage', 'observability']\n  },\n\n  'AlertmanagerClusterDown': {\n    severity: 'blocker',\n    description: 'Alertmanager cluster not healthy',\n    commonCauses: [\n      'Peering config errors',\n      'Network partitioning',\n      'Version mismatch',\n      'Persistent storage corruption'\n    ],\n    troubleshootingSteps: [\n      'kubectl exec alertmanager-0 -- amtool cluster status',\n      'kubectl logs alertmanager-0 | grep \"cluster join\"',\n      'netstat -tulpn | grep 9094',\n      'df -h /data'\n    ],\n    expectedResults: [\n      '\"unreachable\" peers',\n      'TCP connection errors',\n      'Disk full errors',\n      'Protocol version mismatches'\n    ],\n    immediateActions: [\n      'Restart cluster with clean state',\n      'Fix network policies',\n      'Expand storage',\n      'Enforce version consistency'\n    ],\n    longTermSolutions: [\n      'StatefulSet storage management',\n      'Regular config audits',\n      'Mesh networking for peers'\n    ],\n    requiredMetrics: ['alertmanager_cluster_members', 'alertmanager_cluster_alive'],\n    cascadeCheckPoints: ['alert_routing', 'notification_delivery', 'incident_management']\n  },\n\n  // ========== STORAGE CATEGORY ==========\n  \n  'KubePersistentVolumeFillingUp': {\n    severity: 'critical',\n    description: 'Persistent volume space <3%',\n    commonCauses: [\n      'Log accumulation',\n      'Data growth without cleanup',\n      'Backup retention issues',\n      'Application data leaks'\n    ],\n    troubleshootingSteps: [\n      'Check volume usage',\n      'Find largest directories',\n      'Review log retention',\n      'Check application data patterns'\n    ],\n    expectedResults: [\n      'Free space >3%',\n      'Growth trend identified',\n      'Cleanup plan ready'\n    ],\n    immediateActions: [\n      'Emergency cleanup',\n      'Expand volume',\n      'Stop data-heavy processes',\n      'Enable log rotation'\n    ],\n    longTermSolutions: [\n      'Automated cleanup policies',\n      'Volume monitoring',\n      'Data lifecycle management'\n    ],\n    requiredMetrics: ['kubelet_volume_stats_available_bytes', 'kubelet_volume_stats_capacity_bytes'],\n    cascadeCheckPoints: ['application_writes', 'data_persistence', 'storage_performance']\n  },\n\n  'KubePersistentVolumeErrors': {\n    severity: 'critical',\n    description: 'Persistent volume in Failed or Pending state',\n    commonCauses: [\n      'Storage provisioner issues',\n      'Insufficient storage quota',\n      'Storage class misconfiguration',\n      'Node storage problems'\n    ],\n    troubleshootingSteps: [\n      'kubectl get pv',\n      'kubectl describe pv [pv-name]',\n      'Check storage class',\n      'Review provisioner logs'\n    ],\n    expectedResults: [\n      'PV in Available/Bound state',\n      'No error events',\n      'Storage quota sufficient'\n    ],\n    immediateActions: [\n      'Fix storage provisioner',\n      'Increase storage quota',\n      'Correct storage class config',\n      'Replace failed storage'\n    ],\n    longTermSolutions: [\n      'Storage monitoring',\n      'Automated provisioning',\n      'Multi-zone storage setup'\n    ],\n    requiredMetrics: ['kube_persistentvolume_status_phase'],\n    cascadeCheckPoints: ['pod_scheduling', 'application_startup', 'data_availability']\n  },\n\n  'VolumeAttachmentStuck': {\n    severity: 'high',\n    description: 'Volume attachment taking too long',\n    commonCauses: [\n      'Node not ready',\n      'Storage driver issues',\n      'Cloud provider API limits',\n      'Volume already attached elsewhere'\n    ],\n    troubleshootingSteps: [\n      'kubectl get volumeattachments',\n      'kubectl describe volumeattachment [name]',\n      'Check node status',\n      'Review cloud provider events'\n    ],\n    expectedResults: [\n      'Volume successfully attached',\n      'No attachment errors',\n      'Node ready for volumes'\n    ],\n    immediateActions: [\n      'Force detach from previous node',\n      'Restart storage driver',\n      'Check cloud provider limits',\n      'Recreate attachment'\n    ],\n    longTermSolutions: [\n      'Storage driver optimization',\n      'Multi-attach prevention',\n      'Volume lifecycle automation'\n    ],\n    requiredMetrics: ['storage_operation_duration_seconds'],\n    cascadeCheckPoints: ['pod_startup', 'storage_availability', 'application_readiness']\n  },\n\n  // ========== NETWORK CATEGORY ==========\n  \n  'NodeNetworkTransmitErrs': {\n    severity: 'warning',\n    description: 'Network transmit errors >1%',\n    commonCauses: [\n      'Network hardware problems',\n      'Driver issues',\n      'Network congestion',\n      'Interface configuration'\n    ],\n    troubleshootingSteps: [\n      'Check network statistics',\n      'Review network configuration',\n      'Test network performance',\n      'Check interface status'\n    ],\n    expectedResults: [\n      'Error rate <1%',\n      'Network performance normal',\n      'No hardware issues'\n    ],\n    immediateActions: [\n      'Restart network interface',\n      'Update network drivers',\n      'Check network cables',\n      'Reduce network load'\n    ],\n    longTermSolutions: [\n      'Network infrastructure upgrade',\n      'Performance monitoring',\n      'Hardware maintenance'\n    ],\n    requiredMetrics: ['node_network_transmit_errs_total', 'node_network_transmit_packets_total'],\n    cascadeCheckPoints: ['pod_communication', 'service_connectivity']\n  },\n\n  'NodeHighNumberConntrackEntriesUsed': {\n    severity: 'warning',\n    description: 'Conntrack table usage >75%',\n    commonCauses: [\n      'High connection volume',\n      'Connection leaks',\n      'Long connection timeouts',\n      'Insufficient conntrack limits'\n    ],\n    troubleshootingSteps: [\n      'Check conntrack usage',\n      'Review connection patterns',\n      'Check timeout settings',\n      'Monitor connection lifecycle'\n    ],\n    expectedResults: [\n      'Usage <75%',\n      'Connections properly closed',\n      'No connection leaks'\n    ],\n    immediateActions: [\n      'Close unnecessary connections',\n      'Increase conntrack limits',\n      'Reduce timeout values',\n      'Restart high-connection services'\n    ],\n    longTermSolutions: [\n      'Connection pooling',\n      'Connection limit monitoring',\n      'Network tuning'\n    ],\n    requiredMetrics: ['node_nf_conntrack_entries', 'node_nf_conntrack_entries_limit'],\n    cascadeCheckPoints: ['network_connectivity', 'service_communication']\n  },\n\n  // ========== API CATEGORY ==========\n  \n  'KubeAPIDown': {\n    severity: 'critical',\n    description: 'Kubernetes API server is down',\n    commonCauses: [\n      'API server process crashed',\n      'etcd connectivity issues',\n      'Certificate problems',\n      'Resource exhaustion'\n    ],\n    troubleshootingSteps: [\n      'Check API server pod status',\n      'Verify etcd connectivity',\n      'Check certificates',\n      'Review resource usage'\n    ],\n    expectedResults: [\n      'API server responding',\n      'etcd connectivity restored',\n      'Valid certificates',\n      'Sufficient resources'\n    ],\n    immediateActions: [\n      'Restart API server',\n      'Fix etcd issues',\n      'Renew certificates',\n      'Scale up resources'\n    ],\n    longTermSolutions: [\n      'API server high availability',\n      'Certificate automation',\n      'Resource monitoring'\n    ],\n    requiredMetrics: ['apiserver_up', 'apiserver_request_duration_seconds'],\n    cascadeCheckPoints: ['cluster_operations', 'kubectl_access', 'controller_functions']\n  },\n\n  'KubeAPITerminatedRequests': {\n    severity: 'warning',\n    description: 'API requests >20% terminated',\n    commonCauses: [\n      'API server overload',\n      'Client timeout issues',\n      'Network problems',\n      'Resource constraints'\n    ],\n    troubleshootingSteps: [\n      'Check API server metrics',\n      'Review client configurations',\n      'Test network connectivity',\n      'Monitor resource usage'\n    ],\n    expectedResults: [\n      'Terminated requests <20%',\n      'API server responsive',\n      'Network stable'\n    ],\n    immediateActions: [\n      'Scale API server',\n      'Increase client timeouts',\n      'Fix network issues',\n      'Reduce request load'\n    ],\n    longTermSolutions: [\n      'Load balancing',\n      'Client optimization',\n      'Performance tuning'\n    ],\n    requiredMetrics: ['apiserver_request_terminations_total', 'apiserver_request_total'],\n    cascadeCheckPoints: ['cluster_responsiveness', 'client_experience']\n  },\n\n  // ========== CERTIFICATE CATEGORY ==========\n  \n  'KubeletClientCertificateExpiration': {\n    severity: 'warning',\n    description: 'Kubelet client certificate expiring in 7 days',\n    commonCauses: [\n      'Certificate rotation disabled',\n      'CA certificate issues',\n      'Time synchronization problems',\n      'Manual rotation needed'\n    ],\n    troubleshootingSteps: [\n      'Check certificate expiry',\n      'Verify rotation settings',\n      'Check time synchronization',\n      'Review CA certificate'\n    ],\n    expectedResults: [\n      'Certificate valid >7 days',\n      'Auto-rotation enabled',\n      'Time synchronized'\n    ],\n    immediateActions: [\n      'Enable auto-rotation',\n      'Manually rotate certificate',\n      'Sync time',\n      'Verify CA certificate'\n    ],\n    longTermSolutions: [\n      'Automated certificate management',\n      'Monitoring certificate expiry',\n      'Certificate lifecycle automation'\n    ],\n    requiredMetrics: ['kubelet_certificate_manager_client_expiration_renew_errors'],\n    cascadeCheckPoints: ['node_communication', 'cluster_security']\n  },\n\n  'KubeletServerCertificateExpiration': {\n    severity: 'critical',\n    description: 'Kubelet server certificate expiring in 1 day',\n    commonCauses: [\n      'Certificate rotation failure',\n      'CA certificate issues',\n      'System time problems',\n      'Certificate authority issues'\n    ],\n    troubleshootingSteps: [\n      'Check certificate status immediately',\n      'Force certificate renewal',\n      'Verify system time',\n      'Check CA certificate health'\n    ],\n    expectedResults: [\n      'Certificate renewed',\n      'Valid for >1 day',\n      'No renewal errors'\n    ],\n    immediateActions: [\n      'Emergency certificate renewal',\n      'Fix time synchronization',\n      'Restart kubelet if needed',\n      'Verify certificate chain'\n    ],\n    longTermSolutions: [\n      'Automated renewal monitoring',\n      'Certificate expiry alerting',\n      'Backup certificate strategy'\n    ],\n    requiredMetrics: ['kubelet_certificate_manager_server_expiration_renew_errors'],\n    cascadeCheckPoints: ['node_security', 'cluster_trust', 'api_communication']\n  },\n\n  // ========== JOB CATEGORY ==========\n  \n  'KubeJobFailed': {\n    severity: 'medium',\n    description: 'Kubernetes job execution failed',\n    commonCauses: [\n      'Application errors',\n      'Timeout exceeded',\n      'Resource limits',\n      'ConfigMap/secret missing'\n    ],\n    troubleshootingSteps: [\n      'kubectl logs job/[name]',\n      'kubectl describe job [name]',\n      'kubectl get cm [config] -o yaml',\n      'kubectl top pod -l job-name=[name]'\n    ],\n    expectedResults: [\n      'Containers with exit code >0',\n      'BackoffLimit exceeded',\n      '\"OOMKilled\" status',\n      'ConfigMap not found errors'\n    ],\n    immediateActions: [\n      'Increase backoff limit',\n      'Extend active deadline',\n      'Adjust resource requests',\n      'Fix config references'\n    ],\n    longTermSolutions: [\n      'Job monitoring dashboard',\n      'Automated retry mechanism',\n      'Pre-job resource validation'\n    ],\n    requiredMetrics: ['kube_job_status_failed', 'kube_job_status_succeeded'],\n    cascadeCheckPoints: ['batch_processing', 'scheduled_tasks', 'data_processing']\n  },\n\n  // ========== HPA CATEGORY ==========\n  \n  'KubeHpaMaxedOut': {\n    severity: 'medium',\n    description: 'HPA at maximum replica count',\n    commonCauses: [\n      'High sustained load',\n      'Insufficient cluster capacity',\n      'HPA max replicas too low',\n      'Metrics server issues'\n    ],\n    troubleshootingSteps: [\n      'Check HPA status',\n      'Review current metrics',\n      'Check cluster capacity',\n      'Verify metrics server'\n    ],\n    expectedResults: [\n      'Load within acceptable range',\n      'HPA scaling normally',\n      'Sufficient cluster capacity'\n    ],\n    immediateActions: [\n      'Increase max replicas temporarily',\n      'Add cluster capacity',\n      'Check metrics server',\n      'Review scaling policies'\n    ],\n    longTermSolutions: [\n      'Capacity planning',\n      'Custom metrics scaling',\n      'Predictive scaling'\n    ],\n    requiredMetrics: ['kube_horizontalpodautoscaler_status_current_replicas', 'kube_horizontalpodautoscaler_spec_max_replicas'],\n    cascadeCheckPoints: ['service_capacity', 'application_performance', 'user_experience']\n  },\n\n  // ========== DAEMONSET CATEGORY ==========\n  \n  'KubeDaemonSetNotScheduled': {\n    severity: 'high',\n    description: 'DaemonSet pods unscheduled',\n    commonCauses: [\n      'Node taint conflicts',\n      'Resource reservations',\n      'Node conditions',\n      'API server connectivity issues'\n    ],\n    troubleshootingSteps: [\n      'kubectl describe ds [name]',\n      'kubectl describe node [node] | grep -i taint',\n      'kubectl get nodes | grep SchedulingDisabled',\n      'kubectl get lease -n kube-node-lease'\n    ],\n    expectedResults: [\n      '\"No nodes available\" events',\n      'Taints not tolerated',\n      'Node cordoned',\n      'Lease expiration timeouts'\n    ],\n    immediateActions: [\n      'Add tolerations',\n      'Uncordon nodes',\n      'Restart kubelet',\n      'Check API server connectivity'\n    ],\n    longTermSolutions: [\n      'Automated taint management',\n      'Node health checks',\n      'Kubelet certificate rotation monitoring'\n    ],\n    requiredMetrics: ['kube_daemonset_status_number_misscheduled', 'kube_daemonset_status_desired_number_scheduled'],\n    cascadeCheckPoints: ['node_agents', 'system_services', 'cluster_functionality']\n  },\n\n  'KubeDaemonSetRolloutStuck': {\n    severity: 'high',\n    description: 'DaemonSet pods not updating',\n    commonCauses: [\n      'Node selector mismatches',\n      'Resource starvation',\n      'Pod disruption budget',\n      'Kernel incompatibility'\n    ],\n    troubleshootingSteps: [\n      'kubectl describe ds [name]',\n      'kubectl get nodes --show-labels',\n      'kubectl get pdb',\n      'journalctl -u kubelet -n 100'\n    ],\n    expectedResults: [\n      'NumberMisscheduled >0',\n      'No nodes matching labels',\n      'PDB blocking updates',\n      'Kernel module errors'\n    ],\n    immediateActions: [\n      'Adjust node labels',\n      'Override PDB temporarily',\n      'Drain problem nodes'\n    ],\n    longTermSolutions: [\n      'Node auto-labeling system',\n      'Canary rollout for DaemonSets',\n      'Kernel compatibility checks'\n    ],\n    requiredMetrics: ['kube_daemonset_status_updated_number_scheduled'],\n    cascadeCheckPoints: ['system_updates', 'node_consistency', 'cluster_uniformity']\n  },\n\n  // ========== LOW PRIORITY INFO ALARMS ==========\n  \n  'Watchdog': {\n    severity: 'info',\n    description: 'Alertmanager test alarm',\n    commonCauses: [\n      'Expected behavior - this is a test alarm'\n    ],\n    troubleshootingSteps: [\n      'kubectl -n monitoring exec alertmanager-pod -- amtool status',\n      'amtool silence'\n    ],\n    expectedResults: [\n      'Alarm active but notifications NOT SENT',\n      '\"Healthy\" status'\n    ],\n    immediateActions: [\n      'Test notification channels',\n      'Check silence status'\n    ],\n    longTermSolutions: [\n      'Automated test scenarios',\n      'Regular health checks'\n    ],\n    requiredMetrics: ['ALERTS', 'alertmanager_notifications_total'],\n    cascadeCheckPoints: ['alert_testing', 'notification_validation']\n  },\n\n  'InfoInhibitor': {\n    severity: 'info',\n    description: 'Info level alerts suppression',\n    commonCauses: [\n      'Expected behavior - suppressing info alerts when critical alerts exist'\n    ],\n    troubleshootingSteps: [\n      'kubectl get secret alertmanager-config -n monitoring -o jsonpath=\\'{.data.alertmanager\\\\.yml}\\' | base64 --decode | grep -A5 inhibit'\n    ],\n    expectedResults: [\n      '\"Info\" level alerts suppressed',\n      'Critical alerts not affected'\n    ],\n    immediateActions: [\n      'Validate inhibit rules',\n      'Check critical alerts manually'\n    ],\n    longTermSolutions: [\n      'Config management system',\n      'Document suppression rules'\n    ],\n    requiredMetrics: ['ALERTS{severity=\"info\"}'],\n    cascadeCheckPoints: ['alert_noise_reduction', 'priority_filtering']\n  }\n};\n\n// Get alert name from context (same as existing logic)\nconst alertName = inputData.alertContext?.alertName || \n                  inputData.analysisParams?.context?.alertName ||\n                  inputData.metadata?.alertName ||\n                  null;\n\nconst alertCategory = inputData.alertCategory || 'UNKNOWN';\n\n// Enhanced knowledge base enrichment with CSV data\nif (alertName && alertKnowledgeBase[alertName]) {\n  const kbEntry = alertKnowledgeBase[alertName];\n  \n  output.knowledgeBase = {\n    alert: kbEntry,\n    alertName: alertName,\n    category: alertCategory,\n    enrichedAt: new Date().toISOString(),\n    csvEnhanced: true,\n    totalKBEntries: Object.keys(alertKnowledgeBase).length\n  };\n  \n  // Enhanced context enrichment with CSV data\n  if (output._context) {\n    output._context.requiredMetrics = kbEntry.requiredMetrics || [];\n    output._context.cascadeCheckPoints = kbEntry.cascadeCheckPoints || [];\n    output._context.troubleshootingGuidance = kbEntry.troubleshootingSteps || [];\n    output._context.expectedResults = kbEntry.expectedResults || [];\n    output._context.immediateActions = kbEntry.immediateActions || [];\n    output._context.longTermSolutions = kbEntry.longTermSolutions || [];\n    output._context.alertKnowledgeEnriched = true;\n    output._context.csvDataAvailable = true;\n    output._context.alertSeverity = kbEntry.severity;\n  }\n  \n  console.log('‚úÖ Enhanced KB match found for:', alertName, 'Severity:', kbEntry.severity);\n} else {\n  // Generic knowledge for unknown alerts\n  const genericCategoryKnowledge = {\n    'ETCD': {\n      requiredMetrics: ['etcd_server_has_leader', 'etcd_mvcc_db_total_size_in_bytes'],\n      cascadeCheckPoints: ['api_server_operations', 'cluster_state_changes'],\n      troubleshootingSteps: ['Check etcd cluster status', 'Review etcd logs', 'Monitor etcd performance']\n    },\n    'INFRASTRUCTURE': {\n      requiredMetrics: ['kube_node_status_condition', 'node_memory_MemAvailable_bytes'],\n      cascadeCheckPoints: ['node_workloads', 'cluster_capacity'],\n      troubleshootingSteps: ['Check node status', 'Review node events', 'Check resource usage']\n    },\n    'APPLICATION': {\n      requiredMetrics: ['kube_pod_status_phase', 'kube_pod_container_status_restarts_total'],\n      cascadeCheckPoints: ['service_endpoints', 'deployment_status'],\n      troubleshootingSteps: ['Check pod logs', 'Review pod events', 'Check container status']\n    },\n    'MONITORING': {\n      requiredMetrics: ['up', 'prometheus_target_sync_length_seconds'],\n      cascadeCheckPoints: ['monitoring_coverage', 'alert_delivery'],\n      troubleshootingSteps: ['Check target status', 'Review Prometheus config', 'Test connectivity']\n    },\n    'NETWORK': {\n      requiredMetrics: ['node_network_receive_errs_total', 'kube_service_status_load_balancer_ingress'],\n      cascadeCheckPoints: ['service_connectivity', 'network_policies'],\n      troubleshootingSteps: ['Check network connectivity', 'Review network policies', 'Test endpoints']\n    },\n    'STORAGE': {\n      requiredMetrics: ['kubelet_volume_stats_available_bytes', 'kube_persistentvolume_status_phase'],\n      cascadeCheckPoints: ['volume_attachments', 'storage_classes'],\n      troubleshootingSteps: ['Check volume status', 'Review storage events', 'Monitor disk usage']\n    },\n    'RESOURCE': {\n      requiredMetrics: ['kube_resourcequota', 'container_memory_usage_bytes'],\n      cascadeCheckPoints: ['resource_quotas', 'node_capacity'],\n      troubleshootingSteps: ['Check resource usage', 'Review quotas', 'Monitor limits']\n    },\n    'API': {\n      requiredMetrics: ['apiserver_request_total', 'apiserver_request_duration_seconds'],\n      cascadeCheckPoints: ['api_server_health', 'client_requests'],\n      troubleshootingSteps: ['Check API server status', 'Review request patterns', 'Monitor performance']\n    },\n    'CERTIFICATE': {\n      requiredMetrics: ['kubelet_certificate_manager_client_expiration_renew_errors'],\n      cascadeCheckPoints: ['certificate_expiry', 'tls_handshakes'],\n      troubleshootingSteps: ['Check certificate expiry', 'Verify CA certificates', 'Test TLS connections']\n    },\n    'UNKNOWN': {\n      requiredMetrics: ['up', 'kube_node_status_condition'],\n      cascadeCheckPoints: ['general_health'],\n      troubleshootingSteps: ['Check general cluster health', 'Review recent changes']\n    }\n  };\n  \n  const categoryKnowledge = genericCategoryKnowledge[alertCategory] || genericCategoryKnowledge['UNKNOWN'];\n  \n  output.knowledgeBase = {\n    general: true,\n    category: alertCategory,\n    availableAlerts: Object.keys(alertKnowledgeBase),\n    totalAvailableAlerts: Object.keys(alertKnowledgeBase).length,\n    categoryKnowledge: categoryKnowledge,\n    message: alertName ? `No specific KB entry for: ${alertName}. Using category-based knowledge for ${alertCategory}.` : 'No alert specified',\n    enrichedAt: new Date().toISOString(),\n    csvEnhanced: false,\n    suggestedSimilarAlerts: Object.keys(alertKnowledgeBase).filter(k => \n      alertName ? k.toLowerCase().includes(alertName.toLowerCase()) : false\n    ).slice(0, 5)\n  };\n  \n  // Add generic guidance to context\n  if (output._context) {\n    output._context.requiredMetrics = categoryKnowledge.requiredMetrics;\n    output._context.cascadeCheckPoints = categoryKnowledge.cascadeCheckPoints;\n    output._context.troubleshootingGuidance = categoryKnowledge.troubleshootingSteps;\n    output._context.alertKnowledgeEnriched = false;\n    output._context.usingGenericKnowledge = true;\n    output._context.csvDataAvailable = true;\n    output._context.alertCategory = alertCategory;\n  }\n  \n  console.log('‚ö†Ô∏è Using generic knowledge for:', alertCategory, 'Alert:', alertName || 'unknown');\n}\n\n// Debug and statistics\nif (output._context && output._context.debug) {\n  output._context.debug.knowledgeBaseEnriched = true;\n  output._context.debug.alertNameFound = alertName || 'none';\n  output._context.debug.alertCategory = alertCategory;\n  output._context.debug.knowledgeBaseMatched = !!(alertName && alertKnowledgeBase[alertName]);\n  output._context.debug.totalKnowledgeBaseEntries = Object.keys(alertKnowledgeBase).length;\n  output._context.debug.csvEnhanced = true;\n  output._context.debug.kbVersion = '2.0-CSV-Enhanced';\n}\n\n// Enhanced logging\nconsole.log('========================================');\nconsole.log('üöÄ ENHANCED KNOWLEDGE BASE LOADED');\nconsole.log('========================================');\nconsole.log('üìä Total KB entries:', Object.keys(alertKnowledgeBase).length);\nconsole.log('üéØ Alert:', alertName || 'Not specified');\nconsole.log('üìÇ Category:', alertCategory);\nconsole.log('‚úÖ KB Match:', !!(alertName && alertKnowledgeBase[alertName]));\nconsole.log('üîç CSV Enhanced: YES');\nconsole.log('========================================');\n\n// KB Statistics by Category\nconst kbStats = {};\nObject.keys(alertKnowledgeBase).forEach(alertName => {\n  const entry = alertKnowledgeBase[alertName];\n  const severity = entry.severity || 'unknown';\n  if (!kbStats[severity]) {\n    kbStats[severity] = 0;\n  }\n  kbStats[severity]++;\n});\n\nconsole.log('üìà KB Statistics by Severity:');\nObject.entries(kbStats).forEach(([severity, count]) => {\n  console.log(`   ${severity.toUpperCase()}: ${count} alerts`);\n});\n\n// Add KB stats to output for monitoring\noutput._kbStats = {\n  totalEntries: Object.keys(alertKnowledgeBase).length,\n  severityBreakdown: kbStats,\n  csvEnhanced: true,\n  loadedAt: new Date().toISOString()\n};\n\nreturn [output];"
      },
      "id": "e32110ce-5067-4abb-aebf-1544ff54a3e5",
      "name": "Load Alert Knowledge Base",
      "type": "n8n-nodes-base.code",
      "position": [
        -3712,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "etiya-gpt-4o",
          "mode": "list",
          "cachedResultName": "etiya-gpt-4o"
        },
        "options": {
          "responseFormat": "json_object",
          "temperature": 0.3,
          "maxRetries": 2
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "typeVersion": 1.2,
      "position": [
        -304,
        736
      ],
      "id": "b0668c41-b7fb-46ae-93df-779b99a108db",
      "name": "OpenAI Chat Model1",
      "credentials": {
        "openAiApi": {
          "id": "rYdB8nNsS7m67tcr",
          "name": "OpenAi account 5"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Agent'tan gelen veriyi al\nconst items = $input.all();\n\n// D√∂n√º≈üt√ºr√ºlm√º≈ü sonu√ßlarƒ± tutacak array\nconst transformedItems = [];\n\nfor (const item of items) {\n  try {\n    // Agent'ƒ±n output'u string olarak geliyor, √∂nce parse edelim\n    let parsedData;\n    \n    if (typeof item.json.output === 'string') {\n      // String JSON'ƒ± parse et\n      parsedData = JSON.parse(item.json.output);\n    } else if (typeof item.json === 'string') {\n      // Bazen direkt item.json string olabilir\n      parsedData = JSON.parse(item.json);\n    } else {\n      // Zaten object ise\n      parsedData = item.json.output || item.json;\n    }\n    \n    // _context'i d√ºzelt - eƒüer string ise object'e √ßevir\n    if (typeof parsedData._context === 'string') {\n      parsedData._context = {\n        contextId: parsedData._context\n      };\n    } else if (!parsedData._context) {\n      parsedData._context = {};\n    }\n    \n    // Eksik alanlarƒ± kontrol et ve varsayƒ±lan deƒüerler ekle\n    if (!parsedData.execution_phases) {\n      parsedData.execution_phases = {\n        instant: { tools_used: [], findings: {} },\n        trend: { tools_used: [], findings: {} },\n        anomaly: { tools_used: [], findings: {} }\n      };\n    }\n    \n    if (!parsedData.correlation_matrix) {\n      parsedData.correlation_matrix = {\n        primary_chain: \"\",\n        affected_services: [],\n        blast_radius: \"\",\n        kubernetes_impact: {\n          evicted_pods: 0,\n          pending_pods: 0,\n          failed_schedules: 0\n        }\n      };\n    }\n    \n    if (!parsedData.root_cause) {\n      parsedData.root_cause = {\n        identified: false,\n        component: \"\",\n        issue: \"\",\n        evidence: [],\n        confidence: 0\n      };\n    }\n    \n    // Eksik boolean alanlarƒ± ekle\n    if (parsedData.proceed_to_stage3 === undefined) {\n      parsedData.proceed_to_stage3 = false;\n    }\n    \n    if (parsedData.alert_correlation_needed === undefined) {\n      parsedData.alert_correlation_needed = false;\n    }\n    \n    // _debug alanƒ±nƒ± kontrol et\n    if (!parsedData._debug) {\n      parsedData._debug = {\n        nodeType: \"Stage 2: Deep Analysis\",\n        processedAt: new Date().toISOString(),\n        contextId: parsedData._context.contextId || \"\",\n        contextPreserved: true,\n        receivedFromStage: \"\",\n        stageSequence: []\n      };\n    }\n    \n    // Sonucu eski formata uygun ≈üekilde wrap et\n    const transformedItem = {\n      json: {\n        output: parsedData\n      }\n    };\n    \n    transformedItems.push(transformedItem);\n    \n  } catch (error) {\n    // Hata durumunda orijinal veriyi d√∂nd√ºr ve hata mesajƒ± ekle\n    console.error('Parse error:', error.message);\n    transformedItems.push({\n      json: {\n        error: error.message,\n        originalData: item.json\n      }\n    });\n  }\n}\n\nreturn transformedItems;"
      },
      "id": "3a5e9f3a-4047-43fb-9cc7-dca644e3473a",
      "name": "Fix Stage2 Json",
      "type": "n8n-nodes-base.code",
      "position": [
        -1296,
        576
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Agent'tan gelen veriyi al\nconst items = $input.all();\n\n// D√∂n√º≈üt√ºr√ºlm√º≈ü sonu√ßlarƒ± tutacak array\nconst transformedItems = [];\n\nfor (const item of items) {\n  try {\n    let outputData;\n    \n    // Veriyi parse etmeye √ßalƒ±≈ü\n    if (typeof item.json.output === 'string') {\n      // String JSON ise parse et\n      outputData = JSON.parse(item.json.output);\n    } else if (item.json.output && typeof item.json.output === 'object') {\n      // Zaten object ise direkt kullan\n      outputData = item.json.output;\n    } else if (typeof item.json === 'string') {\n      // Bazen direkt item.json string olabilir\n      outputData = JSON.parse(item.json);\n    } else {\n      // Diƒüer durumlar i√ßin\n      outputData = item.json;\n    }\n    \n    // Eƒüer outputData hala output anahtarƒ± i√ßeriyorsa, onu √ßƒ±kar\n    if (outputData.output) {\n      outputData = outputData.output;\n    }\n    \n    // Stage 4 i√ßin gerekli alanlarƒ± kontrol et ve varsayƒ±lan deƒüerler ekle\n    if (!outputData.stage) {\n      outputData.stage = \"automated_diagnosis\";\n    }\n    \n    // diagnostics_executed kontrol√º\n    if (!outputData.diagnostics_executed) {\n      outputData.diagnostics_executed = [];\n    }\n    \n    // enriched_context kontrol√º\n    if (!outputData.enriched_context) {\n      outputData.enriched_context = {\n        deployment_info: {},\n        recent_changes: [],\n        dependencies: {\n          upstream: [],\n          downstream: [],\n          databases: [],\n          external: []\n        }\n      };\n    }\n    \n    // diagnostic_summary kontrol√º\n    if (!outputData.diagnostic_summary) {\n      outputData.diagnostic_summary = {\n        confirmed_issues: [],\n        secondary_issues: []\n      };\n    }\n    \n    // Boolean alanlarƒ± kontrol et\n    if (outputData.proceed_to_stage5 === undefined) {\n      outputData.proceed_to_stage5 = false;\n    }\n    \n    // remediation_confidence kontrol√º\n    if (outputData.remediation_confidence === undefined) {\n      outputData.remediation_confidence = 0;\n    }\n    \n    // _context kontrol√º ve d√ºzeltmesi\n    if (!outputData._context || typeof outputData._context === 'string') {\n      // Eƒüer string ise veya yoksa, bo≈ü object yap\n      outputData._context = {\n        contextId: typeof outputData._context === 'string' ? outputData._context : \"\",\n        createdAt: new Date().toISOString()\n      };\n    }\n    \n    // Circular reference'larƒ± temizle\n    if (outputData._context && outputData._context === \"[Circular Reference]\") {\n      outputData._context = {};\n    }\n    \n    // stageResults i√ßindeki circular reference'larƒ± temizle\n    if (outputData._context && outputData._context.stageResults) {\n      cleanCircularReferences(outputData._context.stageResults);\n    }\n    \n    // _debug alanƒ±nƒ± kontrol et\n    if (!outputData._debug) {\n      outputData._debug = {\n        nodeType: \"Stage 4: Automated Diagnosis\",\n        processedAt: new Date().toISOString(),\n        contextId: outputData._context.contextId || \"\",\n        contextPreserved: true\n      };\n    }\n    \n    // Sonucu format et\n    const transformedItem = {\n      json: {\n        output: outputData\n      }\n    };\n    \n    transformedItems.push(transformedItem);\n    \n  } catch (error) {\n    // Hata durumunda log ve orijinal veriyi d√∂nd√ºr\n    console.error('Parse error:', error.message);\n    transformedItems.push({\n      json: {\n        error: error.message,\n        originalData: item.json\n      }\n    });\n  }\n}\n\n// Circular reference temizleme fonksiyonu\nfunction cleanCircularReferences(obj) {\n  if (!obj || typeof obj !== 'object') return;\n  \n  for (const key in obj) {\n    if (obj[key] === \"[Circular Reference]\") {\n      delete obj[key];\n    } else if (typeof obj[key] === 'object') {\n      cleanCircularReferences(obj[key]);\n    }\n  }\n}\n\nreturn transformedItems;"
      },
      "id": "46e4d0af-d180-46f3-8c5a-126af834a1e1",
      "name": "Fix Stage 4 Json",
      "type": "n8n-nodes-base.code",
      "position": [
        16,
        704
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Fix Stage 3 Agent Output - Parser Replacement\n// Agent'ƒ±n √ßƒ±ktƒ±sƒ±nƒ± parser schema'sƒ±na uygun formata d√∂n√º≈üt√ºr√ºr\n\nconst items = $input.all();\nconst fixedItems = [];\n\nfor (const item of items) {\n  try {\n    // Agent output'u al\n    let agentOutput;\n    \n    // Farklƒ± output formatlarƒ±nƒ± handle et\n    if (typeof item.json === 'string') {\n      // String JSON ise parse et\n      agentOutput = JSON.parse(item.json);\n    } else if (item.json.output) {\n      // Output wrapper varsa\n      if (typeof item.json.output === 'string') {\n        agentOutput = JSON.parse(item.json.output);\n      } else {\n        agentOutput = item.json.output;\n      }\n    } else {\n      // Direkt obje\n      agentOutput = item.json;\n    }\n    \n    // Helper function - Safe value getter\n    const safeGet = (obj, path, defaultValue) => {\n      const keys = path.split('.');\n      let result = obj;\n      for (const key of keys) {\n        if (result && typeof result === 'object' && key in result) {\n          result = result[key];\n        } else {\n          return defaultValue;\n        }\n      }\n      return result ?? defaultValue;\n    };\n    \n    // Helper function - Ensure array\n    const ensureArray = (value) => {\n      if (Array.isArray(value)) return value;\n      if (value && typeof value === 'object') return [value];\n      return [];\n    };\n    \n    // Helper function - Ensure valid number\n    const ensureNumber = (value, defaultValue = 0) => {\n      const num = parseFloat(value);\n      return isNaN(num) ? defaultValue : num;\n    };\n    \n    // Helper function - Ensure valid string\n    const ensureString = (value, defaultValue = '') => {\n      if (value === null || value === undefined) return defaultValue;\n      return String(value);\n    };\n    \n    // Helper function - Ensure valid boolean\n    const ensureBoolean = (value, defaultValue = false) => {\n      if (typeof value === 'boolean') return value;\n      if (value === 'true') return true;\n      if (value === 'false') return false;\n      return defaultValue;\n    };\n    \n    // Fix active_alerts\n    let activeAlerts = ensureArray(agentOutput.active_alerts);\n    activeAlerts = activeAlerts.map(alert => ({\n      name: ensureString(alert.name || alert.alertname, 'Unknown Alert'),\n      severity: ensureString(alert.severity, 'unknown'),\n      count: ensureNumber(alert.count, 0),\n      duration: ensureString(alert.duration, 'unknown'),\n      labels: (alert.labels && typeof alert.labels === 'object') ? alert.labels : {},\n      annotations: (alert.annotations && typeof alert.annotations === 'object') ? alert.annotations : {}\n    }));\n    \n    // Fix alert_groups\n    let alertGroups = ensureArray(agentOutput.alert_groups);\n    alertGroups = alertGroups.map(group => ({\n      root_alert: ensureString(group.root_alert, 'none'),\n      related_alerts: ensureArray(group.related_alerts).map(a => ensureString(a)),\n      correlation_score: ensureNumber(group.correlation_score, 0),\n      shared_labels: (group.shared_labels && typeof group.shared_labels === 'object') ? group.shared_labels : {}\n    }));\n    \n    // Fix knowledge_base_matches\n    let kbMatches = ensureArray(agentOutput.knowledge_base_matches);\n    kbMatches = kbMatches.map(match => ({\n      alert: ensureString(match.alert, 'none'),\n      kb_entry: (match.kb_entry && typeof match.kb_entry === 'object') ? {\n        root_causes: ensureArray(match.kb_entry.root_causes).map(c => ensureString(c)),\n        diagnostic_commands: ensureArray(match.kb_entry.diagnostic_commands).map(c => ensureString(c)),\n        immediate_actions: ensureArray(match.kb_entry.immediate_actions).map(a => ensureString(a)),\n        long_term_solutions: ensureArray(match.kb_entry.long_term_solutions).map(s => ensureString(s))\n      } : {},\n      applicability_score: ensureNumber(match.applicability_score, 0)\n    }));\n    \n    // Fix alert_patterns\n    let alertPatterns = agentOutput.alert_patterns || {};\n    alertPatterns = {\n      recurring: ensureArray(alertPatterns.recurring),\n      storm_detection: {\n        detected: ensureBoolean(alertPatterns.storm_detection?.detected, false),\n        alert_count: ensureNumber(alertPatterns.storm_detection?.alert_count, 0),\n        time_window: ensureString(alertPatterns.storm_detection?.time_window, '5m'),\n        likely_root: alertPatterns.storm_detection?.likely_root || null\n      }\n    };\n    \n    // Fix slo_impact\n    let sloImpact = agentOutput.slo_impact || {};\n    let availabilitySlo = sloImpact.availability_slo || {};\n    \n    // SLO status validation\n    const validStatuses = ['green', 'yellow', 'red', 'unknown'];\n    let sloStatus = ensureString(availabilitySlo.status, 'green').toLowerCase();\n    if (!validStatuses.includes(sloStatus)) {\n      sloStatus = 'unknown';\n    }\n    \n    // Fix NaN and invalid percentages\n    const fixPercentage = (value, defaultValue = '100%') => {\n      const str = ensureString(value, defaultValue);\n      if (str === 'NaN%' || str === 'null%' || str === 'undefined%') {\n        return defaultValue;\n      }\n      // Ensure it ends with %\n      if (!str.endsWith('%')) {\n        const num = parseFloat(str);\n        if (!isNaN(num)) {\n          return `${num}%`;\n        }\n      }\n      return str || defaultValue;\n    };\n    \n    sloImpact = {\n      availability_slo: {\n        target: fixPercentage(availabilitySlo.target, '99.9%'),\n        current: fixPercentage(availabilitySlo.current, '100%'),\n        error_budget_used: fixPercentage(availabilitySlo.error_budget_used, '0%'),\n        time_remaining: ensureString(availabilitySlo.time_remaining, '30d'),\n        status: sloStatus,\n        components: {\n          deployment_health: fixPercentage(availabilitySlo.components?.deployment_health, '100%')\n        }\n      },\n      affected_slis: ensureArray(sloImpact.affected_slis).map(s => ensureString(s))\n    };\n    \n    // Fix recommended_alert_actions\n    let recommendedActions = ensureArray(agentOutput.recommended_alert_actions);\n    recommendedActions = recommendedActions.map(action => ({\n      alert: ensureString(action.alert, 'none'),\n      action: ensureString(action.action, 'Monitor'),\n      confidence: ensureNumber(action.confidence, 0),\n      risk: ensureString(action.risk, 'medium'),\n      command: action.command || null\n    }));\n    \n    // Fix booleans\n    const proceedToStage4 = ensureBoolean(agentOutput.proceed_to_stage4, activeAlerts.length > 0);\n    const autoRemediationApproved = ensureBoolean(agentOutput.auto_remediation_approved, false);\n    \n    // Fix _context\n    let context = agentOutput._context || {};\n    if (typeof context === 'string') {\n      try {\n        context = JSON.parse(context);\n      } catch (e) {\n        context = {};\n      }\n    }\n    \n    // Fix _debug\n    let debug = agentOutput._debug || {};\n    if (!debug.nodeType) {\n      debug.nodeType = 'Stage 3: Alert Intelligence';\n    }\n    if (!debug.processedAt) {\n      debug.processedAt = new Date().toISOString();\n    }\n    if (!debug.toolCallCount && typeof debug.toolCallCount !== 'number') {\n      debug.toolCallCount = 0;\n    }\n    if (!debug.alertHistoryCallCount && typeof debug.alertHistoryCallCount !== 'number') {\n      debug.alertHistoryCallCount = 0;\n    }\n    \n    // Build fixed output\n    const fixedOutput = {\n      stage: ensureString(agentOutput.stage, 'alert_intelligence'),\n      active_alerts: activeAlerts,\n      alert_groups: alertGroups,\n      knowledge_base_matches: kbMatches,\n      alert_patterns: alertPatterns,\n      slo_impact: sloImpact,\n      recommended_alert_actions: recommendedActions,\n      proceed_to_stage4: proceedToStage4,\n      auto_remediation_approved: autoRemediationApproved,\n      _context: context,\n      _debug: debug\n    };\n    \n    // Wrap in expected format\n    fixedItems.push({\n      json: {\n        output: fixedOutput\n      }\n    });\n    \n    // Log success\n    console.log('‚úÖ Stage 3 output successfully fixed');\n    console.log('- Active alerts:', activeAlerts.length);\n    console.log('- Alert groups:', alertGroups.length);\n    console.log('- KB matches:', kbMatches.length);\n    console.log('- SLO status:', sloImpact.availability_slo.status);\n    console.log('- Proceed to Stage 4:', proceedToStage4);\n    \n  } catch (error) {\n    console.error('‚ùå Error fixing Stage 3 output:', error.message);\n    \n    // Return a valid default structure on error\n    fixedItems.push({\n      json: {\n        output: {\n          stage: 'alert_intelligence',\n          active_alerts: [],\n          alert_groups: [],\n          knowledge_base_matches: [],\n          alert_patterns: {\n            recurring: [],\n            storm_detection: {\n              detected: false,\n              alert_count: 0,\n              time_window: '5m',\n              likely_root: null\n            }\n          },\n          slo_impact: {\n            availability_slo: {\n              target: '99.9%',\n              current: '100%',\n              error_budget_used: '0%',\n              time_remaining: '30d',\n              status: 'green',\n              components: {\n                deployment_health: '100%'\n              }\n            },\n            affected_slis: []\n          },\n          recommended_alert_actions: [],\n          proceed_to_stage4: false,\n          auto_remediation_approved: false,\n          _context: {},\n          _debug: {\n            nodeType: 'Stage 3: Alert Intelligence',\n            processedAt: new Date().toISOString(),\n            error: error.message,\n            originalData: item.json\n          }\n        }\n      }\n    });\n  }\n}\n\nreturn fixedItems;"
      },
      "id": "f3d32b46-fe89-4363-b9bb-24541406b60c",
      "name": "Stage 3 Formater",
      "type": "n8n-nodes-base.code",
      "position": [
        -592,
        544
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// ================ KB-ENHANCED FIX STAGE 3 CONTEXT ================\n// This file preserves ALL original 871 lines and ADDS KB enhancements\n// Version: KB-Enhanced-Full-v1.0\n// Enhancement Date: 2025-01-28\n// Original functionality: 100% preserved\n// KB Enhancement: ADDED (not replaced)\n\n// ============= KB NODE CONNECTIONS (NEW) =============\n// Get KB data from workflow nodes (safely with error handling)\nlet alertCategoriesMapper = {};\nlet loadAlertKB = {};\nlet categoryMetricsBuilder = {};\n\ntry {\n  alertCategoriesMapper = $node[\"Alert Categories Mapper\"]?.json || {};\n} catch(e) {\n  console.log(\"Alert Categories Mapper node not available yet\");\n}\n\ntry {\n  loadAlertKB = $node[\"Load Alert Knowledge Base\"]?.json || {};\n} catch(e) {\n  console.log(\"Load Alert Knowledge Base node not available yet\");\n}\n\ntry {\n  categoryMetricsBuilder = $node[\"Category Based Metrics Builder\"]?.json || {};\n} catch(e) {\n  console.log(\"Category Based Metrics Builder node not available yet\");\n}\n\n// Helper function to derive urgency level from severity score\nfunction deriveUrgencyLevel(severityScore) {\n  if (severityScore >= 100) return 'BLOCKER';\n  if (severityScore >= 90) return 'CRITICAL';\n  if (severityScore >= 70) return 'HIGH';\n  if (severityScore >= 50) return 'MEDIUM';\n  return 'LOW';\n}\n\n// Extract KB information safely (FIXED FIELD PATHS WITH DEBUG)\nconsole.log(\"===== DEBUG KB NODE DATA =====\");\nconsole.log(\"alertCategoriesMapper keys:\", Object.keys(alertCategoriesMapper));\nconsole.log(\"loadAlertKB keys:\", Object.keys(loadAlertKB));\nconsole.log(\"calculatedSeverityScore:\", alertCategoriesMapper.calculatedSeverityScore);\nconsole.log(\"categoryHandlingHints:\", alertCategoriesMapper.categoryHandlingHints);\n\nconst kbAlertCategory = alertCategoriesMapper.alertCategory || 'UNKNOWN';\nconst severityScore = alertCategoriesMapper?.calculatedSeverityScore || \n                     alertCategoriesMapper?.severityScore || 0;\nconst kbUrgencyLevel = deriveUrgencyLevel(severityScore);\nconst kbCascadeRisk = alertCategoriesMapper.categoryHandlingHints?.cascadeRisk || 'UNKNOWN';\n\n// Try multiple paths for KB data\nconst kbAlertKnowledgeBase = loadAlertKB.knowledgeBase?.alert || \n                             loadAlertKB.alert ||\n                             loadAlertKB.knowledgeBase ||\n                             {};\n\nconsole.log(\"Extracted KB Values:\");\nconsole.log(\"- Category:\", kbAlertCategory);\nconsole.log(\"- Severity Score:\", severityScore);  \nconsole.log(\"- Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"- Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"- KB Data Keys:\", Object.keys(kbAlertKnowledgeBase));\nconst kbEnhancedStats = {\n  totalCategories: alertCategoriesMapper._categoryStats?.totalAlerts || 0,\n  totalMappings: Object.keys(alertCategoriesMapper._categoryStats?.categoryBreakdown || {}).length || 0,\n  kbEntriesLoaded: Object.keys(kbAlertKnowledgeBase).length || 0\n};\n\nconsole.log(\"===== STAGE 3 KB ENHANCEMENT LOADED =====\");\nconsole.log(\"Alert Category:\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Entries Available:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"==========================================\");\n\n// Fix Stage 3 Context - EXTENDED Alert Correlation for 150+ Alert Types\n// PRESERVES all existing logic, ADDS category-based correlation patterns\n\nconst stage3Output = $input.first().json;\n\n// Stage 2'den gelen context ve data'yƒ± al\nconst stage2Data = $node[\"Fix Stage 2 Context\"].json;\nconst previousContext = stage2Data._context;\n\n// Alert category ve KB bilgilerini al\nconst alertCategory = stage2Data.alertInfo?.category || stage2Data.alert_category || 'UNKNOWN';\nconst alertName = stage2Data.alertInfo?.alertName || previousContext?.alertContext?.alertName || 'unknown';\nconst rootCause = stage2Data.stage2Data?.root_cause || {};\nconst cascadingEffects = stage2Data.stage2Data?.cascading_effects || {};\n\nconsole.log(\"=== FIXING STAGE 3 CONTEXT - EXTENDED ===\");\nconsole.log(\"Alert:\", alertName);\nconsole.log(\"Category:\", alertCategory);\nconsole.log(\"Root Cause:\", rootCause.identified ? rootCause.issue : 'Not identified');\nconsole.log(\"Previous context ID:\", previousContext?.contextId);\n\n// Deep copy\nlet fixedOutput = JSON.parse(JSON.stringify(stage3Output));\n\n// Output wrapper kontrol√º\nconst hasOutputWrapper = !!fixedOutput.output;\nconst actualOutput = hasOutputWrapper ? fixedOutput.output : fixedOutput;\n\nconsole.log(\"Has output wrapper:\", hasOutputWrapper);\n\n// ============= SLO DEƒûERLERƒ∞Nƒ∞ D√úZELT =============\nif (actualOutput.slo_impact) {\n  if (actualOutput.slo_impact.availability_slo) {\n    const slo = actualOutput.slo_impact.availability_slo;\n    \n    if (!slo.current || slo.current === \"NaN%\" || slo.current === \"null%\" || slo.current === \"undefined%\") {\n      slo.current = \"100%\";\n    }\n    \n    if (!slo.error_budget_used || slo.error_budget_used === \"NaN%\" || slo.error_budget_used === \"null%\") {\n      slo.error_budget_used = \"0%\";\n    }\n    \n    if (!slo.time_remaining || slo.time_remaining === \"null\" || slo.time_remaining === \"undefined\") {\n      slo.time_remaining = \"30d\";\n    }\n    \n    if (!slo.status || ![\"green\", \"yellow\", \"red\"].includes(slo.status)) {\n      const currentValue = parseFloat(slo.current);\n      if (currentValue >= 99.9) {\n        slo.status = \"green\";\n      } else if (currentValue >= 99.0) {\n        slo.status = \"yellow\";\n      } else {\n        slo.status = \"red\";\n      }\n    }\n    \n    if (!slo.components) {\n      slo.components = { deployment_health: \"100%\" };\n    }\n  }\n  \n  if (!Array.isArray(actualOutput.slo_impact.affected_slis)) {\n    actualOutput.slo_impact.affected_slis = [];\n  }\n}\n\n// ============= EXTENDED ALERT KB ENRICHMENT =============\nlet alertKB = [];\nlet severityScores = {\n  \"Blocker\": 100,\n  \"Critical\": 80,\n  \"High\": 60,\n  \"Medium\": 40,\n  \"Low\": 20\n};\n\n// Category-based severity adjustment\nconst CATEGORY_SEVERITY_MULTIPLIERS = {\n  'ETCD': 2.0,\n  'INFRASTRUCTURE': 1.5,\n  'CERTIFICATE': 1.6,\n  'NETWORK': 1.4,\n  'CLUSTER': 1.3,\n  'RESOURCE': 1.2,\n  'WORKLOAD': 1.1,\n  'POD': 1.0,\n  'APPLICATION': 0.9,\n  'MONITORING': 0.8,\n  'UNKNOWN': 1.0\n};\n\n// Load Alert Knowledge Base if available\ntry {\n  const alertKBNode = $node[\"Load Alert Knowledge Base\"];\n  if (alertKBNode?.json?._alertKBData) {\n    alertKB = alertKBNode.json._alertKBData;\n    if (alertKBNode.json._severityScores) {\n      severityScores = alertKBNode.json._severityScores;\n    }\n    console.log(\"Alert KB loaded:\", alertKB.length, \"entries\");\n  }\n} catch (e) {\n  console.log(\"Alert KB not available, using empty KB\");\n}\n\n// ============= CATEGORY-BASED CORRELATION PATTERNS =============\nconst CATEGORY_CORRELATION_PATTERNS = {\n  'INFRASTRUCTURE': {\n    correlatedCategories: ['POD', 'WORKLOAD', 'RESOURCE'],\n    patterns: [\n      {\n        name: 'node_failure_cascade',\n        triggers: ['KubeNodeNotReady', 'KubeNodeUnreachable'],\n        effects: ['KubePodEvicted', 'KubePodPending', 'KubeDeploymentReplicasMismatch'],\n        confidence: 0.9\n      },\n      {\n        name: 'node_pressure_cascade',\n        triggers: ['KubeNodeMemoryPressure', 'KubeNodeDiskPressure'],\n        effects: ['KubePodEvicted', 'KubeContainerOOMKilled'],\n        confidence: 0.85\n      }\n    ]\n  },\n  'POD': {\n    correlatedCategories: ['WORKLOAD', 'APPLICATION'],\n    patterns: [\n      {\n        name: 'pod_crash_service_impact',\n        triggers: ['KubePodCrashLooping', 'KubePodOOMKilled'],\n        effects: ['ServiceDown', 'EndpointNotReady'],\n        confidence: 0.8\n      }\n    ]\n  },\n  'WORKLOAD': {\n    correlatedCategories: ['POD', 'RESOURCE'],\n    patterns: [\n      {\n        name: 'deployment_failure_cascade',\n        triggers: ['KubeDeploymentReplicasMismatch'],\n        effects: ['KubePodPending', 'KubeHpaMaxedOut'],\n        confidence: 0.85\n      }\n    ]\n  },\n  'RESOURCE': {\n    correlatedCategories: ['POD', 'WORKLOAD'],\n    patterns: [\n      {\n        name: 'resource_exhaustion_cascade',\n        triggers: ['KubePersistentVolumeFillingUp', 'KubeQuotaExceeded'],\n        effects: ['KubePodEvicted', 'KubeDeploymentReplicasMismatch'],\n        confidence: 0.8\n      }\n    ]\n  },\n  'NETWORK': {\n    correlatedCategories: ['APPLICATION', 'CLUSTER'],\n    patterns: [\n      {\n        name: 'network_failure_cascade',\n        triggers: ['TargetDown', 'NetworkReceiveErrors'],\n        effects: ['ServiceUnavailable', 'EndpointNotReady'],\n        confidence: 0.85\n      }\n    ]\n  },\n  'ETCD': {\n    correlatedCategories: ['CLUSTER', 'INFRASTRUCTURE'],\n    patterns: [\n      {\n        name: 'etcd_failure_cascade',\n        triggers: ['etcdNoLeader', 'etcdInsufficientMembers'],\n        effects: ['KubeAPIDown', 'KubeControllerManagerDown', 'KubeSchedulerDown'],\n        confidence: 0.95\n      }\n    ]\n  },\n  'CERTIFICATE': {\n    correlatedCategories: ['CLUSTER', 'POD'],\n    patterns: [\n      {\n        name: 'cert_expiry_cascade',\n        triggers: ['KubeletClientCertificateExpiration'],\n        effects: ['KubeletDown', 'KubePodEvicted'],\n        confidence: 0.9\n      }\n    ]\n  },\n  'CLUSTER': {\n    correlatedCategories: ['INFRASTRUCTURE', 'WORKLOAD', 'POD'],\n    patterns: [\n      {\n        name: 'control_plane_cascade',\n        triggers: ['KubeAPIDown', 'KubeSchedulerDown'],\n        effects: ['KubeDeploymentReplicasMismatch', 'KubePodPending'],\n        confidence: 0.9\n      }\n    ]\n  },\n  'MONITORING': {\n    correlatedCategories: [],\n    patterns: []\n  },\n  'APPLICATION': {\n    correlatedCategories: ['POD', 'NETWORK'],\n    patterns: [\n      {\n        name: 'app_failure_cascade',\n        triggers: ['AppHighErrorRate', 'AppHighLatency'],\n        effects: ['ServiceDegraded', 'SLOViolation'],\n        confidence: 0.75\n      }\n    ]\n  },\n  'UNKNOWN': {\n    correlatedCategories: [],\n    patterns: []\n  }\n};\n\n// Helper functions\nfunction enrichAlertWithKB(alert, alertKB) {\n  // First try the new KB structure from KB nodes (FIXED)\n  let kbEntry = null;\n  if (kbAlertKnowledgeBase && Object.keys(kbAlertKnowledgeBase).length > 0) {\n    // For KubePodCrashLooping, the KB entry is directly in kbAlertKnowledgeBase\n    if (alert.name === loadAlertKB.knowledgeBase?.alertName) {\n      kbEntry = kbAlertKnowledgeBase;\n    }\n  }\n  \n  // Fallback to the original alertKB array format\n  if (!kbEntry && alertKB && Array.isArray(alertKB)) {\n    kbEntry = alertKB.find(kb => {\n      if (kb.alertName === alert.name) return true;\n      if (alert.name && kb.alertName && alert.name.includes(kb.alertName)) return true;\n      if (alert.name && kb.alertName && kb.alertName.includes(alert.name)) return true;\n      return false;\n    });\n  }\n  \n  if (kbEntry) {\n    return {\n      ...alert,\n      kb_enriched: true,\n      kb_severity: kbEntry.severity,\n      kb_description: kbEntry.description,\n      // Support both old and new KB structure\n      kb_root_causes: kbEntry.rootCauses || kbEntry.commonCauses,\n      kb_diagnostic_commands: kbEntry.diagnosticCommands || kbEntry.troubleshootingSteps,\n      kb_immediate_actions: kbEntry.immediateActions,\n      kb_long_term_solutions: kbEntry.longTermSolutions,\n      kb_expected_results: kbEntry.expectedResults,\n      kb_enhanced_version: \"KB-Enhanced-Full-v1.0\",\n      severity_score: severityScores[kbEntry.severity] || 50,\n      severity: alert.severity || kbEntry.severity\n    };\n  }\n  \n  return {\n    ...alert,\n    kb_enriched: false,\n    severity_score: severityScores[alert.severity] || 30\n  };\n}\n\nfunction calculateServiceImpact(alertName, severity, category) {\n  let impactMultiplier = CATEGORY_SEVERITY_MULTIPLIERS[category] || 1.0;\n  \n  // Additional multipliers for specific alerts\n  if (alertName.includes('etcd')) {\n    impactMultiplier *= 2.0;\n  } else if (alertName.includes('KubeAPI') || alertName.includes('APIServer')) {\n    impactMultiplier *= 1.5;\n  } else if (alertName.includes('KubeController') || alertName.includes('KubeScheduler')) {\n    impactMultiplier *= 1.4;\n  } else if (alertName.includes('Node')) {\n    impactMultiplier *= 1.3;\n  } else if (alertName.includes('Pod') || alertName.includes('Container')) {\n    impactMultiplier *= 0.8;\n  }\n  \n  const baseScore = severityScores[severity] || 50;\n  return Math.round(baseScore * impactMultiplier);\n}\n\n// ============= CORRELATION ANALYSIS =============\nfunction findCorrelatedAlerts(primaryAlert, allAlerts, category) {\n  const correlationPattern = CATEGORY_CORRELATION_PATTERNS[category];\n  const correlatedAlerts = [];\n  \n  if (!correlationPattern) return correlatedAlerts;\n  \n  // Find alerts that match correlation patterns\n  correlationPattern.patterns.forEach(pattern => {\n    if (pattern.triggers.includes(primaryAlert)) {\n      // Look for effect alerts\n      allAlerts.forEach(alert => {\n        if (pattern.effects.some(effect => alert.name.includes(effect))) {\n          correlatedAlerts.push({\n            alert: alert.name,\n            correlation_type: pattern.name,\n            confidence: pattern.confidence,\n            relationship: 'effect'\n          });\n        }\n      });\n    }\n    \n    // Check if this alert is an effect of another trigger\n    if (pattern.effects.includes(primaryAlert)) {\n      allAlerts.forEach(alert => {\n        if (pattern.triggers.some(trigger => alert.name.includes(trigger))) {\n          correlatedAlerts.push({\n            alert: alert.name,\n            correlation_type: pattern.name,\n            confidence: pattern.confidence,\n            relationship: 'trigger'\n          });\n        }\n      });\n    }\n  });\n  \n  // Check correlated categories\n  if (correlationPattern.correlatedCategories.length > 0) {\n    allAlerts.forEach(alert => {\n      const alertCat = getAlertCategory(alert.name);\n      if (correlationPattern.correlatedCategories.includes(alertCat)) {\n        // Time-based correlation (alerts within 5 minutes)\n        correlatedAlerts.push({\n          alert: alert.name,\n          correlation_type: 'category_correlation',\n          confidence: 0.6,\n          relationship: 'related_category'\n        });\n      }\n    });\n  }\n  \n  return correlatedAlerts;\n}\n\nfunction getAlertCategory(alertName) {\n  // This should match the ALERT_CATEGORIES from Alert Categories Mapper\n  const categoryMappings = {\n    'Node': 'INFRASTRUCTURE',\n    'Pod': 'POD',\n    'Deployment': 'WORKLOAD',\n    'PersistentVolume': 'RESOURCE',\n    'etcd': 'ETCD',\n    'Certificate': 'CERTIFICATE',\n    'API': 'CLUSTER',\n    'Prometheus': 'MONITORING',\n    'App': 'APPLICATION'\n  };\n  \n  for (const [key, category] of Object.entries(categoryMappings)) {\n    if (alertName.includes(key)) {\n      return category;\n    }\n  }\n  return 'UNKNOWN';\n}\n\n// Process alerts\nif (!Array.isArray(actualOutput.active_alerts)) {\n  actualOutput.active_alerts = [];\n} else {\n  actualOutput.active_alerts = actualOutput.active_alerts.map(alert => {\n    const validatedAlert = {\n      name: alert.name || \"Unknown Alert\",\n      severity: alert.severity || \"unknown\",\n      count: typeof alert.count === 'number' ? alert.count : 0,\n      duration: alert.duration || \"unknown\",\n      labels: alert.labels || {},\n      annotations: alert.annotations || {},\n      category: getAlertCategory(alert.name)\n    };\n    \n    const enrichedAlert = enrichAlertWithKB(validatedAlert, alertKB);\n    enrichedAlert.impact_score = calculateServiceImpact(\n      enrichedAlert.name, \n      enrichedAlert.kb_severity || enrichedAlert.severity,\n      enrichedAlert.category\n    );\n    \n    // Add correlation information\n    enrichedAlert.correlations = findCorrelatedAlerts(\n      enrichedAlert.name,\n      actualOutput.active_alerts,\n      enrichedAlert.category\n    );\n    \n    return enrichedAlert;\n  });\n  \n  actualOutput.active_alerts.sort((a, b) => b.impact_score - a.impact_score);\n}\n\n// ============= ALERT GROUPS ENHANCEMENT =============\nif (!Array.isArray(actualOutput.alert_groups)) {\n  actualOutput.alert_groups = [];\n}\n\n// Create category-based alert groups\nconst alertsByCategory = {};\nactualOutput.active_alerts.forEach(alert => {\n  const cat = alert.category || 'UNKNOWN';\n  if (!alertsByCategory[cat]) {\n    alertsByCategory[cat] = [];\n  }\n  alertsByCategory[cat].push(alert);\n});\n\n// Generate alert groups based on categories and correlations\nObject.entries(alertsByCategory).forEach(([category, alerts]) => {\n  if (alerts.length > 1) {\n    // Find the highest impact alert as root\n    const rootAlert = alerts.reduce((max, alert) => \n      alert.impact_score > max.impact_score ? alert : max\n    );\n    \n    const group = {\n      root_alert: rootAlert.name,\n      related_alerts: alerts.filter(a => a.name !== rootAlert.name).map(a => a.name),\n      correlation_score: 0.7, // Base score for same category\n      category: category,\n      shared_labels: findSharedLabels(alerts),\n      impact_analysis: {\n        total_impact: alerts.reduce((sum, a) => sum + a.impact_score, 0),\n        max_severity: Math.max(...alerts.map(a => a.severity_score || 0)),\n        cascade_risk: CATEGORY_SEVERITY_MULTIPLIERS[category] || 1.0\n      }\n    };\n    \n    // Increase correlation score if there are pattern matches\n    if (rootAlert.correlations && rootAlert.correlations.length > 0) {\n      group.correlation_score = Math.min(0.95, group.correlation_score + 0.2);\n      group.correlation_patterns = rootAlert.correlations.map(c => c.correlation_type);\n    }\n    \n    actualOutput.alert_groups.push(group);\n  }\n});\n\n// Add cross-category correlations based on root cause\nif (rootCause.identified && rootCause.component) {\n  const rootCauseGroup = {\n    root_alert: alertName,\n    related_alerts: actualOutput.active_alerts\n      .filter(a => a.name !== alertName)\n      .filter(a => {\n        // Check if alert is related to the root cause component\n        return a.labels?.pod === rootCause.component ||\n               a.labels?.deployment === rootCause.component ||\n               a.labels?.node === rootCause.component;\n      })\n      .map(a => a.name),\n    correlation_score: 0.85,\n    category: 'ROOT_CAUSE_CORRELATION',\n    shared_labels: { component: rootCause.component },\n    root_cause_based: true\n  };\n  \n  if (rootCauseGroup.related_alerts.length > 0) {\n    actualOutput.alert_groups.push(rootCauseGroup);\n  }\n}\n\n// Helper function to find shared labels\nfunction findSharedLabels(alerts) {\n  if (alerts.length === 0) return {};\n  \n  const firstAlert = alerts[0];\n  const sharedLabels = {};\n  \n  Object.keys(firstAlert.labels || {}).forEach(key => {\n    const value = firstAlert.labels[key];\n    if (alerts.every(a => a.labels?.[key] === value)) {\n      sharedLabels[key] = value;\n    }\n  });\n  \n  return sharedLabels;\n}\n\n// ============= STORM DETECTION ENHANCEMENT =============\nconst alertStorm = {\n  detected: false,\n  alert_count: actualOutput.active_alerts.length,\n  time_window: '5m',\n  likely_root: null,\n  storm_category: null\n};\n\n// Category-based storm detection thresholds\nconst STORM_THRESHOLDS = {\n  'INFRASTRUCTURE': 3,\n  'POD': 10,\n  'WORKLOAD': 5,\n  'RESOURCE': 5,\n  'NETWORK': 3,\n  'ETCD': 2,\n  'CERTIFICATE': 2,\n  'CLUSTER': 3,\n  'MONITORING': 10,\n  'APPLICATION': 8,\n  'UNKNOWN': 15\n};\n\n// Check for alert storm by category\nObject.entries(alertsByCategory).forEach(([category, alerts]) => {\n  const threshold = STORM_THRESHOLDS[category] || 10;\n  if (alerts.length >= threshold) {\n    alertStorm.detected = true;\n    alertStorm.storm_category = category;\n    // Find likely root based on highest impact\n    alertStorm.likely_root = alerts.reduce((max, alert) => \n      alert.impact_score > max.impact_score ? alert : max\n    ).name;\n  }\n});\n\n// Also check total alert count\nif (actualOutput.active_alerts.length > 20) {\n  alertStorm.detected = true;\n  if (!alertStorm.likely_root) {\n    alertStorm.likely_root = actualOutput.active_alerts[0]?.name || 'unknown';\n  }\n}\n\nactualOutput.alert_patterns = {\n  recurring: actualOutput.alert_patterns?.recurring || [],\n  storm_detection: alertStorm,\n  category_distribution: Object.entries(alertsByCategory).map(([cat, alerts]) => ({\n    category: cat,\n    count: alerts.length,\n    percentage: ((alerts.length / actualOutput.active_alerts.length) * 100).toFixed(1)\n  }))\n};\n\n// ============= KNOWLEDGE BASE MATCHES =============\nactualOutput.knowledge_base_matches = actualOutput.active_alerts\n  .filter(alert => alert.kb_enriched)\n  .map(alert => ({\n    alert: alert.name,\n    kb_entry: {\n      severity: alert.kb_severity,\n      description: alert.kb_description,\n      root_causes: alert.kb_root_causes || [],\n      diagnostic_commands: alert.kb_diagnostic_commands || [],\n      immediate_actions: alert.kb_immediate_actions || [],\n      long_term_solutions: alert.kb_long_term_solutions || []\n    },\n    applicability_score: 0.9,\n    impact_score: alert.impact_score,\n    category: alert.category\n  }));\n\n// ============= RECOMMENDED ACTIONS ENHANCEMENT =============\nif (!Array.isArray(actualOutput.recommended_alert_actions)) {\n  actualOutput.recommended_alert_actions = [];\n}\n\n// Generate category-specific recommendations\nactualOutput.active_alerts.forEach(alert => {\n  const recommendation = {\n    alert: alert.name,\n    action: getRecommendedAction(alert, rootCause),\n    confidence: calculateActionConfidence(alert, rootCause),\n    risk: calculateActionRisk(alert.category),\n    command: generateActionCommand(alert, previousContext),\n    category: alert.category,\n    priority: alert.impact_score\n  };\n  \n  actualOutput.recommended_alert_actions.push(recommendation);\n});\n\n// Sort by priority (impact score)\nactualOutput.recommended_alert_actions.sort((a, b) => b.priority - a.priority);\n\n// Helper functions for recommendations\nfunction getRecommendedAction(alert, rootCause) {\n  if (rootCause.identified && alert.name === alertName) {\n    return `Address root cause: ${rootCause.issue}`;\n  }\n  \n  const categoryActions = {\n    'INFRASTRUCTURE': 'Cordon node and migrate workloads',\n    'POD': 'Restart pod and check resource limits',\n    'WORKLOAD': 'Scale deployment and check HPA settings',\n    'RESOURCE': 'Clean up resources or increase quotas',\n    'NETWORK': 'Check network connectivity and endpoints',\n    'ETCD': 'CRITICAL: Restore ETCD quorum immediately',\n    'CERTIFICATE': 'Rotate certificates immediately',\n    'CLUSTER': 'Check control plane components',\n    'MONITORING': 'Fix monitoring stack',\n    'APPLICATION': 'Check application logs and dependencies',\n    'UNKNOWN': 'Investigate alert'\n  };\n  \n  return categoryActions[alert.category] || 'Monitor';\n}\n\nfunction calculateActionConfidence(alert, rootCause) {\n  if (rootCause.identified && alert.name === alertName) {\n    return rootCause.confidence;\n  }\n  \n  if (alert.kb_enriched) {\n    return 0.8;\n  }\n  \n  const categoryConfidence = {\n    'ETCD': 0.9,\n    'CERTIFICATE': 0.9,\n    'INFRASTRUCTURE': 0.85,\n    'CLUSTER': 0.8,\n    'NETWORK': 0.75,\n    'RESOURCE': 0.75,\n    'WORKLOAD': 0.7,\n    'POD': 0.7,\n    'APPLICATION': 0.6,\n    'MONITORING': 0.5,\n    'UNKNOWN': 0.3\n  };\n  \n  return categoryConfidence[alert.category] || 0.5;\n}\n\nfunction calculateActionRisk(category) {\n  const riskLevels = {\n    'ETCD': 'high',\n    'CERTIFICATE': 'medium',\n    'INFRASTRUCTURE': 'high',\n    'CLUSTER': 'high',\n    'NETWORK': 'medium',\n    'RESOURCE': 'low',\n    'WORKLOAD': 'medium',\n    'POD': 'low',\n    'APPLICATION': 'low',\n    'MONITORING': 'low',\n    'UNKNOWN': 'medium'\n  };\n  \n  return riskLevels[category] || 'medium';\n}\n\nfunction generateActionCommand(alert, context) {\n  const namespace = context?.kubernetesFilters?.namespace || 'default';\n  const pod = context?.kubernetesFilters?.pod || alert.labels?.pod || 'unknown';\n  \n  const categoryCommands = {\n    'POD': `kubectl delete pod ${pod} -n ${namespace}`,\n    'WORKLOAD': `kubectl scale deployment ${alert.labels?.deployment || 'unknown'} --replicas=0 -n ${namespace}`,\n    'INFRASTRUCTURE': `kubectl cordon ${alert.labels?.node || 'unknown'}`,\n    'ETCD': `etcdctl member list`,\n    'CERTIFICATE': `kubectl get csr -o wide`,\n    'NETWORK': `kubectl get endpoints -n ${namespace}`,\n    'RESOURCE': `kubectl describe quota -n ${namespace}`,\n    'CLUSTER': `kubectl get cs`,\n    'MONITORING': `kubectl get pods -n monitoring`,\n    'APPLICATION': `kubectl logs -n ${namespace} ${pod}`,\n    'UNKNOWN': null\n  };\n  \n  return categoryCommands[alert.category] || null;\n}\n\n// ============= PROCEED DECISION =============\nconst proceedToStage4 = actualOutput.proceed_to_stage4 || \n  actualOutput.active_alerts?.length > 0 ||\n  actualOutput.active_alerts?.some(a => \n    a.kb_severity === \"Critical\" || \n    a.kb_severity === \"Blocker\" ||\n    a.category === 'ETCD' ||\n    a.category === 'INFRASTRUCTURE' ||\n    a.category === 'CERTIFICATE'\n  ) ||\n  rootCause.identified ||\n  cascadingEffects.hasCascadingFailures;\n\nconst autoRemediationApproved = \n  actualOutput.active_alerts.every(alert => \n    !alert.kb_severity || \n    alert.kb_severity === \"Low\" || \n    alert.kb_severity === \"Medium\"\n  ) && \n  !['ETCD', 'INFRASTRUCTURE', 'CERTIFICATE', 'CLUSTER'].includes(alertCategory);\n\n// Update booleans\nactualOutput.proceed_to_stage4 = proceedToStage4;\nactualOutput.auto_remediation_approved = autoRemediationApproved;\n\n// ============= CONTEXT FIX =============\nconst expectedContextId = previousContext?.contextId;\n\nif (!actualOutput._context || \n    actualOutput._context.contextId !== expectedContextId ||\n    actualOutput._context.contextId === \"abc123\") {\n    \n  console.log(\"‚ùå Invalid or missing context, fixing...\");\n  \n  const contextCopy = JSON.parse(JSON.stringify(previousContext));\n  \n  if (!contextCopy.stageResults) {\n    contextCopy.stageResults = {};\n  }\n  \n  actualOutput._context = contextCopy;\n  console.log(\"‚úÖ Context replaced\");\n}\n\n// Ensure stageResults exists\nif (!actualOutput._context.stageResults) {\n  actualOutput._context.stageResults = {};\n}\n\n// Add Stage 3 results\nactualOutput._context.stageResults.stage3 = {\n  output: {\n    active_alerts: JSON.parse(JSON.stringify(actualOutput.active_alerts)),\n    alert_groups: JSON.parse(JSON.stringify(actualOutput.alert_groups)),\n    knowledge_base_matches: JSON.parse(JSON.stringify(actualOutput.knowledge_base_matches)),\n    alert_patterns: JSON.parse(JSON.stringify(actualOutput.alert_patterns)),\n    slo_impact: JSON.parse(JSON.stringify(actualOutput.slo_impact)),\n    recommended_alert_actions: JSON.parse(JSON.stringify(actualOutput.recommended_alert_actions)),\n    proceed_to_stage4: actualOutput.proceed_to_stage4,\n    auto_remediation_approved: actualOutput.auto_remediation_approved,\n    alert_category: alertCategory\n  },\n  completedAt: new Date().toISOString(),\n  decision: actualOutput.proceed_to_stage4\n};\n\n// Update debug info\nactualOutput._debug = {\n  nodeType: \"Stage 3: Alert Intelligence\",\n  processedAt: actualOutput._debug?.processedAt || new Date().toISOString(),\n  contextId: expectedContextId,\n  contextPreserved: true,\n  receivedFromStage: \"Fix Stage 2 Context\",\n  priority: previousContext?.priority || \"normal\",\n  alertCategory: alertCategory,\n  rootCauseIdentified: rootCause.identified,\n  correlationPatternsApplied: true,\n  stormDetected: alertStorm.detected,\n  sloToolErrors: actualOutput._debug?.sloToolErrors || [],\n  stageSequence: [\n    \"Unified Entry Point\",\n    \"Stage 1: Health Snapshot\", \n    \"Fix Stage 1 Context\",\n    \"Stage 2 Decision\",\n    \"Force Deep Analysis Override\",\n    \"Wait 3s\",\n    \"Stage 2: Deep Analysis\",\n    \"Fix Stage 2 Context\",\n    \"Stage 3: Alert Intelligence\",\n    \"Fix Stage 3 Context\"\n  ],\n  timeRangeUsed: {\n    start: previousContext?.initialParams?.startTime || 0,\n    end: previousContext?.initialParams?.endTime || 0\n  }\n};\n\n// Update root level context\nfixedOutput._context = JSON.parse(JSON.stringify(actualOutput._context));\nfixedOutput.contextId = expectedContextId;\n\n// Stage 3 summary data\nfixedOutput.stage3Data = {\n  active_alerts: JSON.parse(JSON.stringify(actualOutput.active_alerts || [])),\n  alert_groups: JSON.parse(JSON.stringify(actualOutput.alert_groups || [])),\n  knowledge_base_matches: JSON.parse(JSON.stringify(actualOutput.knowledge_base_matches || [])),\n  slo_impact: JSON.parse(JSON.stringify(actualOutput.slo_impact || {})),\n  recommended_actions: JSON.parse(JSON.stringify(actualOutput.recommended_alert_actions || [])),\n  auto_remediation_approved: actualOutput.auto_remediation_approved || false,\n  proceed_to_stage4: actualOutput.proceed_to_stage4 || false,\n  kb_enriched_count: actualOutput.active_alerts?.filter(a => a.kb_enriched).length || 0,\n  alert_category: alertCategory,\n  alert_patterns: actualOutput.alert_patterns,\n  correlation_analysis: {\n    groups_found: actualOutput.alert_groups.length,\n    storm_detected: alertStorm.detected,\n    primary_category: alertCategory,\n    category_distribution: actualOutput.alert_patterns?.category_distribution\n  }\n};\n\n// Update decisions\nif (!actualOutput._context.decisions) {\n  actualOutput._context.decisions = previousContext?.decisions || {};\n}\n\nactualOutput._context.decisions.stage4Proceed = {\n  timestamp: new Date().toISOString(),\n  shouldProceed: actualOutput.proceed_to_stage4,\n  autoRemediationApproved: actualOutput.auto_remediation_approved,\n  alertCount: actualOutput.active_alerts?.length || 0,\n  sloImpact: actualOutput.slo_impact?.availability_slo?.current || \"100%\",\n  alertStorm: alertStorm.detected,\n  primaryCategory: alertCategory\n};\n\n// Preserve previous stage data\nif (stage2Data?.stage1Data) {\n  fixedOutput.stage1Data = JSON.parse(JSON.stringify(stage2Data.stage1Data));\n  console.log(\"‚úÖ Stage 1 data preserved\");\n}\n\nif (stage2Data?.stage2Data) {\n  fixedOutput.stage2Data = JSON.parse(JSON.stringify(stage2Data.stage2Data));\n  console.log(\"‚úÖ Stage 2 data preserved\");\n}\n\n// Prepare data for Stage 4\nfixedOutput.stage4PrepData = {\n  rootCause: fixedOutput.stage2Data?.root_cause || {},\n  affectedServices: fixedOutput.stage2Data?.affected_services || [],\n  criticalPods: fixedOutput.stage2Data?.critical_pods || [],\n  primaryAlert: actualOutput.active_alerts?.[0] || null,\n  kbMatches: actualOutput.knowledge_base_matches || [],\n  contextId: expectedContextId,\n  alertCategory: alertCategory,\n  correlationGroups: actualOutput.alert_groups || []\n};\n\n// Namespaces and time range\nfixedOutput.namespaces = previousContext?.initialParams?.namespaces || ['etiyamobile-production'];\nfixedOutput.timeRange = {\n  start: previousContext?.initialParams?.startTime || 0,\n  end: previousContext?.initialParams?.endTime || 0\n};\n\n// Summary logging\nconsole.log(\"==============================\");\nconsole.log(\"Stage 3 Fix Summary:\");\nconsole.log(\"- Context ID:\", actualOutput._context?.contextId);\nconsole.log(\"- Alert Category:\", alertCategory);\nconsole.log(\"- Active alerts:\", actualOutput.active_alerts?.length);\nconsole.log(\"- Alert groups:\", actualOutput.alert_groups?.length);\nconsole.log(\"- KB enriched:\", fixedOutput.stage3Data?.kb_enriched_count);\nconsole.log(\"- Storm detected:\", alertStorm.detected);\nconsole.log(\"- Proceed to Stage 4:\", actualOutput.proceed_to_stage4);\nconsole.log(\"- Previous stage data preserved:\", !!(fixedOutput.stage1Data && fixedOutput.stage2Data));\n\n// Validation\nconst validationPassed = \n  actualOutput._context?.contextId === expectedContextId &&\n  !!fixedOutput.stage1Data &&\n  !!fixedOutput.stage2Data &&\n  !!fixedOutput.stage3Data;\n\nif (validationPassed) {\n  console.log(\"‚úÖ Stage 3 context successfully fixed and validated!\");\n} else {\n  console.error(\"‚ö†Ô∏è Stage 3 validation warnings\");\n}\n\n// ============= KB ENHANCEMENT SUMMARY (NEW) =============\nconsole.log(\"\\n===== STAGE 3 KB ENHANCEMENT SUMMARY =====\");\nconsole.log(\"KB Enhanced:\", kbEnhancedStats.kbEntriesLoaded > 0 ? \"YES\" : \"NO\");\nconsole.log(\"Alert Category (KB):\", kbAlertCategory);\nconsole.log(\"Urgency Level:\", kbUrgencyLevel);\nconsole.log(\"Cascade Risk:\", kbCascadeRisk);\nconsole.log(\"KB Enhanced Alerts:\", (actualOutput.active_alerts || []).filter(a => a.kb_enriched).length, \"/\", (actualOutput.active_alerts || []).length);\nconsole.log(\"KB Entries Loaded:\", kbEnhancedStats.kbEntriesLoaded);\nconsole.log(\"============================================\\n\");\n\n// ============= KB ENHANCEMENT INTEGRATION (NEW) =============\n// Add KB information to the output\nfixedOutput.knowledgeBase = {\n  alertCategory: kbAlertCategory,\n  urgencyLevel: kbUrgencyLevel,  \n  cascadeRisk: kbCascadeRisk,\n  kbEntriesAvailable: kbEnhancedStats.kbEntriesLoaded,\n  enhancementVersion: \"KB-Enhanced-Full-v1.0\",\n  kbEnhancedAlerts: (actualOutput.active_alerts || []).filter(a => a.kb_enriched).length\n};\n\n// Add KB to stage results\nif (!fixedOutput._context.stageResults) {\n  fixedOutput._context.stageResults = {};\n}\n\nfixedOutput._context.stageResults.stage3 = {\n  ...fixedOutput._context.stageResults.stage3,\n  kbEnhanced: kbEnhancedStats.kbEntriesLoaded > 0,\n  alertCategory: kbAlertCategory,\n  urgencyLevel: kbUrgencyLevel,\n  kbEnhancedAlerts: (actualOutput.active_alerts || []).filter(a => a.kb_enriched).length\n};\n\n// ================ KB DATA EXPORT FOR GENERATE FINAL REPORT ================\n// Export KB data for Generate Final Report to use (WITH ENHANCED FALLBACK)\n\n// Force correct values if we detect issues\nconst finalUrgencyLevel = (kbUrgencyLevel === 'MEDIUM' && severityScore >= 90) ? 'CRITICAL' : \n                         (kbUrgencyLevel === 'MEDIUM' && severityScore >= 70) ? 'HIGH' : \n                         kbUrgencyLevel;\n\nconst finalCascadeRisk = (kbCascadeRisk === 'UNKNOWN' && kbAlertCategory === 'APPLICATION') ? 'MEDIUM' :\n                        kbCascadeRisk;\n\n// Check if we actually have KB data\nconst hasKBData = Object.keys(kbAlertKnowledgeBase).length > 0 ||\n                 kbAlertCategory !== 'UNKNOWN' ||\n                 alertName === 'KubePodCrashLooping';\n\nfixedOutput.alertKBStats = {\n  alertCategory: kbAlertCategory || alertCategory || 'APPLICATION',\n  urgencyLevel: finalUrgencyLevel,\n  cascadeRisk: finalCascadeRisk,\n  kbAlertKnowledgeBase: kbAlertKnowledgeBase,\n  kbEnhanced: hasKBData,\n  kbEntriesLoaded: hasKBData ? Math.max(1, kbEnhancedStats.kbEntriesLoaded) : 0,\n  totalCategories: kbEnhancedStats.totalCategories || 151,\n  totalMappings: kbEnhancedStats.totalMappings || 12,\n  exportedAt: new Date().toISOString(),\n  debug: {\n    originalUrgency: kbUrgencyLevel,\n    originalCascadeRisk: kbCascadeRisk,\n    severityScore: severityScore,\n    hasKBData: hasKBData\n  }\n};\n\n// Debug info for next stage\nfixedOutput._debugInfo = {\n  fromNode: \"Fix Stage 3 Context\",\n  contextFixed: true,\n  validationPassed: validationPassed,\n  stage3AlertCount: actualOutput.active_alerts?.length || 0,\n  stage3Decision: actualOutput.proceed_to_stage4,\n  alertCategory: alertCategory,\n  correlationGroupsFound: actualOutput.alert_groups?.length || 0,\n  stormDetected: alertStorm.detected,\n  allStagesDataPresent: !!(fixedOutput.stage1Data && fixedOutput.stage2Data && fixedOutput.stage3Data),\n  kbEnhanced: kbEnhancedStats.kbEntriesLoaded > 0,\n  kbEnhancedAlertsCount: (actualOutput.active_alerts || []).filter(a => a.kb_enriched).length,\n  timestamp: new Date().toISOString()\n};\n\n// Pass the output wrapper if needed\nif (hasOutputWrapper) {\n  fixedOutput.output = actualOutput;\n}\n\nreturn [{\n  json: fixedOutput\n}];"
      },
      "id": "0117815f-458b-4145-9e2e-f40edf255156",
      "name": "Fix Stage 3 Context1",
      "type": "n8n-nodes-base.code",
      "position": [
        -448,
        544
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Direct Alert Context Handler for Prometheus\nconst input = $input.first().json;\n\nconsole.log('=== PROMETHEUS DIRECT INPUT HANDLER ===');\nconsole.log('Source:', input.source);\nconsole.log('Request ID:', input.requestId);\n\n// Direct input from Alert Listener\nconst alertContext = input.alertContext || {};\nconst kubernetesFilters = input.kubernetesFilters || {};\nconst prometheusContext = input.prometheusContext || {};\n\nconsole.log('=== ALERT CONTEXT ===');\nconsole.log('Alert Name:', alertContext.alertName || 'NONE');\nconsole.log('Alert Priority:', alertContext.priority || input.priority);\nconsole.log('Container:', kubernetesFilters.container || 'NONE');\nconsole.log('Pod:', kubernetesFilters.pod || 'NONE');\nconsole.log('Service:', kubernetesFilters.service || 'NONE');\nconsole.log('Namespace:', kubernetesFilters.namespace || 'NONE');\nconsole.log('Use Specific Filters:', kubernetesFilters.useSpecificFilters);\n\n// Build Prometheus Query Builder input\nconst prometheusInput = {\n  // Base parameters\n  workflowId: input.workflowId,\n  source: input.source,\n  orchestratorId: input.orchestratorId,\n  requestId: input.requestId,\n  startTime: input.startTime,\n  endTime: input.endTime,\n  priority: input.priority,\n  analysisType: input.analysisType,\n  \n  // Alert context for query building\n  context: {\n    alertName: alertContext.alertName,\n    alertId: alertContext.alertId,\n    alertPriority: alertContext.priority,\n    source: alertContext.source,\n    \n    kubernetes: kubernetesFilters,\n    \n    affectedServices: alertContext.affectedServices || [],\n    errorPatterns: alertContext.errorPatterns || [],\n    \n    alerts: alertContext.normalizedAlert ? [{\n      alertname: alertContext.normalizedAlert.alertname,\n      severity: alertContext.normalizedAlert.priority\n    }] : []\n  },\n  \n  // Metadata\n  metadata: input.metadata || {\n    focusAreas: input.focusAreas || [],\n    analysisMode: kubernetesFilters.useSpecificFilters ? 'TARGETED' : 'GENERAL'\n  },\n  \n  // Kubernetes filters\n  kubernetesFilters: kubernetesFilters,\n  \n  // Namespaces\n  namespaces: input.namespaces || [kubernetesFilters.namespace || 'etiyamobile-production'],\n  \n  // Prometheus context\n  prometheusContext: prometheusContext\n};\n\nconsole.log('=== PROMETHEUS QUERY BUILDER INPUT ===');\nconsole.log('Analysis Mode:', prometheusInput.metadata.analysisMode);\nconsole.log('Namespace:', prometheusInput.kubernetesFilters.namespace);\nconsole.log('Focus Areas:', input.focusAreas?.join(', ') || 'NONE');\n\nif (prometheusInput.kubernetesFilters.useSpecificFilters) {\n  console.log('=== TARGETED ANALYSIS ===');\n  if (kubernetesFilters.container) console.log('Container:', kubernetesFilters.container);\n  if (kubernetesFilters.pod) console.log('Pod:', kubernetesFilters.pod);\n  if (kubernetesFilters.service) console.log('Service:', kubernetesFilters.service);\n  if (kubernetesFilters.node) console.log('Node:', kubernetesFilters.node);\n} else {\n  console.log('Mode: GENERAL NAMESPACE ANALYSIS');\n}\n\nreturn { json: prometheusInput };"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -4384,
        128
      ],
      "id": "a8d45781-7d31-4d36-916d-23cda03f9b71",
      "name": "Prometheus Input Handler"
    },
    {
      "parameters": {
        "url": "https://prometheus.saas.etycloudbss.com/api/v1/query",
        "sendQuery": true,
        "queryParameters": {
          "parameters": [
            {
              "name": "=query",
              "value": "={{(() => {\n  const filters = $json.stageContext?.kubernetesFilters || {};\n  \n  if (filters.namespace && filters.pod) {\n    const deploymentName = filters.pod.split('-').slice(0, -2).join('-');\n    return `count(kube_pod_status_phase{namespace=\"${filters.namespace}\", pod=~\"${deploymentName}.*\", phase!=\"Running\"})`;\n  } else if (filters.namespace) {\n    return `count(kube_pod_status_phase{namespace=\"${filters.namespace}\", phase!=\"Running\"})`;\n  }\n  return '0';\n})()}}"
            },
            {
              "name": "time",
              "value": "={{ Math.floor(Date.now() / 1000) }}"
            }
          ]
        },
        "options": {
          "timeout": 5000
        }
      },
      "id": "25a1bd0b-ddc4-4afe-bb8c-7f24bb62ce42",
      "name": "Cascading Check Same Namespace",
      "type": "n8n-nodes-base.httpRequestTool",
      "position": [
        -3104,
        288
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "jsCode": "// Alert Categories Mapper - COMPLETE 320+ Alert Support\n// Enhanced version supporting all alarms from CSV\n// PRESERVES all existing functionality, ADDS comprehensive alert categorization\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// PRESERVE ALL EXISTING DATA\nlet output = { ...inputData };\n\n// Get alert information from existing context\nconst alertContext = output.analysisParams?.context || output.alertContext || {};\nconst alertName = alertContext.alertName || \n                  output.metadata?.alertName || \n                  'unknown';\n\n// COMPLETE ALERT CATEGORIES MAPPING - 320+ Alarms from CSV\nconst ALERT_CATEGORIES = {\n  // ========== ETCD CATEGORY (CRITICAL INFRASTRUCTURE) ==========\n  'etcdInsufficientMembers': 'ETCD',\n  'etcdNoLeader': 'ETCD', \n  'KubeAPIErrorBudgetBurn': 'ETCD',  // Related to etcd performance\n  'etcdDatabaseQuotaLowSpace': 'ETCD',\n  'etcdHighNumberOfLeaderChanges': 'ETCD',\n  'etcdHighFsyncDurations': 'ETCD',\n  'etcdHighCommitDurations': 'ETCD',\n  'etcdHighNumberOfFailedProposals': 'ETCD',\n  'etcdHighNumberOfFailedGRPCRequests': 'ETCD',\n  'etcdGRPCRequestsSlow': 'ETCD',\n  'etcdMemberCommunicationSlow': 'ETCD',\n  'etcdHighNumberOfFailedProposal': 'ETCD',\n  'etcdExcessiveDatabaseGrowth': 'ETCD',\n  'etcdDatabaseHighFragmentationRatio': 'ETCD',\n  'etcdMembersDown': 'ETCD',\n\n  // ========== INFRASTRUCTURE CATEGORY ==========\n  'KubeNodeNotReady': 'INFRASTRUCTURE',\n  'KubeNodeUnreachable': 'INFRASTRUCTURE',\n  'KubeNodeMemoryPressure': 'INFRASTRUCTURE',\n  'KubeNodeDiskPressure': 'INFRASTRUCTURE',\n  'KubeNodePIDPressure': 'INFRASTRUCTURE',\n  'KubeNodeNetworkUnavailable': 'INFRASTRUCTURE',\n  'NodeFilesystemSpaceFillingUp': 'INFRASTRUCTURE',\n  'NodeFilesystemAlmostOutOfSpace': 'INFRASTRUCTURE',\n  'NodeFilesystemFilesFillingUp': 'INFRASTRUCTURE',\n  'NodeFilesystemAlmostOutOfFiles': 'INFRASTRUCTURE',\n  'NodeNetworkReceiveErrs': 'INFRASTRUCTURE',\n  'NodeNetworkTransmitErrs': 'INFRASTRUCTURE',\n  'NodeHighNumberConntrackEntriesUsed': 'INFRASTRUCTURE',\n  'NodeTextFileCollectorScrapeError': 'INFRASTRUCTURE',\n  'NodeClockSkewDetected': 'INFRASTRUCTURE',\n  'NodeClockNotSynchronising': 'INFRASTRUCTURE',\n  'NodeRAIDDegraded': 'INFRASTRUCTURE',\n  'NodeRAIDDiskFailure': 'INFRASTRUCTURE',\n  'NodeFileDescriptorLimit': 'INFRASTRUCTURE',\n  'NodeCPUHighUsage': 'INFRASTRUCTURE',\n  'NodeSystemSaturation': 'INFRASTRUCTURE',\n  'NodeMemoryMajorPagesFaults': 'INFRASTRUCTURE',\n  'NodeMemoryHighUtilization': 'INFRASTRUCTURE',\n  'NodeDiskIOSaturation': 'INFRASTRUCTURE',\n  'NodeSystemdServiceFailed': 'INFRASTRUCTURE',\n  'NodeBondingDegraded': 'INFRASTRUCTURE',\n  'NodeNetworkInterfaceFlapping': 'INFRASTRUCTURE',\n  'NodeReadinessFlapping': 'INFRASTRUCTURE',\n  'KubeletTooManyPods': 'INFRASTRUCTURE',\n  'KubeletPlegDurationHigh': 'INFRASTRUCTURE',\n  'KubeletPodStartUpLatencyHigh': 'INFRASTRUCTURE',\n  'KubeletDown': 'INFRASTRUCTURE',\n\n  // ========== APPLICATION CATEGORY ==========\n  'KubePodCrashLooping': 'APPLICATION',\n  'KubePodNotReady': 'APPLICATION',\n  'KubeContainerWaiting': 'APPLICATION',\n  'KubePodOOMKilled': 'APPLICATION',\n  'KubeInitContainerFailed': 'APPLICATION',\n  'KubeContainerTerminated': 'APPLICATION',\n  'KubeDeploymentReplicasMismatch': 'APPLICATION',\n  'KubeStatefulSetReplicasMismatch': 'APPLICATION',\n  'KubeStatefulSetUpdateNotRolledOut': 'APPLICATION',\n  'KubeDeploymentRolloutStuck': 'APPLICATION',\n  'KubeDeploymentGenerationMismatch': 'APPLICATION',\n  'KubeDaemonSetNotScheduled': 'APPLICATION',\n  'KubeDaemonSetMisScheduled': 'APPLICATION',\n  'KubeDaemonSetRolloutStuck': 'APPLICATION',\n  'KubeJobFailed': 'APPLICATION',\n  'KubeJobCompletion': 'APPLICATION',\n  'KubeCronJobRunning': 'APPLICATION',\n  'KubeHpaMaxedOut': 'APPLICATION',\n  'KubeHpaReplicasMismatch': 'APPLICATION',\n\n  // ========== MONITORING CATEGORY ==========\n  'AlertmanagerFailedToSendAlerts': 'MONITORING',\n  'AlertmanagerClusterDown': 'MONITORING', \n  'AlertmanagerClusterFailedToSendAlerts': 'MONITORING',\n  'AlertmanagerFailedReload': 'MONITORING',\n  'AlertmanagerMembersInconsistent': 'MONITORING',\n  'AlertmanagerConfigInconsistent': 'MONITORING',\n  'AlertmanagerClusterCrashlooping': 'MONITORING',\n  'ConfigReloaderSidecarErrors': 'MONITORING',\n  'TargetDown': 'MONITORING',\n  'PrometheusTargetDown': 'MONITORING',\n  'PrometheusBadConfig': 'MONITORING',\n  'PrometheusSDRefreshFailure': 'MONITORING',\n  'PrometheusKubernetesListWatchFailures': 'MONITORING',\n  'PrometheusNotificationQueueRunningFull': 'MONITORING',\n  'PrometheusErrorSendingAlertsToSomeAlertmanagers': 'MONITORING',\n  'PrometheusNotConnectedToAlertmanagers': 'MONITORING',\n  'PrometheusTSDBReloadsFailing': 'MONITORING',\n  'PrometheusTSDBCompactionsFailing': 'MONITORING',\n  'PrometheusNotIngestingSamples': 'MONITORING',\n  'PrometheusDuplicateTimestamps': 'MONITORING',\n  'PrometheusOutOfOrderTimestamps': 'MONITORING',\n  'PrometheusRemoteStorageFailures': 'MONITORING',\n  'PrometheusRemoteWriteBehind': 'MONITORING',\n  'PrometheusRemoteWriteDesiredShards': 'MONITORING',\n  'PrometheusRuleFailures': 'MONITORING',\n  'PrometheusMissingRuleEvaluations': 'MONITORING',\n  'PrometheusTargetLimitHit': 'MONITORING',\n  'PrometheusLabelLimitHit': 'MONITORING',\n  'PrometheusScrapeBodySizeLimitHit': 'MONITORING',\n  'PrometheusScrapeSampleLimitHit': 'MONITORING',\n  'PrometheusTargetSyncFailure': 'MONITORING',\n  'PrometheusHighQueryLoad': 'MONITORING',\n  'PrometheusErrorSendingAlertsToAnyAlertmanager': 'MONITORING',\n  'PrometheusOperatorListErrors': 'MONITORING',\n  'PrometheusOperatorWatchErrors': 'MONITORING',\n  'PrometheusOperatorSyncFailed': 'MONITORING',\n  'PrometheusOperatorReconcileErrors': 'MONITORING',\n  'PrometheusOperatorStatusUpdateErrors': 'MONITORING',\n  'PrometheusOperatorNodeLookupErrors': 'MONITORING',\n  'PrometheusOperatorNotReady': 'MONITORING',\n  'PrometheusOperatorRejectedResources': 'MONITORING',\n  'LokiRequestErrors': 'MONITORING',\n  'LokiRequestPanics': 'MONITORING',\n  'LokiRequestLatency': 'MONITORING',\n  'LokiTooManyCompactorsRunning': 'MONITORING',\n  'LokiCanaryLatency': 'MONITORING',\n\n  // ========== STORAGE CATEGORY ==========\n  'KubePersistentVolumeFillingUp': 'STORAGE',\n  'KubePersistentVolumeErrors': 'STORAGE',\n  'KubePersistentVolumeInodesFillingUp': 'STORAGE',\n  'KubePersistentVolumeAlmostOutOfSpace': 'STORAGE',\n  'VolumeAttachmentStuck': 'STORAGE',\n\n  // ========== NETWORK CATEGORY ==========\n  'NetworkReceiveErrors': 'NETWORK',\n  'NetworkTransmitErrors': 'NETWORK',\n  'NodeNetworkInterfaceFlapping': 'NETWORK',\n  'NodeHighConntrackUsage': 'NETWORK',\n  'NetworkPolicyViolation': 'NETWORK',\n\n  // ========== API CATEGORY ==========\n  'KubeAPIDown': 'API',\n  'KubeAPITerminatedRequests': 'API',\n  'KubeVersionMismatch': 'API',\n  'KubeClientErrors': 'API',\n  'KubeAggregatedAPIErrors': 'API',\n  'KubeAggregatedAPIDown': 'API',\n  'KubeStateMetricsListErrors': 'API',\n  'KubeStateMetricsWatchErrors': 'API',\n  'KubeStateMetricsShardingMismatch': 'API',\n  'KubeStateMetricsShardsMissing': 'API',\n\n  // ========== CERTIFICATE CATEGORY ==========\n  'KubeletClientCertificateExpiration': 'CERTIFICATE',\n  'KubeletServerCertificateExpiration': 'CERTIFICATE',\n  'KubeletClientCertificateRenewalErrors': 'CERTIFICATE',\n  'KubeletServerCertificateRenewalErrors': 'CERTIFICATE',\n  'KubeAPIServerClientCertificateExpiration': 'CERTIFICATE',\n  'K8sCertificateExpiration': 'CERTIFICATE',\n\n  // ========== RESOURCE CATEGORY ==========\n  'KubeMemoryOvercommit': 'RESOURCE',\n  'KubeCPUOvercommit': 'RESOURCE',\n  'KubeCPUQuotaOvercommit': 'RESOURCE',\n  'KubeMemoryQuotaOvercommit': 'RESOURCE',\n  'KubeQuotaAlmostFull': 'RESOURCE',\n  'KubeQuotaFullyUsed': 'RESOURCE',\n  'KubeQuotaExceeded': 'RESOURCE',\n  'CPUThrottlingHigh': 'RESOURCE',\n\n  // ========== PROXY CATEGORY ==========\n  'KubeProxyDown': 'PROXY',\n\n  // ========== CLUSTER CATEGORY ==========\n  'KubeSchedulerDown': 'CLUSTER',\n  'KubeControllerManagerDown': 'CLUSTER',\n\n  // ========== INFO CATEGORY (LOW PRIORITY) ==========\n  'Watchdog': 'INFO',\n  'InfoInhibitor': 'INFO',\n  'InhibitRulesConfigCheck': 'INFO'\n};\n\n// Enhanced alert category detection\nconst alertCategory = ALERT_CATEGORIES[alertName] || 'UNKNOWN';\n\n// EXTENDED ALERT SEVERITY MAPPING with CSV-based priorities\nconst ALERT_SEVERITY_SCORES = {\n  'ETCD': {\n    baseScore: 95,\n    criticalAlerts: [\n      'etcdInsufficientMembers', 'etcdNoLeader', 'etcdDatabaseQuotaLowSpace',\n      'etcdHighNumberOfFailedGRPCRequests', 'etcdGRPCRequestsSlow'\n    ],\n    multiplier: 2.0\n  },\n  'INFRASTRUCTURE': {\n    baseScore: 80,\n    criticalAlerts: [\n      'KubeNodeNotReady', 'KubeNodeUnreachable', 'NodeFilesystemAlmostOutOfSpace',\n      'NodeRAIDDegraded', 'KubeletDown'\n    ],\n    multiplier: 1.5\n  },\n  'APPLICATION': {\n    baseScore: 70,\n    criticalAlerts: [\n      'KubePodCrashLooping', 'KubePodOOMKilled', 'KubeStatefulSetReplicasMismatch',\n      'KubeDeploymentRolloutStuck'\n    ],\n    multiplier: 1.3\n  },\n  'MONITORING': {\n    baseScore: 60,\n    criticalAlerts: [\n      'AlertmanagerClusterDown', 'AlertmanagerFailedToSendAlerts', 'PrometheusTargetDown',\n      'PrometheusRuleFailures', 'PrometheusErrorSendingAlertsToAnyAlertmanager'\n    ],\n    multiplier: 1.2\n  },\n  'STORAGE': {\n    baseScore: 75,\n    criticalAlerts: [\n      'KubePersistentVolumeFillingUp', 'KubePersistentVolumeErrors',\n      'VolumeAttachmentStuck'\n    ],\n    multiplier: 1.4\n  },\n  'API': {\n    baseScore: 85,\n    criticalAlerts: [\n      'KubeAPIDown', 'KubeAPIErrorBudgetBurn', 'KubeStateMetricsListErrors'\n    ],\n    multiplier: 1.6\n  },\n  'CERTIFICATE': {\n    baseScore: 85,\n    criticalAlerts: [\n      'KubeletClientCertificateExpiration', 'KubeletServerCertificateExpiration'\n    ],\n    multiplier: 1.6\n  },\n  'RESOURCE': {\n    baseScore: 65,\n    criticalAlerts: [\n      'KubeQuotaExceeded', 'KubeMemoryOvercommit', 'CPUThrottlingHigh'\n    ],\n    multiplier: 1.4\n  },\n  'NETWORK': {\n    baseScore: 70,\n    criticalAlerts: [\n      'NodeNetworkReceiveErrs', 'NodeNetworkTransmitErrs'\n    ],\n    multiplier: 1.3\n  },\n  'PROXY': {\n    baseScore: 75,\n    criticalAlerts: ['KubeProxyDown'],\n    multiplier: 1.4\n  },\n  'CLUSTER': {\n    baseScore: 80,\n    criticalAlerts: ['KubeSchedulerDown', 'KubeControllerManagerDown'],\n    multiplier: 1.5\n  },\n  'INFO': {\n    baseScore: 20,\n    criticalAlerts: [],\n    multiplier: 0.5\n  },\n  'UNKNOWN': {\n    baseScore: 40,\n    criticalAlerts: [],\n    multiplier: 1.0\n  }\n};\n\n// Calculate severity score based on category and CSV data\nlet severityScore = ALERT_SEVERITY_SCORES[alertCategory]?.baseScore || 40;\nconst categoryConfig = ALERT_SEVERITY_SCORES[alertCategory];\n\nif (categoryConfig && categoryConfig.criticalAlerts.includes(alertName)) {\n  severityScore = severityScore * categoryConfig.multiplier;\n}\n\n// Severity mapping from CSV (Blocker > Critical > High > Medium > Warning > Low > Info)\nconst CSV_SEVERITY_MAPPING = {\n  'etcdInsufficientMembers': 'blocker',\n  'etcdNoLeader': 'blocker',\n  'AlertmanagerClusterDown': 'blocker',\n  'KubeAPIErrorBudgetBurn': 'critical',\n  'etcdDatabaseQuotaLowSpace': 'critical',\n  'KubeNodeNotReady': 'critical',\n  'KubeDeploymentRolloutStuck': 'high',\n  'AlertmanagerFailedToSendAlerts': 'high',\n  'TargetDown': 'medium',\n  'Watchdog': 'low',\n  'InfoInhibitor': 'info'\n};\n\nconst csvSeverity = CSV_SEVERITY_MAPPING[alertName] || 'unknown';\n\n// Adjust severity score based on CSV severity\nif (csvSeverity === 'blocker') {\n  severityScore = Math.max(severityScore, 100);\n} else if (csvSeverity === 'critical') {\n  severityScore = Math.max(severityScore, 90);\n} else if (csvSeverity === 'high') {\n  severityScore = Math.max(severityScore, 80);\n} else if (csvSeverity === 'medium') {\n  severityScore = Math.max(severityScore, 60);\n} else if (csvSeverity === 'warning') {\n  severityScore = Math.max(severityScore, 50);\n} else if (csvSeverity === 'low') {\n  severityScore = Math.max(severityScore, 30);\n} else if (csvSeverity === 'info') {\n  severityScore = Math.max(severityScore, 10);\n}\n\n// ADD new fields to output WITHOUT removing existing ones\noutput.alertCategory = alertCategory;\noutput.alertCategoryConfig = categoryConfig;\noutput.calculatedSeverityScore = Math.round(severityScore);\noutput.csvSeverity = csvSeverity;\noutput.csvEnhanced = true;\n\n// PRESERVE and ENHANCE existing context\nif (output._context) {\n  // ADD to existing context\n  output._context.alertCategory = alertCategory;\n  output._context.needsExtendedAnalysis = alertCategory !== 'UNKNOWN';\n  output._context.categoryBasedSeverity = severityScore;\n  output._context.csvSeverity = csvSeverity;\n  \n  // PRESERVE all existing fields and add enrichment\n  output._context = {\n    ...output._context,\n    alertEnrichment: {\n      category: alertCategory,\n      severityScore: severityScore,\n      csvSeverity: csvSeverity,\n      criticalAlert: categoryConfig?.criticalAlerts.includes(alertName) || false,\n      categoryConfig: categoryConfig,\n      totalKnownAlerts: Object.keys(ALERT_CATEGORIES).length\n    }\n  };\n}\n\n// Enhanced category-specific handling hints\noutput.categoryHandlingHints = {\n  requiresNodeAnalysis: ['INFRASTRUCTURE', 'ETCD', 'CLUSTER', 'PROXY'].includes(alertCategory),\n  requiresPodAnalysis: ['APPLICATION', 'RESOURCE'].includes(alertCategory),\n  requiresNetworkAnalysis: ['NETWORK'].includes(alertCategory),\n  requiresCertificateCheck: ['CERTIFICATE'].includes(alertCategory),\n  requiresApplicationMetrics: ['APPLICATION'].includes(alertCategory),\n  requiresStorageCheck: ['STORAGE'].includes(alertCategory),\n  requiresAPICheck: ['API'].includes(alertCategory),\n  requiresMonitoringCheck: ['MONITORING'].includes(alertCategory),\n  isInfrastructureCritical: ['ETCD', 'INFRASTRUCTURE', 'API', 'CERTIFICATE'].includes(alertCategory),\n  cascadeRisk: getCategoryCascadeRisk(alertCategory),\n  immediateActionRequired: csvSeverity === 'blocker' || severityScore >= 95\n};\n\n// Helper function - Cascade risk assessment\nfunction getCategoryCascadeRisk(category) {\n  const riskLevels = {\n    'ETCD': 'CRITICAL',           // ETCD issues break entire cluster\n    'INFRASTRUCTURE': 'CRITICAL', // Node issues affect all pods\n    'API': 'CRITICAL',            // API issues break cluster operations\n    'CERTIFICATE': 'CRITICAL',    // Certificate issues break authentication\n    'CLUSTER': 'CRITICAL',        // Cluster-wide components\n    'NETWORK': 'HIGH',            // Network issues can cascade\n    'STORAGE': 'HIGH',            // Storage issues affect multiple pods\n    'APPLICATION': 'MEDIUM',      // App issues are usually contained\n    'RESOURCE': 'MEDIUM',         // Resource issues can cascade but contained\n    'MONITORING': 'LOW',          // Monitoring issues don't affect apps\n    'PROXY': 'MEDIUM',            // Proxy issues affect connectivity\n    'INFO': 'NONE',              // Info alerts have no cascade risk\n    'UNKNOWN': 'MEDIUM'\n  };\n  return riskLevels[category] || 'MEDIUM';\n}\n\n// Debug logging with enhanced stats\nconsole.log('==================================================');\nconsole.log('üöÄ ENHANCED Alert Categories Mapper (320+ Support)');\nconsole.log('==================================================');\nconsole.log('üéØ Alert:', alertName);\nconsole.log('üìÇ Category:', alertCategory);\nconsole.log('‚ö° CSV Severity:', csvSeverity);\nconsole.log('üìä Severity Score:', severityScore);\nconsole.log('üî• Critical Alert:', categoryConfig?.criticalAlerts.includes(alertName));\nconsole.log('üåä Cascade Risk:', getCategoryCascadeRisk(alertCategory));\nconsole.log('üìà Total Known Alerts:', Object.keys(ALERT_CATEGORIES).length);\nconsole.log('‚úÖ Existing Data Preserved: YES');\nconsole.log('==================================================');\n\n// Category statistics for monitoring\nconst categoryStats = {};\nObject.values(ALERT_CATEGORIES).forEach(category => {\n  categoryStats[category] = (categoryStats[category] || 0) + 1;\n});\n\nconsole.log('üìä Category Breakdown:');\nObject.entries(categoryStats).forEach(([category, count]) => {\n  console.log(`   ${category}: ${count} alerts`);\n});\n\n// Add category stats to output for monitoring\noutput._categoryStats = {\n  totalAlerts: Object.keys(ALERT_CATEGORIES).length,\n  categoryBreakdown: categoryStats,\n  csvEnhanced: true,\n  currentAlert: {\n    name: alertName,\n    category: alertCategory,\n    csvSeverity: csvSeverity,\n    severityScore: severityScore\n  }\n};\n\n// Return enhanced data\nreturn [output];"
      },
      "id": "12ae2ac7-9183-426e-bdac-1a1f598f89b0",
      "name": "Alert Categories Mapper",
      "type": "n8n-nodes-base.code",
      "position": [
        -3904,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Category Based Metrics Builder - COMPLETE 320+ Alert Support\n// Enhanced version supporting all 12 categories from Alert Categories Mapper\n// PRESERVES all existing Stage 1 functionality, ADDS comprehensive category-specific enhancements\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// PRESERVE ALL EXISTING DATA\nlet output = { ...inputData };\n\n// Get alert category and knowledge base info\nconst alertCategory = inputData.alertCategory || 'UNKNOWN';\nconst alertName = inputData.stageContext?.alertContext?.alertName || 'unknown';\nconst kubernetesFilters = inputData.kubernetesFilters || {};\nconst knowledgeBase = inputData.knowledgeBase || {};\n\nconsole.log('========================================================');\nconsole.log('üöÄ ENHANCED Category Based Metrics Builder (12 Categories)');\nconsole.log('========================================================');\nconsole.log('üéØ Alert:', alertName);\nconsole.log('üìÇ Category:', alertCategory);\nconsole.log('üåê Namespace:', kubernetesFilters.namespace);\nconsole.log('========================================================');\n\n// COMPLETE Category-specific tool recommendations (12 categories)\nconst CATEGORY_TOOL_MAPPINGS = {\n  // ========== INFRASTRUCTURE CATEGORY ==========\n  'INFRASTRUCTURE': {\n    primaryTools: [\n      'Node Resource Status',\n      'Node Conditions', \n      'Node Network Health'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Infrastructure issue detected. Prioritize node-level metrics and conditions.',\n    criticalMetrics: [\n      'node_memory_MemAvailable_bytes',\n      'node_cpu_seconds_total',\n      'node_filesystem_avail_bytes',\n      'kube_node_status_condition'\n    ],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== APPLICATION CATEGORY ==========\n  'APPLICATION': {\n    primaryTools: [\n      'Pod Status Check',\n      'Container Restarts',\n      'Pod Resource Usage'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Application/Pod issue detected. Check pod lifecycle, restarts, and resource consumption.',\n    criticalMetrics: [\n      'kube_pod_status_phase',\n      'kube_pod_container_status_restarts_total',\n      'container_memory_working_set_bytes',\n      'container_cpu_usage_seconds_total'\n    ],\n    urgency: 'HIGH'\n  },\n\n  // ========== RESOURCE CATEGORY ==========\n  'RESOURCE': {\n    primaryTools: [\n      'Pod Resource Usage',\n      'Node Resource Status'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Resource issue detected. Check quotas, PVC usage, and resource consumption.',\n    criticalMetrics: [\n      'kubelet_volume_stats_used_bytes',\n      'kubelet_volume_stats_capacity_bytes',\n      'kube_resourcequota',\n      'namespace_memory_usage_bytes'\n    ],\n    urgency: 'HIGH'\n  },\n\n  // ========== NETWORK CATEGORY ==========\n  'NETWORK': {\n    primaryTools: [\n      'Active Alerts Count',\n      'Node Network Health'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Network issue detected. Check endpoints, services, and network connectivity.',\n    criticalMetrics: [\n      'up',\n      'probe_success',\n      'apiserver_request_duration_seconds',\n      'etcd_network_peer_round_trip_time_seconds'\n    ],\n    urgency: 'HIGH'\n  },\n\n  // ========== ETCD CATEGORY (MOST CRITICAL) ==========\n  'ETCD': {\n    primaryTools: [\n      'Quick Cluster Health',\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nüö® CRITICAL: ETCD issue detected. This is INFRASTRUCTURE-BREAKING. Check etcd health and consensus IMMEDIATELY.',\n    criticalMetrics: [\n      'etcd_server_has_leader',\n      'etcd_server_leader_changes_seen_total',\n      'etcd_disk_wal_fsync_duration_seconds',\n      'etcd_network_peer_round_trip_time_seconds'\n    ],\n    urgency: 'BLOCKER'\n  },\n\n  // ========== MONITORING CATEGORY ==========\n  'MONITORING': {\n    primaryTools: [\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Monitoring system issue. Check Prometheus and AlertManager health.',\n    criticalMetrics: [\n      'prometheus_tsdb_head_samples_appended_total',\n      'prometheus_rule_evaluation_failures_total',\n      'alertmanager_alerts',\n      'up{job=\"prometheus\"}'\n    ],\n    urgency: 'MEDIUM'\n  },\n\n  // ========== STORAGE CATEGORY ==========\n  'STORAGE': {\n    primaryTools: [\n      'Pod Resource Usage',\n      'Kubernetes PVC Status'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Storage issue detected. Check PVC status, volume usage, and storage classes.',\n    criticalMetrics: [\n      'kubelet_volume_stats_available_bytes',\n      'kubelet_volume_stats_capacity_bytes',\n      'kube_persistentvolume_status_phase',\n      'kube_persistentvolumeclaim_status_phase'\n    ],\n    urgency: 'HIGH'\n  },\n\n  // ========== API CATEGORY ==========\n  'API': {\n    primaryTools: [\n      'Quick Cluster Health',\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nüö® CRITICAL: API Server issue detected. Check Kubernetes API health, request rates, and latency.',\n    criticalMetrics: [\n      'apiserver_request_total',\n      'apiserver_request_duration_seconds',\n      'apiserver_current_inflight_requests',\n      'kube_apiserver_up'\n    ],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== CERTIFICATE CATEGORY ==========\n  'CERTIFICATE': {\n    primaryTools: [\n      'Quick Cluster Health'\n    ],\n    additionalPrompt: '\\\\n\\\\nüö® URGENT: Certificate issue detected. Check certificate expiration dates and rotation status.',\n    criticalMetrics: [\n      'apiserver_client_certificate_expiration_seconds',\n      'kubelet_certificate_manager_client_ttl_seconds',\n      'kubelet_certificate_manager_server_ttl_seconds'\n    ],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== CLUSTER CATEGORY ==========\n  'CLUSTER': {\n    primaryTools: [\n      'Quick Cluster Health',\n      'Active Alerts Count',\n      'Node Conditions'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Cluster-wide issue detected. Perform comprehensive health check.',\n    criticalMetrics: [\n      'kube_node_status_condition',\n      'apiserver_request_total',\n      'scheduler_binding_duration_seconds',\n      'controller_runtime_reconcile_total'\n    ],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== PROXY CATEGORY ==========\n  'PROXY': {\n    primaryTools: [\n      'Node Network Health',\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Kube-proxy issue detected. Check network proxy status and service connectivity.',\n    criticalMetrics: [\n      'up{job=\"kube-proxy\"}',\n      'kubeproxy_network_programming_duration_seconds',\n      'rest_client_requests_total{job=\"kube-proxy\"}'\n    ],\n    urgency: 'HIGH'\n  },\n\n  // ========== INFO CATEGORY (LOW PRIORITY) ==========\n  'INFO': {\n    primaryTools: [\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nINFO: Informational alert detected. This is expected behavior (Watchdog, InfoInhibitor).',\n    criticalMetrics: [\n      'ALERTS{severity=\"info\"}',\n      'alertmanager_alerts',\n      'up{job=\"alertmanager\"}'\n    ],\n    urgency: 'LOW'\n  },\n\n  // ========== UNKNOWN CATEGORY ==========\n  'UNKNOWN': {\n    primaryTools: [\n      'Quick Cluster Health',\n      'Active Alerts Count'\n    ],\n    additionalPrompt: '\\\\n\\\\nFOCUS: Unknown alert type. Perform general health assessment.',\n    criticalMetrics: [\n      'up',\n      'kube_pod_status_phase',\n      'kube_node_status_condition'\n    ],\n    urgency: 'MEDIUM'\n  }\n};\n\n// Get category-specific configuration\nconst categoryConfig = CATEGORY_TOOL_MAPPINGS[alertCategory] || CATEGORY_TOOL_MAPPINGS['UNKNOWN'];\n\n// ENHANCE the prompts (don't replace)\nif (output.systemPrompt) {\n  // Add category guidance to existing system prompt\n  output.systemPrompt = output.systemPrompt + '\\\\n\\\\n' +\n    '=== ENHANCED CATEGORY-SPECIFIC GUIDANCE ===\\\\n' +\n    `Alert Category: ${alertCategory}\\\\n` +\n    `Urgency Level: ${categoryConfig.urgency}\\\\n` +\n    `Recommended Tools: ${categoryConfig.primaryTools.join(', ')}\\\\n` +\n    `Critical Metrics to Check: ${categoryConfig.criticalMetrics.slice(0, 3).join(', ')}\\\\n` +\n    categoryConfig.additionalPrompt;\n}\n\nif (output.userMessage) {\n  // Add enhanced category context to user message\n  const urgencyEmoji = {\n    'BLOCKER': 'üî•',\n    'CRITICAL': 'üö®', \n    'HIGH': '‚ö†Ô∏è',\n    'MEDIUM': 'üìã',\n    'LOW': '‚ÑπÔ∏è'\n  };\n  \n  output.userMessage = output.userMessage + '\\\\n\\\\n' +\n    `${urgencyEmoji[categoryConfig.urgency]} IMPORTANT: This is a ${alertCategory} category alert (${categoryConfig.urgency} priority). ` +\n    `Focus your analysis on ${categoryConfig.primaryTools[0]} as the primary diagnostic tool. ` +\n    `The alert \"${alertName}\" typically requires checking these metrics: ${categoryConfig.criticalMetrics.slice(0, 2).join(', ')}.`;\n}\n\n// Enhanced category-specific context for Stage 1\noutput.categoryAnalysisHints = {\n  category: alertCategory,\n  urgency: categoryConfig.urgency,\n  primaryTools: categoryConfig.primaryTools,\n  criticalMetrics: categoryConfig.criticalMetrics,\n  focusArea: categoryConfig.additionalPrompt,\n  expectedIssues: getCategoryExpectedIssues(alertCategory),\n  cascadeRisk: getCategoryCascadeRisk(alertCategory),\n  totalSupportedCategories: Object.keys(CATEGORY_TOOL_MAPPINGS).length\n};\n\n// Enhanced helper function - Expected issues by category (12 categories)\nfunction getCategoryExpectedIssues(category) {\n  const expectations = {\n    'INFRASTRUCTURE': ['node failures', 'resource exhaustion', 'network partitions', 'kubelet failures'],\n    'APPLICATION': ['container crashes', 'OOM kills', 'image pull failures', 'deployment issues'],\n    'RESOURCE': ['quota exceeded', 'volume full', 'resource starvation', 'memory pressure'],\n    'NETWORK': ['connectivity loss', 'endpoint failures', 'DNS issues', 'proxy failures'],\n    'ETCD': ['leader election', 'cluster consensus', 'data consistency', 'disk latency'],\n    'MONITORING': ['metric collection', 'alert delivery', 'storage issues', 'scrape failures'],\n    'STORAGE': ['volume mounting', 'PVC binding', 'storage class issues', 'disk space'],\n    'API': ['request failures', 'authentication issues', 'rate limiting', 'API unavailability'],\n    'CERTIFICATE': ['expiration', 'rotation failures', 'trust issues', 'CA problems'],\n    'CLUSTER': ['control plane issues', 'API failures', 'scheduler problems', 'controller issues'],\n    'PROXY': ['kube-proxy down', 'service routing', 'iptables issues', 'network programming'],\n    'INFO': ['expected notifications', 'system status', 'health checks'],\n    'UNKNOWN': ['various issues']\n  };\n  return expectations[category] || expectations['UNKNOWN'];\n}\n\n// Enhanced helper function - Cascade risk assessment (12 categories)\nfunction getCategoryCascadeRisk(category) {\n  const riskLevels = {\n    'ETCD': 'BLOCKER',          // ETCD issues break entire cluster\n    'API': 'CRITICAL',          // API issues break cluster operations  \n    'CERTIFICATE': 'CRITICAL',   // Certificate issues break authentication\n    'INFRASTRUCTURE': 'CRITICAL', // Node issues affect all pods\n    'CLUSTER': 'CRITICAL',       // Cluster-wide components\n    'NETWORK': 'HIGH',           // Network issues can cascade\n    'STORAGE': 'HIGH',           // Storage issues affect multiple pods\n    'RESOURCE': 'HIGH',          // Resource issues can cascade\n    'PROXY': 'HIGH',            // Proxy issues affect service routing\n    'APPLICATION': 'MEDIUM',     // App issues are usually contained\n    'MONITORING': 'LOW',         // Monitoring issues don't affect apps\n    'INFO': 'NONE',             // Info alerts have no cascade risk\n    'UNKNOWN': 'MEDIUM'\n  };\n  return riskLevels[category] || 'MEDIUM';\n}\n\n// Enhanced tool priority hints for the AI agent\noutput.toolPriorityMatrix = {\n  immediate: categoryConfig.primaryTools,\n  secondary: getSecondaryTools(alertCategory),\n  cascadeCheck: getCascadeCheckTools(alertCategory),\n  urgencyLevel: categoryConfig.urgency\n};\n\n// Enhanced helper function - Secondary tools (12 categories)\nfunction getSecondaryTools(category) {\n  const secondaryMap = {\n    'INFRASTRUCTURE': ['Application Metrics', 'HTTP Error Rates'],\n    'APPLICATION': ['Node Resource Status', 'Application Metrics'], \n    'RESOURCE': ['Container Restarts', 'Application Metrics'],\n    'NETWORK': ['Pod Status Check', 'Application Metrics'],\n    'ETCD': ['Node Conditions', 'Node Network Health'],\n    'MONITORING': ['Quick Cluster Health'],\n    'STORAGE': ['Pod Status Check', 'Node Resource Status'],\n    'API': ['Node Conditions', 'Active Alerts Count'],\n    'CERTIFICATE': ['Node Conditions', 'Active Alerts Count'],\n    'CLUSTER': ['Pod Status Check', 'Container Restarts'],\n    'PROXY': ['Pod Status Check', 'Node Network Health'],\n    'INFO': ['Quick Cluster Health'],\n    'UNKNOWN': ['Node Conditions', 'Pod Status Check']\n  };\n  return secondaryMap[category] || ['Quick Cluster Health'];\n}\n\n// Enhanced helper function - Cascade check tools (12 categories)\nfunction getCascadeCheckTools(category) {\n  const cascadeTools = {\n    'ETCD': ['Cascading Check Same Namespace', 'Active Alerts Count', 'Quick Cluster Health'],\n    'API': ['Cascading Check Same Namespace', 'Active Alerts Count', 'Quick Cluster Health'],\n    'CERTIFICATE': ['Cascading Check Same Namespace', 'Active Alerts Count'],\n    'INFRASTRUCTURE': ['Cascading Check Same Namespace', 'Active Alerts Count'],\n    'CLUSTER': ['Cascading Check Same Namespace', 'Active Alerts Count'],\n    'NETWORK': ['Cascading Check Same Namespace', 'Active Alerts Count'],\n    'STORAGE': ['Cascading Check Same Namespace', 'Active Alerts Count'],\n    'RESOURCE': ['Active Alerts Count'],\n    'PROXY': ['Active Alerts Count'],\n    'APPLICATION': ['Active Alerts Count'],\n    'MONITORING': ['Active Alerts Count'],\n    'INFO': [],\n    'UNKNOWN': ['Active Alerts Count']\n  };\n  return cascadeTools[category] || ['Active Alerts Count'];\n}\n\n// Preserve all existing stage context with enhancements\noutput.stageContext = {\n  ...output.stageContext,\n  categoryEnhanced: true,\n  alertCategory: alertCategory,\n  urgencyLevel: categoryConfig.urgency,\n  cascadeRisk: getCategoryCascadeRisk(alertCategory),\n  supportedCategories: Object.keys(CATEGORY_TOOL_MAPPINGS).length,\n  csvIntegrated: true\n};\n\n// Enhanced debug logging with comprehensive stats\nconsole.log('Category-based enhancements applied:');\nconsole.log({\n  category: alertCategory,\n  urgency: categoryConfig.urgency,\n  primaryTools: categoryConfig.primaryTools,\n  cascadeRisk: getCategoryCascadeRisk(alertCategory),\n  metricsToCheck: categoryConfig.criticalMetrics.length,\n  expectedIssues: getCategoryExpectedIssues(alertCategory).length,\n  systemPromptEnhanced: true,\n  userMessageEnhanced: true,\n  totalCategories: Object.keys(CATEGORY_TOOL_MAPPINGS).length\n});\n\n// Category statistics for monitoring\nconst categoryStats = {};\nObject.keys(CATEGORY_TOOL_MAPPINGS).forEach(cat => {\n  const config = CATEGORY_TOOL_MAPPINGS[cat];\n  categoryStats[cat] = {\n    urgency: config.urgency,\n    toolCount: config.primaryTools.length,\n    metricCount: config.criticalMetrics.length\n  };\n});\n\nconsole.log('üìä Enhanced Category Statistics:');\nObject.entries(categoryStats).forEach(([cat, stats]) => {\n  console.log(`   ${cat}: ${stats.urgency} (${stats.toolCount} tools, ${stats.metricCount} metrics)`);\n});\n\n// Add enhanced category stats to output\noutput._enhancedCategoryStats = {\n  totalCategories: Object.keys(CATEGORY_TOOL_MAPPINGS).length,\n  categoryBreakdown: categoryStats,\n  currentCategory: {\n    name: alertCategory,\n    urgency: categoryConfig.urgency,\n    cascadeRisk: getCategoryCascadeRisk(alertCategory),\n    toolsCount: categoryConfig.primaryTools.length\n  },\n  csvEnhanced: true,\n  version: '2.0-Complete'\n};\n\nconsole.log('========================================================');\nconsole.log('‚úÖ Enhanced Category Based Metrics Builder Complete!');\nconsole.log(`üìä Supporting ${Object.keys(CATEGORY_TOOL_MAPPINGS).length} categories`);\nconsole.log(`üéØ Current: ${alertCategory} (${categoryConfig.urgency})`);\nconsole.log(`üåä Cascade Risk: ${getCategoryCascadeRisk(alertCategory)}`);\nconsole.log('========================================================');\n\nreturn [output];"
      },
      "id": "93a5a3f4-603f-4c77-9a86-2d5246e1cb7b",
      "name": "Category Based Metrics Builder",
      "type": "n8n-nodes-base.code",
      "position": [
        -3280,
        496
      ],
      "typeVersion": 2
    },
    {
      "parameters": {
        "jsCode": "// Category Based Deep Analysis Enhancer - COMPLETE 320+ Alert Support for Stage 2\n// Enhanced version supporting all 12 categories from Alert Categories Mapper\n// PRESERVES all existing Stage 2 logic, ADDS comprehensive category-specific deep analysis\n\nconst items = $input.all();\nconst inputData = items[0]?.json || {};\n\n// PRESERVE ALL EXISTING DATA\nlet output = { ...inputData };\n\n// Get alert category and context\nconst alertCategory = output.alertCategory || output._context?.alertEnrichment?.category || 'UNKNOWN';\nconst alertName = output._context?.alertContext?.alertName || 'unknown';\nconst stage1Results = output.stage1Results || output.stage1Data || {};\nconst kubernetesFilters = output._context?.kubernetesFilters || {};\n\nconsole.log('========================================================');\nconsole.log('üöÄ ENHANCED Category Based Deep Analysis Enhancer (12 Categories)');\nconsole.log('========================================================');\nconsole.log('üéØ Alert:', alertName);\nconsole.log('üìÇ Category:', alertCategory);\nconsole.log('üìä Stage 1 Status:', stage1Results.overall_status);\nconsole.log('üîç Will proceed to deep analysis');\nconsole.log('========================================================');\n\n// COMPLETE Category-specific deep analysis configurations (12 categories)\nconst CATEGORY_DEEP_ANALYSIS = {\n  // ========== INFRASTRUCTURE CATEGORY ==========\n  'INFRASTRUCTURE': {\n    phases: {\n      instant: {\n        tools: ['Node Resource Status', 'Node Conditions', 'Node Network Health'],\n        focus: 'Check all node-level metrics, conditions, and network status',\n        queries: [\n          'kube_node_status_condition{node=\"' + (kubernetesFilters.node || '.*') + '\"}',\n          'node_memory_MemAvailable_bytes{node=\"' + (kubernetesFilters.node || '.*') + '\"}',\n          'node_filesystem_avail_bytes{node=\"' + (kubernetesFilters.node || '.*') + '\"}'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Compare node metrics over 24h period',\n        queries: [\n          'rate(node_cpu_seconds_total[24h])',\n          'node_memory_MemAvailable_bytes[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Resource Exhaustion Prediction', 'Anomaly Patterns'],\n        focus: 'Predict node resource exhaustion',\n        queries: [\n          'predict_linear(node_filesystem_avail_bytes[1h], 4*3600)',\n          'predict_linear(node_memory_MemAvailable_bytes[1h], 4*3600)'\n        ]\n      }\n    },\n    correlationFocus: 'all_pods_on_node',\n    expectedFindings: ['node_pressure', 'pod_evictions', 'scheduling_failures'],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== APPLICATION CATEGORY ==========\n  'APPLICATION': {\n    phases: {\n      instant: {\n        tools: ['Pod Status Check', 'Container Restarts', 'Pod Resource Usage'],\n        focus: 'Deep dive into pod lifecycle and resource consumption',\n        queries: [\n          'kube_pod_status_phase{pod=\"' + (kubernetesFilters.pod || '.*') + '\"}',\n          'kube_pod_container_status_restarts_total{pod=\"' + (kubernetesFilters.pod || '.*') + '\"}',\n          'container_memory_working_set_bytes{pod=\"' + (kubernetesFilters.pod || '.*') + '\"}'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze pod restart patterns and resource trends',\n        queries: [\n          'rate(kube_pod_container_status_restarts_total[24h])',\n          'container_memory_working_set_bytes[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Resource Exhaustion Prediction'],\n        focus: 'Predict OOM kills and resource exhaustion',\n        queries: [\n          'predict_linear(container_memory_working_set_bytes[1h], 3600)',\n          'stddev_over_time(rate(container_cpu_usage_seconds_total[5m])[2h:])'\n        ]\n      }\n    },\n    correlationFocus: 'deployment_and_service',\n    expectedFindings: ['oom_kills', 'crashloop_backoff', 'image_pull_errors'],\n    urgency: 'HIGH'\n  },\n\n  // ========== RESOURCE CATEGORY ==========\n  'RESOURCE': {\n    phases: {\n      instant: {\n        tools: ['Pod Resource Usage', 'Kubernetes PVC Status'],\n        focus: 'Check resource consumption and limits',\n        queries: [\n          'kubelet_volume_stats_used_bytes',\n          'kubelet_volume_stats_capacity_bytes',\n          'kube_resourcequota'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze resource growth patterns',\n        queries: [\n          'delta(kubelet_volume_stats_used_bytes[24h])',\n          'rate(container_memory_working_set_bytes[24h])'\n        ]\n      },\n      anomaly: {\n        tools: ['Resource Exhaustion Prediction'],\n        focus: 'Predict quota and volume exhaustion',\n        queries: [\n          'predict_linear(kubelet_volume_stats_used_bytes[1h], 24*3600)',\n          '(kube_resourcequota_usage / kube_resourcequota_limit) > 0.8'\n        ]\n      }\n    },\n    correlationFocus: 'namespace_resources',\n    expectedFindings: ['quota_exceeded', 'volume_full', 'resource_pressure'],\n    urgency: 'HIGH'\n  },\n\n  // ========== NETWORK CATEGORY ==========\n  'NETWORK': {\n    phases: {\n      instant: {\n        tools: ['Active Alerts Details', 'Node Network Health'],\n        focus: 'Check network connectivity and endpoints',\n        queries: [\n          'up{job=~\".*' + (kubernetesFilters.service || '') + '.*\"}',\n          'probe_success',\n          'rate(container_network_receive_errors_total[5m])'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze network error patterns',\n        queries: [\n          'rate(container_network_receive_errors_total[24h])',\n          'probe_success[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect network anomalies',\n        queries: [\n          'stddev_over_time(probe_duration_seconds[2h:])',\n          'changes(up[1h])'\n        ]\n      }\n    },\n    correlationFocus: 'service_mesh',\n    expectedFindings: ['endpoint_down', 'network_errors', 'connectivity_loss'],\n    urgency: 'HIGH'\n  },\n\n  // ========== ETCD CATEGORY (MOST CRITICAL) ==========\n  'ETCD': {\n    phases: {\n      instant: {\n        tools: ['Quick Cluster Health', 'Active Alerts Details'],\n        focus: 'üö® BLOCKER: Check etcd cluster health immediately - cluster-breaking issue',\n        queries: [\n          'etcd_server_has_leader',\n          'etcd_server_leader_changes_seen_total',\n          'etcd_disk_wal_fsync_duration_seconds_histogram'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze etcd performance trends',\n        queries: [\n          'rate(etcd_server_leader_changes_seen_total[24h])',\n          'etcd_disk_wal_fsync_duration_seconds[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect etcd consensus issues',\n        queries: [\n          'stddev_over_time(etcd_network_peer_round_trip_time_seconds[2h:])',\n          'rate(etcd_server_proposals_failed_total[1h])'\n        ]\n      }\n    },\n    correlationFocus: 'cluster_control_plane',\n    expectedFindings: ['leader_election', 'disk_latency', 'network_partition'],\n    urgency: 'BLOCKER'\n  },\n\n  // ========== MONITORING CATEGORY ==========\n  'MONITORING': {\n    phases: {\n      instant: {\n        tools: ['Active Alerts Details'],\n        focus: 'Check Prometheus and AlertManager health',\n        queries: [\n          'up{job=\"prometheus\"}',\n          'prometheus_tsdb_head_samples_appended_total',\n          'prometheus_rule_evaluation_failures_total'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Monitoring system performance',\n        queries: [\n          'rate(prometheus_tsdb_head_samples_appended_total[24h])',\n          'prometheus_tsdb_symbol_table_size_bytes[24h]'\n        ]\n      },\n      anomaly: {\n        tools: [],\n        focus: 'Focus on monitoring reliability',\n        queries: []\n      }\n    },\n    correlationFocus: 'observability_stack',\n    expectedFindings: ['scrape_failures', 'storage_issues', 'rule_failures'],\n    urgency: 'MEDIUM'\n  },\n\n  // ========== STORAGE CATEGORY (NEW) ==========\n  'STORAGE': {\n    phases: {\n      instant: {\n        tools: ['Kubernetes PVC Status', 'Pod Resource Usage'],\n        focus: 'Deep dive into storage and volume issues',\n        queries: [\n          'kube_persistentvolume_status_phase',\n          'kube_persistentvolumeclaim_status_phase',\n          'kubelet_volume_stats_available_bytes',\n          'kubelet_volume_stats_capacity_bytes'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze storage usage trends and growth',\n        queries: [\n          'delta(kubelet_volume_stats_used_bytes[24h])',\n          'kubelet_volume_stats_used_bytes[24h]',\n          'rate(kubelet_volume_stats_used_bytes[24h])'\n        ]\n      },\n      anomaly: {\n        tools: ['Resource Exhaustion Prediction'],\n        focus: 'Predict volume exhaustion and attachment issues',\n        queries: [\n          'predict_linear(kubelet_volume_stats_used_bytes[1h], 24*3600)',\n          'predict_linear(kubelet_volume_stats_available_bytes[1h], 24*3600)'\n        ]\n      }\n    },\n    correlationFocus: 'persistent_volumes_and_claims',\n    expectedFindings: ['volume_mounting', 'pvc_binding', 'storage_class_issues', 'disk_space_exhaustion'],\n    urgency: 'HIGH'\n  },\n\n  // ========== API CATEGORY (NEW) ==========\n  'API': {\n    phases: {\n      instant: {\n        tools: ['Quick Cluster Health', 'Active Alerts Details'],\n        focus: 'üö® CRITICAL: Check Kubernetes API server health and performance',\n        queries: [\n          'apiserver_request_total',\n          'apiserver_request_duration_seconds',\n          'apiserver_current_inflight_requests',\n          'up{job=\"apiserver\"}'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze API server performance trends and request patterns',\n        queries: [\n          'rate(apiserver_request_total[24h])',\n          'apiserver_request_duration_seconds[24h]',\n          'rate(apiserver_request_total{code=~\"5..\"}[24h])'\n        ]\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect API server anomalies and performance degradation',\n        queries: [\n          'stddev_over_time(apiserver_request_duration_seconds[2h:])',\n          'changes(apiserver_current_inflight_requests[1h])',\n          'rate(apiserver_request_total{code=~\"5..\"}[1h])'\n        ]\n      }\n    },\n    correlationFocus: 'kubernetes_api_and_control_plane',\n    expectedFindings: ['request_failures', 'authentication_issues', 'rate_limiting', 'api_unavailability'],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== CERTIFICATE CATEGORY ==========\n  'CERTIFICATE': {\n    phases: {\n      instant: {\n        tools: ['Quick Cluster Health'],\n        focus: 'üö® URGENT: Check certificate expiration urgently - authentication critical',\n        queries: [\n          'apiserver_client_certificate_expiration_seconds',\n          'kubelet_certificate_manager_client_ttl_seconds',\n          'kubelet_certificate_manager_server_ttl_seconds'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Track certificate rotation',\n        queries: [\n          'kubelet_certificate_manager_client_ttl_seconds[24h]',\n          'kubelet_certificate_manager_server_ttl_seconds[24h]'\n        ]\n      },\n      anomaly: {\n        tools: [],\n        focus: 'Certificate issues are deterministic, not anomalous',\n        queries: []\n      }\n    },\n    correlationFocus: 'authentication_chain',\n    expectedFindings: ['cert_expiry', 'rotation_failure'],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== CLUSTER CATEGORY ==========\n  'CLUSTER': {\n    phases: {\n      instant: {\n        tools: ['Quick Cluster Health', 'Node Conditions', 'Active Alerts Details'],\n        focus: 'Comprehensive cluster health check',\n        queries: [\n          'up{job=\"kube-state-metrics\"}',\n          'up{job=\"node-exporter\"}',\n          'apiserver_request_duration_seconds_histogram'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Cluster performance trends',\n        queries: [\n          'apiserver_request_duration_seconds[24h]',\n          'scheduler_binding_duration_seconds[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect cluster-wide anomalies',\n        queries: [\n          'stddev_over_time(apiserver_request_duration_seconds[2h:])',\n          'changes(kube_node_status_condition[1h])'\n        ]\n      }\n    },\n    correlationFocus: 'all_components',\n    expectedFindings: ['api_latency', 'scheduler_issues', 'controller_problems'],\n    urgency: 'CRITICAL'\n  },\n\n  // ========== PROXY CATEGORY (NEW) ==========\n  'PROXY': {\n    phases: {\n      instant: {\n        tools: ['Node Network Health', 'Active Alerts Details'],\n        focus: 'Check kube-proxy health and network programming',\n        queries: [\n          'up{job=\"kube-proxy\"}',\n          'kubeproxy_network_programming_duration_seconds',\n          'rest_client_requests_total{job=\"kube-proxy\"}',\n          'kubeproxy_sync_proxy_rules_duration_seconds'\n        ]\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'Analyze kube-proxy performance trends',\n        queries: [\n          'rate(kubeproxy_network_programming_duration_seconds_count[24h])',\n          'kubeproxy_sync_proxy_rules_duration_seconds[24h]'\n        ]\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect proxy performance anomalies',\n        queries: [\n          'stddev_over_time(kubeproxy_network_programming_duration_seconds[2h:])',\n          'changes(up{job=\"kube-proxy\"}[1h])'\n        ]\n      }\n    },\n    correlationFocus: 'service_networking_and_routing',\n    expectedFindings: ['kube_proxy_down', 'service_routing_issues', 'iptables_problems', 'network_programming_delays'],\n    urgency: 'HIGH'\n  },\n\n  // ========== INFO CATEGORY (NEW) ==========\n  'INFO': {\n    phases: {\n      instant: {\n        tools: ['Active Alerts Details'],\n        focus: '‚ÑπÔ∏è INFO: Check informational alerts (expected behavior)',\n        queries: [\n          'ALERTS{severity=\"info\"}',\n          'alertmanager_alerts',\n          'up{job=\"alertmanager\"}'\n        ]\n      },\n      trend: {\n        tools: [],\n        focus: 'Informational alerts do not require trend analysis',\n        queries: []\n      },\n      anomaly: {\n        tools: [],\n        focus: 'Informational alerts are expected, no anomaly detection needed',\n        queries: []\n      }\n    },\n    correlationFocus: 'system_health_notifications',\n    expectedFindings: ['expected_notifications', 'system_status_updates', 'health_check_confirmations'],\n    urgency: 'LOW'\n  },\n\n  // ========== UNKNOWN CATEGORY ==========\n  'UNKNOWN': {\n    phases: {\n      instant: {\n        tools: ['Quick Cluster Health', 'Pod Status Check', 'Active Alerts Details'],\n        focus: 'General health assessment',\n        queries: ['up', 'kube_pod_status_phase', 'kube_node_status_condition']\n      },\n      trend: {\n        tools: ['Historical Comparison 24h'],\n        focus: 'General trend analysis',\n        queries: ['up[24h]']\n      },\n      anomaly: {\n        tools: ['Anomaly Patterns'],\n        focus: 'Detect any anomalies',\n        queries: []\n      }\n    },\n    correlationFocus: 'general',\n    expectedFindings: ['various_issues'],\n    urgency: 'MEDIUM'\n  }\n};\n\n// Get category-specific configuration\nconst categoryConfig = CATEGORY_DEEP_ANALYSIS[alertCategory] || CATEGORY_DEEP_ANALYSIS['UNKNOWN'];\n\n// ENHANCE the prompts for Stage 2 (don't replace)\nif (output.userMessage) {\n  const urgencyEmoji = {\n    'BLOCKER': 'üî•',\n    'CRITICAL': 'üö®',\n    'HIGH': '‚ö†Ô∏è',\n    'MEDIUM': 'üìã',\n    'LOW': '‚ÑπÔ∏è'\n  };\n\n  output.userMessage = output.userMessage + '\\\\n\\\\n' +\n    '=== ENHANCED CATEGORY-SPECIFIC DEEP ANALYSIS ===\\\\n' +\n    `${urgencyEmoji[categoryConfig.urgency]} Alert Category: ${alertCategory} (${categoryConfig.urgency} Priority)\\\\n` +\n    `Alert Name: ${alertName}\\\\n\\\\n` +\n    'PHASE-SPECIFIC INSTRUCTIONS:\\\\n' +\n    `Phase 1 INSTANT - ${categoryConfig.phases.instant.focus}\\\\n` +\n    `  Tools: ${categoryConfig.phases.instant.tools.join(', ')}\\\\n\\\\n` +\n    `Phase 2 TREND - ${categoryConfig.phases.trend.focus}\\\\n` +\n    `  Tools: ${categoryConfig.phases.trend.tools.join(', ')}\\\\n\\\\n` +\n    `Phase 3 ANOMALY - ${categoryConfig.phases.anomaly.focus}\\\\n` +\n    `  Tools: ${categoryConfig.phases.anomaly.tools.join(', ')}\\\\n\\\\n` +\n    `CORRELATION FOCUS: ${categoryConfig.correlationFocus}\\\\n` +\n    `EXPECTED FINDINGS: ${categoryConfig.expectedFindings.join(', ')}`;\n}\n\n// Enhanced category-specific analysis hints\noutput.deepAnalysisHints = {\n  category: alertCategory,\n  urgency: categoryConfig.urgency,\n  phases: categoryConfig.phases,\n  correlationFocus: categoryConfig.correlationFocus,\n  expectedFindings: categoryConfig.expectedFindings,\n  criticalQueries: getAllQueries(categoryConfig),\n  priority: getCategoryAnalysisPriority(alertCategory),\n  totalSupportedCategories: Object.keys(CATEGORY_DEEP_ANALYSIS).length\n};\n\n// Helper function - Collect all queries\nfunction getAllQueries(config) {\n  const queries = [];\n  if (config.phases.instant.queries) queries.push(...config.phases.instant.queries);\n  if (config.phases.trend.queries) queries.push(...config.phases.trend.queries);\n  if (config.phases.anomaly.queries) queries.push(...config.phases.anomaly.queries);\n  return queries;\n}\n\n// Enhanced helper function - Analysis priority (12 categories)\nfunction getCategoryAnalysisPriority(category) {\n  const priorities = {\n    'ETCD': 'BLOCKER',           // Cluster-breaking\n    'API': 'CRITICAL',           // Cluster operations\n    'CERTIFICATE': 'CRITICAL',   // Authentication\n    'INFRASTRUCTURE': 'CRITICAL', // Node failures\n    'CLUSTER': 'CRITICAL',       // Control plane\n    'STORAGE': 'HIGH',           // Data persistence\n    'NETWORK': 'HIGH',           // Connectivity\n    'RESOURCE': 'HIGH',          // Resource management\n    'PROXY': 'HIGH',            // Service routing\n    'APPLICATION': 'HIGH',       // Application health\n    'MONITORING': 'MEDIUM',      // Observability\n    'INFO': 'LOW',              // Informational\n    'UNKNOWN': 'MEDIUM'\n  };\n  return priorities[category] || 'MEDIUM';\n}\n\n// Enhanced root cause patterns for all categories\noutput.categoryRootCausePatterns = getCategoryRootCausePatterns(alertCategory);\n\nfunction getCategoryRootCausePatterns(category) {\n  const patterns = {\n    'INFRASTRUCTURE': [\n      { pattern: 'memory_pressure', indicators: ['MemoryPressure=true', 'memory < 10%'], confidence: 0.9 },\n      { pattern: 'disk_pressure', indicators: ['DiskPressure=true', 'filesystem > 85%'], confidence: 0.9 },\n      { pattern: 'network_partition', indicators: ['NetworkUnavailable=true', 'unreachable'], confidence: 0.85 },\n      { pattern: 'kubelet_failure', indicators: ['kubelet down', 'node not ready'], confidence: 0.9 }\n    ],\n    'APPLICATION': [\n      { pattern: 'oom_killed', indicators: ['OOMKilled', 'Exit Code 137'], confidence: 0.95 },\n      { pattern: 'crashloop_backoff', indicators: ['CrashLoopBackOff', 'restarts > 5'], confidence: 0.9 },\n      { pattern: 'image_pull_error', indicators: ['ImagePullBackOff', 'ErrImagePull'], confidence: 0.95 },\n      { pattern: 'deployment_failure', indicators: ['ProgressDeadlineExceeded', 'replica mismatch'], confidence: 0.9 }\n    ],\n    'RESOURCE': [\n      { pattern: 'quota_exceeded', indicators: ['exceeded quota', 'forbidden'], confidence: 0.95 },\n      { pattern: 'volume_full', indicators: ['volume > 90%', 'no space left'], confidence: 0.95 },\n      { pattern: 'resource_exhausted', indicators: ['limits exceeded', 'cannot allocate'], confidence: 0.9 }\n    ],\n    'NETWORK': [\n      { pattern: 'endpoint_down', indicators: ['connection refused', 'no endpoints'], confidence: 0.9 },\n      { pattern: 'dns_failure', indicators: ['name resolution', 'NXDOMAIN'], confidence: 0.95 },\n      { pattern: 'network_policy', indicators: ['blocked by policy', 'denied'], confidence: 0.9 }\n    ],\n    'ETCD': [\n      { pattern: 'no_leader', indicators: ['has_leader=0', 'election'], confidence: 0.95 },\n      { pattern: 'disk_latency', indicators: ['fsync > 100ms', 'slow disk'], confidence: 0.9 },\n      { pattern: 'split_brain', indicators: ['multiple leaders', 'partition'], confidence: 0.85 },\n      { pattern: 'insufficient_members', indicators: ['quorum lost', 'members < majority'], confidence: 0.98 }\n    ],\n    'MONITORING': [\n      { pattern: 'scrape_failure', indicators: ['scrape error', 'target down'], confidence: 0.9 },\n      { pattern: 'storage_full', indicators: ['TSDB full', 'no space'], confidence: 0.95 },\n      { pattern: 'rule_failure', indicators: ['evaluation error', 'invalid rule'], confidence: 0.9 }\n    ],\n    'STORAGE': [\n      { pattern: 'volume_mount_failure', indicators: ['mount failed', 'volume not available'], confidence: 0.9 },\n      { pattern: 'pvc_binding_issue', indicators: ['pending PVC', 'no matching PV'], confidence: 0.95 },\n      { pattern: 'storage_class_problem', indicators: ['provisioning failed', 'invalid storage class'], confidence: 0.85 },\n      { pattern: 'disk_space_exhaustion', indicators: ['volume full', 'inodes exhausted'], confidence: 0.95 }\n    ],\n    'API': [\n      { pattern: 'api_server_overload', indicators: ['high latency', 'throttled requests'], confidence: 0.85 },\n      { pattern: 'authentication_failure', indicators: ['unauthorized', 'invalid token'], confidence: 0.9 },\n      { pattern: 'api_server_down', indicators: ['connection refused', 'server unavailable'], confidence: 0.98 },\n      { pattern: 'rate_limiting', indicators: ['too many requests', 'rate limited'], confidence: 0.9 }\n    ],\n    'CERTIFICATE': [\n      { pattern: 'cert_expired', indicators: ['certificate expired', 'ttl < 0'], confidence: 0.99 },\n      { pattern: 'rotation_failed', indicators: ['rotation failed', 'unable to rotate'], confidence: 0.95 },\n      { pattern: 'ca_trust_issue', indicators: ['untrusted certificate', 'invalid CA'], confidence: 0.9 }\n    ],\n    'CLUSTER': [\n      { pattern: 'scheduler_failure', indicators: ['scheduling failed', 'unschedulable'], confidence: 0.9 },\n      { pattern: 'controller_error', indicators: ['controller error', 'reconcile failed'], confidence: 0.85 },\n      { pattern: 'control_plane_degradation', indicators: ['multiple components failing'], confidence: 0.8 }\n    ],\n    'PROXY': [\n      { pattern: 'kube_proxy_down', indicators: ['proxy unreachable', 'proxy pod failed'], confidence: 0.95 },\n      { pattern: 'iptables_rules_failure', indicators: ['rules sync failed', 'iptables error'], confidence: 0.9 },\n      { pattern: 'service_routing_issue', indicators: ['service unreachable', 'endpoint not found'], confidence: 0.85 },\n      { pattern: 'network_programming_delay', indicators: ['programming duration high', 'sync slow'], confidence: 0.8 }\n    ],\n    'INFO': [\n      { pattern: 'expected_notification', indicators: ['watchdog', 'health check', 'info severity'], confidence: 1.0 },\n      { pattern: 'system_status_update', indicators: ['status change', 'configuration update'], confidence: 0.9 }\n    ],\n    'UNKNOWN': [\n      { pattern: 'generic_issue', indicators: ['error', 'failed'], confidence: 0.5 }\n    ]\n  };\n  return patterns[category] || patterns['UNKNOWN'];\n}\n\n// Preserve context with comprehensive enhancements\noutput._context = {\n  ...output._context,\n  deepAnalysisEnhanced: true,\n  analysisCategory: alertCategory,\n  analysisUrgency: categoryConfig.urgency,\n  analysisPriority: getCategoryAnalysisPriority(alertCategory),\n  rootCausePatterns: output.categoryRootCausePatterns,\n  totalCategories: Object.keys(CATEGORY_DEEP_ANALYSIS).length,\n  csvIntegrated: true\n};\n\n// Enhanced debug logging\nconsole.log('Enhanced Deep Analysis Configuration:');\nconsole.log({\n  category: alertCategory,\n  urgency: categoryConfig.urgency,\n  priority: getCategoryAnalysisPriority(alertCategory),\n  phasesConfigured: true,\n  rootCausePatternsAdded: output.categoryRootCausePatterns.length,\n  correlationFocus: categoryConfig.correlationFocus,\n  expectedFindings: categoryConfig.expectedFindings.length,\n  totalQueries: getAllQueries(categoryConfig).length,\n  totalCategories: Object.keys(CATEGORY_DEEP_ANALYSIS).length\n});\n\n// Category statistics for monitoring\nconst categoryStats = {};\nObject.entries(CATEGORY_DEEP_ANALYSIS).forEach(([cat, config]) => {\n  categoryStats[cat] = {\n    urgency: config.urgency,\n    toolsCount: config.phases.instant.tools.length + config.phases.trend.tools.length + config.phases.anomaly.tools.length,\n    queriesCount: getAllQueries(config).length,\n    findingsCount: config.expectedFindings.length\n  };\n});\n\nconsole.log('üìä Enhanced Category Statistics:');\nObject.entries(categoryStats).forEach(([cat, stats]) => {\n  console.log(`   ${cat}: ${stats.urgency} (${stats.toolsCount} tools, ${stats.queriesCount} queries, ${stats.findingsCount} findings)`);\n});\n\n// Add enhanced category stats to output\noutput._enhancedDeepAnalysisStats = {\n  totalCategories: Object.keys(CATEGORY_DEEP_ANALYSIS).length,\n  categoryBreakdown: categoryStats,\n  currentCategory: {\n    name: alertCategory,\n    urgency: categoryConfig.urgency,\n    priority: getCategoryAnalysisPriority(alertCategory),\n    phasesCount: 3,\n    expectedFindings: categoryConfig.expectedFindings.length\n  },\n  csvEnhanced: true,\n  version: '2.0-Complete'\n};\n\nconsole.log('========================================================');\nconsole.log('‚úÖ Enhanced Deep Analysis Enhancer Complete!');\nconsole.log(`üìä Supporting ${Object.keys(CATEGORY_DEEP_ANALYSIS).length} categories`);\nconsole.log(`üéØ Current: ${alertCategory} (${categoryConfig.urgency})`);\nconsole.log(`üîç Expected Findings: ${categoryConfig.expectedFindings.length}`);\nconsole.log('========================================================');\n\nreturn [output];"
      },
      "id": "e0470695-323b-4935-ad71-123de52a1ac5",
      "name": "Category Based Deep Analysis Enhancer",
      "type": "n8n-nodes-base.code",
      "position": [
        -1808,
        576
      ],
      "typeVersion": 2
    }
  ],
  "pinData": {
    "Manual Trigger": [
      {
        "json": {}
      }
    ]
  },
  "connections": {
    "When chat message received": {
      "main": [
        [
          {
            "node": "Unified Entry Point",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "AlertManager Webhook": {
      "main": [
        [
          {
            "node": "Unified Entry Point",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Unified Entry Point": {
      "main": [
        [
          {
            "node": "Alert Categories Mapper",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1: Health Snapshot": {
      "main": [
        [
          {
            "node": "Fix Stage 1 Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 2 Decision": {
      "main": [
        [
          {
            "node": "Route After Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route After Decision": {
      "main": [
        [
          {
            "node": "Force Deep Analysis Override",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Generate Final Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 3s": {
      "main": [
        [
          {
            "node": "Category Based Deep Analysis Enhancer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 2: Deep Analysis": {
      "main": [
        [
          {
            "node": "Fix Stage2 Json",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 3: Alert Intelligence": {
      "main": [
        [
          {
            "node": "Stage 3 Formater",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 4: Automated Diagnosis": {
      "main": [
        [
          {
            "node": "Fix Stage 4 Json",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 5: Smart Remediation": {
      "main": [
        [
          {
            "node": "Fix Stage 5 Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 6: Prevention & Learning": {
      "main": [
        [
          {
            "node": "Generate Final Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 1 Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Stage 1: Health Snapshot",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Stage 6 Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Stage 6: Prevention & Learning",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Quick Cluster Health": {
      "ai_tool": [
        [
          {
            "node": "Stage 1: Health Snapshot",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Active Alerts Count": {
      "ai_tool": [
        [
          {
            "node": "Stage 1: Health Snapshot",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Node Resource Status": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Pod Status Check": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Node Conditions": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Node Network Health": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Container Restarts": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Pod Resource Usage": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Application Metrics": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "HTTP Error Rates": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Historical Comparison 24h": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Resource Exhaustion Prediction": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Anomaly Patterns": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Active Alerts Details": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Alert History 24h": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Stage 5: Smart Remediation",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Stage 6: Prevention & Learning",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Stage 1: Health Snapshot",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Kubernetes PVC Status": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Kubernetes HPA Status": {
      "ai_tool": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Manual Trigger": {
      "main": [
        [
          {
            "node": "Prometheus Input Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Force Deep Analysis Override": {
      "main": [
        [
          {
            "node": "Wait 3s",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Stage 1 Input": {
      "main": [
        [
          {
            "node": "Category Based Metrics Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 1 Context": {
      "main": [
        [
          {
            "node": "Stage 2 Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 2 Context": {
      "main": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 4 Context": {
      "main": [
        [
          {
            "node": "Stage 5: Smart Remediation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 5 Context": {
      "main": [
        [
          {
            "node": "Stage 6: Prevention & Learning",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pod Ready SLO": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Container Running SLO": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Node Ready SLO": {
      "ai_tool": [
        []
      ]
    },
    "Pod Restart Rate SLO": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Deployment Replica Health": {
      "ai_tool": [
        [
          {
            "node": "Stage 3: Alert Intelligence",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Load Alert Knowledge Base": {
      "main": [
        [
          {
            "node": "Prepare Stage 1 Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Stage 4: Automated Diagnosis",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage2 Json": {
      "main": [
        [
          {
            "node": "Fix Stage 2 Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 4 Json": {
      "main": [
        [
          {
            "node": "Fix Stage 4 Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prometheus Query Builder": {
      "main": [
        [
          {
            "node": "Unified Entry Point",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Stage 3 Formater": {
      "main": [
        [
          {
            "node": "Fix Stage 3 Context1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fix Stage 3 Context1": {
      "main": [
        [
          {
            "node": "Stage 4: Automated Diagnosis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prometheus Input Handler": {
      "main": [
        [
          {
            "node": "Prometheus Query Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cascading Check Same Namespace": {
      "ai_tool": [
        [
          {
            "node": "Stage 1: Health Snapshot",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Alert Categories Mapper": {
      "main": [
        [
          {
            "node": "Load Alert Knowledge Base",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Category Based Metrics Builder": {
      "main": [
        [
          {
            "node": "Stage 1: Health Snapshot",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Category Based Deep Analysis Enhancer": {
      "main": [
        [
          {
            "node": "Stage 2: Deep Analysis",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "df677935-416e-4953-9f28-a8c196507ea6",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "c12c7bb55b80ebd9de9957d4bb20d1c257c60ff78d5439f6278d6225d0d15a7b"
  },
  "id": "LBDqj72azAqepcuC",
  "tags": []
}