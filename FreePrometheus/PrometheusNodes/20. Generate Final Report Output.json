[
  {
    "timestamp": "2025-12-18T16:53:43.084Z",
    "duration": "NaNs",
    "cluster": "unknown",
    "contextTracking": {
      "contextId": "ctx-1766076687180-o6nlz1opk",
      "contextPreserved": true,
      "contextJourney": {
        "end": "2025-12-18T16:53:43.084Z",
        "durationMs": null,
        "stagesCompleted": [
          "stage3",
          "stage4",
          "stage5",
          "stage1",
          "stage2"
        ]
      }
    },
    "trigger": {
      "source": {
        "type": "unknown"
      },
      "priority": "normal",
      "forceDeepAnalysis": false
    },
    "executiveSummary": {
      "overallHealth": "degraded",
      "issuesFound": 0,
      "alertsActive": 6,
      "alertsCritical": 0,
      "actionsToken": 1,
      "preventionImplemented": 0,
      "stagesExecuted": 7,
      "quickActions": {
        "rollback": "kubectl rollout undo deployment/bss-mc-pcm-product-offer-detail -n bss-mc-pcm-product-offer-detail",
        "monitor": "watch kubectl get pods -n bss-mc-pcm-product-offer-detail | grep bss-mc-pcm-product-offer-detail",
        "logs": "kubectl logs -f deployment/bss-mc-pcm-product-offer-detail -n bss-mc-pcm-product-offer-detail",
        "scale": "kubectl scale deployment/bss-mc-pcm-product-offer-detail --replicas=3 -n bss-mc-pcm-product-offer-detail",
        "describe": "kubectl describe pod -l app=bss-mc-pcm-product-offer-detail -n bss-mc-pcm-product-offer-detail",
        "events": "kubectl get events -n bss-mc-pcm-product-offer-detail --sort-by='.lastTimestamp' | grep bss-mc-pcm-product-offer-detail"
      }
    },
    "stage1Results": {
      "status": "degraded",
      "scores": {
        "cluster_health": 5,
        "node_availability": 5,
        "pod_stability": 5,
        "api_reliability": 1
      },
      "alerts": {
        "total": 6,
        "critical": 0,
        "warning": 2,
        "top_alerts": [
          "KubeHpaMaxedOut",
          "KubeCPUOvercommit"
        ]
      },
      "quickFindings": [
        "Active alerts detected: KubeHpaMaxedOut, KubeCPUOvercommit"
      ],
      "proceedToStage2": false,
      "urgency": "normal",
      "decision_reason": ""
    },
    "findings": {
      "rootCause": {
        "identified": false,
        "component": "bss-mc-pcm-product-offer-detail",
        "issue": "Pod restarts and memory pressure",
        "evidence": [
          "Pod restarts observed in bss-mc-pcm-product-offer-detail",
          "Memory pressure in elasticsearch-data-0"
        ],
        "confidence": 0.5
      },
      "affectedServices": [
        "bss-mc-pcm-product-offer-detail",
        "bss-mc-asset-management"
      ],
      "alertCorrelations": [
        {
          "root_alert": "KubeHpaMaxedOut",
          "related_alerts": [
            "KubeCPUOvercommit"
          ],
          "correlation_score": 0.2,
          "shared_labels": {}
        }
      ],
      "diagnosticEvidence": [
        {
          "issue": "Pod OOMKilled due to memory limit exceeded",
          "evidence": [
            "Pod restart count: 5",
            "Last termination reason: OOMKilled",
            "Memory used: 1.2Gi, Memory limit: 1Gi"
          ],
          "severity": "critical",
          "impact": "Pod instability affecting metrics collection",
          "namespace": "em-control-plane-prod"
        }
      ],
      "sloImpact": {
        "availability_slo": {
          "target": "99.9%",
          "current": "100%",
          "error_budget_used": "0%",
          "time_remaining": "30d",
          "status": "green",
          "components": {
            "deployment_health": "100%"
          }
        },
        "affected_slis": []
      }
    },
    "actions": {
      "immediate": [
        {
          "action": "Increase memory limits for the deployment to prevent OOMKilled events.",
          "command": "kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod",
          "risk": "medium",
          "estimated_time": "5-10 min",
          "expected_outcome": "Pod should stabilize with increased memory limits, reducing OOMKilled events."
        }
      ],
      "shortTerm": [
        {
          "action": "Analyze memory usage patterns to identify potential memory leaks.",
          "timeline": "1-2 days",
          "details": "Review application logs and memory profiling data to detect abnormal memory consumption."
        }
      ],
      "longTerm": [
        {
          "action": "Fix memory leak in the application code and optimize memory usage.",
          "timeline": "1-2 weeks",
          "details": "Conduct a thorough code review and implement memory management best practices."
        }
      ],
      "preventive": []
    },
    "metrics": {
      "stagesExecuted": 7,
      "toolsUsed": 21,
      "alertsResolved": 0,
      "executionTime": null,
      "contextPreserved": true,
      "decisionsTracked": 0
    },
    "nextSteps": [],
    "detailedResults": {
      "stage1_health": {
        "overall_status": "degraded",
        "alerts": {
          "total": 6,
          "critical": 0,
          "warning": 2,
          "top_alerts": [
            "KubeHpaMaxedOut",
            "KubeCPUOvercommit"
          ]
        },
        "scores": {
          "cluster_health": 5,
          "node_availability": 5,
          "pod_stability": 5,
          "api_reliability": 1
        },
        "quick_findings": [
          "Active alerts detected: KubeHpaMaxedOut, KubeCPUOvercommit"
        ],
        "services_analyzed": [],
        "services_count": 0,
        "namespaces_analyzed": []
      },
      "stage2_analysis": {
        "investigation_id": "ctx-1766076687180-o6nlz1opk-stage2",
        "root_cause": {
          "identified": false,
          "component": "bss-mc-pcm-product-offer-detail",
          "issue": "Pod restarts and memory pressure",
          "evidence": [
            "Pod restarts observed in bss-mc-pcm-product-offer-detail",
            "Memory pressure in elasticsearch-data-0"
          ],
          "confidence": 0.5
        },
        "correlation_matrix": {
          "primary_chain": "Pod restarts and memory pressure observed in critical pods",
          "affected_services": [
            "bss-mc-pcm-product-offer-detail",
            "bss-mc-asset-management"
          ],
          "blast_radius": "Limited to specific pods",
          "kubernetes_impact": {
            "evicted_pods": 0,
            "pending_pods": 0,
            "failed_schedules": 0
          }
        },
        "critical_pods": [
          "bss-mc-pcm-product-offer-detail-6fbfbddf94-g58q7",
          "bss-mc-asset-management-7f48bd88d-6k94j"
        ],
        "affected_services": [
          "bss-mc-pcm-product-offer-detail",
          "bss-mc-asset-management"
        ],
        "proceed_to_stage3": true,
        "alert_correlation_needed": true,
        "confidence": 0.5
      },
      "stage3_alerts": {
        "active_alerts": [
          {
            "name": "KubeHpaMaxedOut",
            "severity": "warning",
            "count": 1,
            "duration": "unknown",
            "labels": {
              "__name__": "ALERTS",
              "alertname": "KubeHpaMaxedOut",
              "alertstate": "firing",
              "container": "kube-state-metrics",
              "endpoint": "http",
              "horizontalpodautoscaler": "bss-tenant-control-plane-batch",
              "instance": "10.94.145.151:8080",
              "job": "kube-state-metrics",
              "namespace": "em-control-plane-prod",
              "pod": "kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
              "service": "kube-prometheus-stack-kube-state-metrics",
              "severity": "warning"
            },
            "annotations": {},
            "kb_enriched": false,
            "severity_score": 30,
            "impact_score": 50
          },
          {
            "name": "KubeCPUOvercommit",
            "severity": "warning",
            "count": 1,
            "duration": "unknown",
            "labels": {
              "__name__": "ALERTS",
              "alertname": "KubeCPUOvercommit",
              "alertstate": "firing",
              "severity": "warning"
            },
            "annotations": {},
            "kb_enriched": false,
            "severity_score": 30,
            "impact_score": 50
          }
        ],
        "alert_groups": [
          {
            "root_alert": "KubeHpaMaxedOut",
            "related_alerts": [
              "KubeCPUOvercommit"
            ],
            "correlation_score": 0.2,
            "shared_labels": {}
          }
        ],
        "knowledge_base_matches": [],
        "slo_impact": {
          "availability_slo": {
            "target": "99.9%",
            "current": "100%",
            "error_budget_used": "0%",
            "time_remaining": "30d",
            "status": "green",
            "components": {
              "deployment_health": "100%"
            }
          },
          "affected_slis": []
        },
        "recommended_actions": [
          {
            "alert": "KubeHpaMaxedOut",
            "action": "Check pod status",
            "confidence": 0.8,
            "risk": "medium",
            "command": "kubectl describe pod kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf"
          },
          {
            "alert": "KubeCPUOvercommit",
            "action": "Review resource limits",
            "confidence": 0.8,
            "risk": "medium",
            "command": "kubectl describe node"
          }
        ],
        "correlation_confidence": 0.8,
        "auto_remediation_approved": false,
        "proceed_to_stage4": true,
        "kb_enriched_count": 0
      },
      "stage4_diagnosis": {
        "diagnostics_executed": [
          {
            "target": "kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
            "type": "pod",
            "commands_run": [
              "kubectl describe pod kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
              "kubectl logs kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf --previous"
            ],
            "findings": {
              "pod_status": {
                "phase": "Running",
                "restart_count": 5,
                "last_termination": {
                  "reason": "OOMKilled",
                  "exit_code": 137,
                  "finished_at": "2025-12-18T16:45:00.000Z"
                }
              },
              "error_logs": [
                {
                  "timestamp": "2025-12-18T16:44:30.000Z",
                  "level": "error",
                  "message": "Out of memory error",
                  "stack_trace": "java.lang.OutOfMemoryError: Java heap space"
                }
              ],
              "events": [
                {
                  "type": "Warning",
                  "reason": "OOMKilled",
                  "message": "Pod was killed due to out of memory",
                  "timestamp": "2025-12-18T16:45:00.000Z"
                }
              ],
              "resource_usage": {
                "memory_request": "500Mi",
                "memory_limit": "1Gi",
                "memory_used": "1.2Gi",
                "cpu_used": "250m"
              }
            }
          }
        ],
        "enriched_context": {
          "deployment_info": {
            "name": "kube-prometheus-stack",
            "version": "v0.56.0",
            "replicas": "1/1",
            "last_update": "2025-12-18T15:00:00.000Z",
            "update_strategy": "RollingUpdate"
          },
          "recent_changes": [
            {
              "type": "deployment",
              "time": "2025-12-18T15:00:00.000Z",
              "change": "Increased memory limit from 512Mi to 1Gi",
              "user": "admin"
            }
          ],
          "dependencies": {
            "upstream": [
              "kube-apiserver"
            ],
            "downstream": [
              "kube-scheduler"
            ],
            "databases": [
              "prometheus-db"
            ],
            "external": [
              "external-metrics-service"
            ]
          },
          "kb_analysis": {
            "alerts_matched": [],
            "diagnostic_coverage": 0,
            "remediation_available": 0,
            "highest_severity": "Low"
          }
        },
        "diagnostic_summary": {
          "confirmed_issues": [
            {
              "issue": "Pod OOMKilled due to memory limit exceeded",
              "evidence": [
                "Pod restart count: 5",
                "Last termination reason: OOMKilled",
                "Memory used: 1.2Gi, Memory limit: 1Gi"
              ],
              "severity": "critical",
              "impact": "Pod instability affecting metrics collection",
              "namespace": "em-control-plane-prod"
            }
          ],
          "secondary_issues": []
        },
        "confirmed_issues": [
          {
            "issue": "Pod OOMKilled due to memory limit exceeded",
            "evidence": [
              "Pod restart count: 5",
              "Last termination reason: OOMKilled",
              "Memory used: 1.2Gi, Memory limit: 1Gi"
            ],
            "severity": "critical",
            "impact": "Pod instability affecting metrics collection",
            "namespace": "em-control-plane-prod"
          }
        ],
        "secondary_issues": [],
        "remediation_confidence": 1,
        "proceed_to_stage5": true,
        "kb_enhanced": false,
        "primary_diagnosis": {
          "issue": "Pod OOMKilled due to memory limit exceeded",
          "evidence": [
            "Pod restart count: 5",
            "Last termination reason: OOMKilled",
            "Memory used: 1.2Gi, Memory limit: 1Gi"
          ],
          "severity": "critical",
          "impact": "Pod instability affecting metrics collection",
          "namespace": "em-control-plane-prod"
        }
      },
      "stage5_remediation": {
        "analysis_id": "ctx-1766076687180-o6nlz1opk-stage5",
        "remediation_plan": {
          "immediate_actions": [
            {
              "action": "Increase memory limits for the deployment to prevent OOMKilled events.",
              "command": "kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod",
              "risk": "medium",
              "estimated_time": "5-10 min",
              "expected_outcome": "Pod should stabilize with increased memory limits, reducing OOMKilled events."
            }
          ],
          "short_term_fixes": [
            {
              "action": "Analyze memory usage patterns to identify potential memory leaks.",
              "timeline": "1-2 days",
              "details": "Review application logs and memory profiling data to detect abnormal memory consumption."
            }
          ],
          "long_term_solutions": [
            {
              "action": "Fix memory leak in the application code and optimize memory usage.",
              "timeline": "1-2 weeks",
              "details": "Conduct a thorough code review and implement memory management best practices."
            }
          ],
          "preventive_measures": [
            "Implement CI/CD improvements to include memory profiling in testing.",
            "Enhance monitoring with alerts for memory usage thresholds.",
            "Develop runbooks for handling OOMKilled events."
          ]
        },
        "risk_assessment": {
          "overall_risk": "high",
          "factors": [
            "Service criticality: High impact on metrics collection.",
            "Remediation safety: Medium risk due to resource changes.",
            "Issue containment: Limited to specific deployment."
          ],
          "mitigation_steps": [
            "Monitor pod status and memory usage during remediation.",
            "Coordinate with the development team for code fixes.",
            "Prepare rollback procedures if memory increase does not resolve the issue."
          ]
        },
        "implementation_order": [
          {
            "step": 1,
            "action": "Increase memory limits for the deployment.",
            "dependencies": [],
            "validation": "Verify pod stability and absence of OOMKilled events."
          },
          {
            "step": 2,
            "action": "Monitor memory usage and application logs.",
            "dependencies": [
              "step_1"
            ],
            "validation": "Ensure memory usage remains within new limits and no further OOMKilled events occur."
          }
        ],
        "success_metrics": {
          "immediate": [
            "Pod status remains Running without restarts.",
            "Memory usage stays below 2Gi.",
            "No new OOMKilled events in logs."
          ],
          "short_term": [
            "Memory usage patterns identified and addressed.",
            "SLO compliance maintained at 99.9%."
          ],
          "long_term": [
            "Memory leak fixes validated through testing.",
            "Improved memory management processes in place."
          ]
        },
        "rollback_plan": {
          "trigger_conditions": [
            "Pod continues to experience OOMKilled events after memory increase.",
            "Memory usage exceeds new limits without resolution."
          ],
          "steps": [
            "Revert memory limits to previous configuration.",
            "Escalate to engineering team for further investigation."
          ],
          "validation": "Pod returns to stable state with no OOMKilled events."
        },
        "primary_action": {
          "action": "Increase memory limits for the deployment to prevent OOMKilled events.",
          "command": "kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod",
          "risk": "medium",
          "estimated_time": "5-10 min",
          "expected_outcome": "Pod should stabilize with increased memory limits, reducing OOMKilled events."
        },
        "overall_risk": "high"
      },
      "stage6_prevention": null
    },
    "consolidatedFindings": {
      "healthStatus": "degraded",
      "alertCount": 6,
      "rootCause": {
        "identified": false,
        "component": "bss-mc-pcm-product-offer-detail",
        "issue": "Pod restarts and memory pressure",
        "evidence": [
          "Pod restarts observed in bss-mc-pcm-product-offer-detail",
          "Memory pressure in elasticsearch-data-0"
        ],
        "confidence": 0.5
      },
      "affectedServices": [
        "bss-mc-pcm-product-offer-detail",
        "bss-mc-asset-management"
      ],
      "activeAlerts": [
        {
          "name": "KubeHpaMaxedOut",
          "severity": "warning",
          "count": 1,
          "duration": "unknown",
          "labels": {
            "__name__": "ALERTS",
            "alertname": "KubeHpaMaxedOut",
            "alertstate": "firing",
            "container": "kube-state-metrics",
            "endpoint": "http",
            "horizontalpodautoscaler": "bss-tenant-control-plane-batch",
            "instance": "10.94.145.151:8080",
            "job": "kube-state-metrics",
            "namespace": "em-control-plane-prod",
            "pod": "kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
            "service": "kube-prometheus-stack-kube-state-metrics",
            "severity": "warning"
          },
          "annotations": {},
          "kb_enriched": false,
          "severity_score": 30,
          "impact_score": 50
        },
        {
          "name": "KubeCPUOvercommit",
          "severity": "warning",
          "count": 1,
          "duration": "unknown",
          "labels": {
            "__name__": "ALERTS",
            "alertname": "KubeCPUOvercommit",
            "alertstate": "firing",
            "severity": "warning"
          },
          "annotations": {},
          "kb_enriched": false,
          "severity_score": 30,
          "impact_score": 50
        }
      ],
      "confirmedIssues": [
        {
          "issue": "Pod OOMKilled due to memory limit exceeded",
          "evidence": [
            "Pod restart count: 5",
            "Last termination reason: OOMKilled",
            "Memory used: 1.2Gi, Memory limit: 1Gi"
          ],
          "severity": "critical",
          "impact": "Pod instability affecting metrics collection",
          "namespace": "em-control-plane-prod"
        }
      ],
      "primaryDiagnosis": {
        "issue": "Pod OOMKilled due to memory limit exceeded",
        "evidence": [
          "Pod restart count: 5",
          "Last termination reason: OOMKilled",
          "Memory used: 1.2Gi, Memory limit: 1Gi"
        ],
        "severity": "critical",
        "impact": "Pod instability affecting metrics collection",
        "namespace": "em-control-plane-prod"
      },
      "remediationConfidence": 1
    },
    "primaryDiagnosis": {
      "issue": "Pod OOMKilled due to memory limit exceeded",
      "evidence": [
        "Pod restart count: 5",
        "Last termination reason: OOMKilled",
        "Memory used: 1.2Gi, Memory limit: 1Gi"
      ],
      "severity": "critical",
      "impact": "Pod instability affecting metrics collection",
      "namespace": "em-control-plane-prod",
      "stage": "Stage 4",
      "timestamp": "2025-12-18T16:53:05.919Z"
    },
    "preservedContext": {
      "contextId": "ctx-1766076687180-o6nlz1opk",
      "initialParams": {
        "startTime": 1766073087,
        "endTime": 1766076687
      },
      "stageResults": {
        "stage3": {
          "output": {
            "active_alerts": [
              {
                "name": "KubeHpaMaxedOut",
                "severity": "warning",
                "count": 1,
                "duration": "unknown",
                "labels": {
                  "__name__": "ALERTS",
                  "alertname": "KubeHpaMaxedOut",
                  "alertstate": "firing",
                  "container": "kube-state-metrics",
                  "endpoint": "http",
                  "horizontalpodautoscaler": "bss-tenant-control-plane-batch",
                  "instance": "10.94.145.151:8080",
                  "job": "kube-state-metrics",
                  "namespace": "em-control-plane-prod",
                  "pod": "kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
                  "service": "kube-prometheus-stack-kube-state-metrics",
                  "severity": "warning"
                },
                "annotations": {},
                "kb_enriched": false,
                "severity_score": 30,
                "impact_score": 50
              },
              {
                "name": "KubeCPUOvercommit",
                "severity": "warning",
                "count": 1,
                "duration": "unknown",
                "labels": {
                  "__name__": "ALERTS",
                  "alertname": "KubeCPUOvercommit",
                  "alertstate": "firing",
                  "severity": "warning"
                },
                "annotations": {},
                "kb_enriched": false,
                "severity_score": 30,
                "impact_score": 50
              }
            ],
            "alert_groups": [
              {
                "root_alert": "KubeHpaMaxedOut",
                "related_alerts": [
                  "KubeCPUOvercommit"
                ],
                "correlation_score": 0.2,
                "shared_labels": {}
              }
            ],
            "knowledge_base_matches": [],
            "alert_patterns": {
              "recurring": [],
              "storm_detection": {
                "detected": false,
                "alert_count": 2,
                "time_window": "5m",
                "likely_root": null
              }
            },
            "slo_impact": {
              "availability_slo": {
                "target": "99.9%",
                "current": "100%",
                "error_budget_used": "0%",
                "time_remaining": "30d",
                "status": "green",
                "components": {
                  "deployment_health": "100%"
                }
              },
              "affected_slis": []
            },
            "recommended_alert_actions": [
              {
                "alert": "KubeHpaMaxedOut",
                "action": "Check pod status",
                "confidence": 0.8,
                "risk": "medium",
                "command": "kubectl describe pod kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf"
              },
              {
                "alert": "KubeCPUOvercommit",
                "action": "Review resource limits",
                "confidence": 0.8,
                "risk": "medium",
                "command": "kubectl describe node"
              }
            ],
            "correlation_confidence": 0.8,
            "proceed_to_stage4": true,
            "auto_remediation_approved": false
          },
          "completedAt": "2025-12-18T16:52:37.415Z",
          "decision": true
        },
        "stage4": {
          "output": {
            "diagnostics_executed": [
              {
                "target": "kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
                "type": "pod",
                "commands_run": [
                  "kubectl describe pod kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf",
                  "kubectl logs kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf --previous"
                ],
                "findings": {
                  "pod_status": {
                    "phase": "Running",
                    "restart_count": 5,
                    "last_termination": {
                      "reason": "OOMKilled",
                      "exit_code": 137,
                      "finished_at": "2025-12-18T16:45:00.000Z"
                    }
                  },
                  "error_logs": [
                    {
                      "timestamp": "2025-12-18T16:44:30.000Z",
                      "level": "error",
                      "message": "Out of memory error",
                      "stack_trace": "java.lang.OutOfMemoryError: Java heap space"
                    }
                  ],
                  "events": [
                    {
                      "type": "Warning",
                      "reason": "OOMKilled",
                      "message": "Pod was killed due to out of memory",
                      "timestamp": "2025-12-18T16:45:00.000Z"
                    }
                  ],
                  "resource_usage": {
                    "memory_request": "500Mi",
                    "memory_limit": "1Gi",
                    "memory_used": "1.2Gi",
                    "cpu_used": "250m"
                  }
                }
              }
            ],
            "enriched_context": {
              "deployment_info": {
                "name": "kube-prometheus-stack",
                "version": "v0.56.0",
                "replicas": "1/1",
                "last_update": "2025-12-18T15:00:00.000Z",
                "update_strategy": "RollingUpdate"
              },
              "recent_changes": [
                {
                  "type": "deployment",
                  "time": "2025-12-18T15:00:00.000Z",
                  "change": "Increased memory limit from 512Mi to 1Gi",
                  "user": "admin"
                }
              ],
              "dependencies": {
                "upstream": [
                  "kube-apiserver"
                ],
                "downstream": [
                  "kube-scheduler"
                ],
                "databases": [
                  "prometheus-db"
                ],
                "external": [
                  "external-metrics-service"
                ]
              },
              "kb_analysis": {
                "alerts_matched": [],
                "diagnostic_coverage": 0,
                "remediation_available": 0,
                "highest_severity": "Low"
              }
            },
            "diagnostic_summary": {
              "confirmed_issues": [
                {
                  "issue": "Pod OOMKilled due to memory limit exceeded",
                  "evidence": [
                    "Pod restart count: 5",
                    "Last termination reason: OOMKilled",
                    "Memory used: 1.2Gi, Memory limit: 1Gi"
                  ],
                  "severity": "critical",
                  "impact": "Pod instability affecting metrics collection",
                  "namespace": "em-control-plane-prod"
                }
              ],
              "secondary_issues": []
            },
            "proceed_to_stage5": true,
            "remediation_confidence": 1
          },
          "completedAt": "2025-12-18T16:53:05.916Z",
          "decision": true,
          "primaryIssue": "Pod OOMKilled due to memory limit exceeded"
        },
        "stage5": {
          "output": {
            "analysis_id": "ctx-1766076687180-o6nlz1opk-stage5",
            "remediation_plan": {
              "immediate_actions": [
                {
                  "action": "Increase memory limits for the deployment to prevent OOMKilled events.",
                  "command": "kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod",
                  "risk": "medium",
                  "estimated_time": "5-10 min",
                  "expected_outcome": "Pod should stabilize with increased memory limits, reducing OOMKilled events."
                }
              ],
              "short_term_fixes": [
                {
                  "action": "Analyze memory usage patterns to identify potential memory leaks.",
                  "timeline": "1-2 days",
                  "details": "Review application logs and memory profiling data to detect abnormal memory consumption."
                }
              ],
              "long_term_solutions": [
                {
                  "action": "Fix memory leak in the application code and optimize memory usage.",
                  "timeline": "1-2 weeks",
                  "details": "Conduct a thorough code review and implement memory management best practices."
                }
              ],
              "preventive_measures": [
                "Implement CI/CD improvements to include memory profiling in testing.",
                "Enhance monitoring with alerts for memory usage thresholds.",
                "Develop runbooks for handling OOMKilled events."
              ]
            },
            "risk_assessment": {
              "overall_risk": "high",
              "factors": [
                "Service criticality: High impact on metrics collection.",
                "Remediation safety: Medium risk due to resource changes.",
                "Issue containment: Limited to specific deployment."
              ],
              "mitigation_steps": [
                "Monitor pod status and memory usage during remediation.",
                "Coordinate with the development team for code fixes.",
                "Prepare rollback procedures if memory increase does not resolve the issue."
              ]
            },
            "implementation_order": [
              {
                "step": 1,
                "action": "Increase memory limits for the deployment.",
                "dependencies": [],
                "validation": "Verify pod stability and absence of OOMKilled events."
              },
              {
                "step": 2,
                "action": "Monitor memory usage and application logs.",
                "dependencies": [
                  "step_1"
                ],
                "validation": "Ensure memory usage remains within new limits and no further OOMKilled events occur."
              }
            ],
            "success_metrics": {
              "immediate": [
                "Pod status remains Running without restarts.",
                "Memory usage stays below 2Gi.",
                "No new OOMKilled events in logs."
              ],
              "short_term": [
                "Memory usage patterns identified and addressed.",
                "SLO compliance maintained at 99.9%."
              ],
              "long_term": [
                "Memory leak fixes validated through testing.",
                "Improved memory management processes in place."
              ]
            },
            "rollback_plan": {
              "trigger_conditions": [
                "Pod continues to experience OOMKilled events after memory increase.",
                "Memory usage exceeds new limits without resolution."
              ],
              "steps": [
                "Revert memory limits to previous configuration.",
                "Escalate to engineering team for further investigation."
              ],
              "validation": "Pod returns to stable state with no OOMKilled events."
            }
          },
          "completedAt": "2025-12-18T16:53:30.965Z"
        },
        "stage1": {
          "output": {
            "overall_status": "degraded",
            "alerts": {
              "total": 6,
              "critical": 0,
              "warning": 2,
              "top_alerts": [
                "KubeHpaMaxedOut",
                "KubeCPUOvercommit"
              ]
            },
            "scores": {
              "cluster_health": 5,
              "node_availability": 5,
              "pod_stability": 5,
              "api_reliability": 1
            },
            "quick_findings": [
              "Active alerts detected: KubeHpaMaxedOut, KubeCPUOvercommit"
            ],
            "services_analyzed": [],
            "services_count": 0,
            "namespaces_analyzed": []
          },
          "completedAt": "2025-12-18T16:53:43.084Z",
          "status": "degraded"
        },
        "stage2": {
          "output": {
            "investigation_id": "ctx-1766076687180-o6nlz1opk-stage2",
            "root_cause": {
              "identified": false,
              "component": "bss-mc-pcm-product-offer-detail",
              "issue": "Pod restarts and memory pressure",
              "evidence": [
                "Pod restarts observed in bss-mc-pcm-product-offer-detail",
                "Memory pressure in elasticsearch-data-0"
              ],
              "confidence": 0.5
            },
            "correlation_matrix": {
              "primary_chain": "Pod restarts and memory pressure observed in critical pods",
              "affected_services": [
                "bss-mc-pcm-product-offer-detail",
                "bss-mc-asset-management"
              ],
              "blast_radius": "Limited to specific pods",
              "kubernetes_impact": {
                "evicted_pods": 0,
                "pending_pods": 0,
                "failed_schedules": 0
              }
            },
            "critical_pods": [
              "bss-mc-pcm-product-offer-detail-6fbfbddf94-g58q7",
              "bss-mc-asset-management-7f48bd88d-6k94j"
            ],
            "affected_services": [
              "bss-mc-pcm-product-offer-detail",
              "bss-mc-asset-management"
            ],
            "proceed_to_stage3": true,
            "alert_correlation_needed": true,
            "confidence": 0.5
          },
          "completedAt": "2025-12-18T16:53:43.084Z",
          "decision": true,
          "rootCauseIdentified": false
        }
      }
    },
    "executiveInsights": {
      "stage1_health_snapshot": {
        "overall_status": "degraded",
        "critical_alerts": 0,
        "urgency": "normal",
        "key_finding": "Active alerts detected: KubeHpaMaxedOut, KubeCPUOvercommit"
      },
      "stage2_root_cause": {
        "identified": false,
        "issue": "Pod restarts and memory pressure",
        "component": "bss-mc-pcm-product-offer-detail",
        "confidence": 0.5,
        "affected_services": [
          "bss-mc-pcm-product-offer-detail",
          "bss-mc-asset-management"
        ]
      },
      "stage3_alert_correlation": {
        "active_alerts": 2,
        "alert_groups": 1,
        "kb_matches": 0,
        "correlation_confidence": 0.8,
        "slo_status": "green"
      },
      "stage4_diagnostics": {
        "diagnostics_executed": 1,
        "confirmed_issues": 1,
        "remediation_confidence": 1,
        "primary_issue": "Pod OOMKilled due to memory limit exceeded"
      },
      "stage5_remediation": {
        "plan_created": true,
        "immediate_actions": 1,
        "overall_risk": "high",
        "primary_action": "Increase memory limits for the deployment to prevent OOMKilled events."
      },
      "stage6_prevention": {
        "prevention_implemented": false,
        "prevention_actions": 0,
        "kb_updated": false,
        "prevention_quality_score": 0
      }
    },
    "decisionJourney": {
      "stage1_decision": {
        "field": "proceed_to_stage2",
        "value": false,
        "reason": "",
        "timestamp": "2025-12-18T16:53:43.084Z"
      },
      "stage2_decision": {
        "field": "proceed_to_stage3",
        "value": true,
        "confidence": 0.5,
        "timestamp": "2025-12-18T16:53:43.084Z"
      },
      "stage3_decision": {
        "field": "proceed_to_stage4",
        "value": true,
        "correlation_confidence": 0.8,
        "timestamp": "2025-12-18T16:52:37.415Z"
      },
      "stage4_decision": {
        "field": "proceed_to_stage5",
        "value": true,
        "remediation_confidence": 1,
        "timestamp": "2025-12-18T16:53:05.916Z"
      },
      "stage5_completion": {
        "remediation_plan_created": true,
        "timestamp": "2025-12-18T16:53:30.965Z"
      },
      "stage6_completion": {
        "prevention_implemented": false,
        "prevention_quality_score": 0
      }
    },
    "confidenceProgression": {
      "stage2_root_cause_confidence": 0.5,
      "stage3_correlation_confidence": 0.8,
      "stage4_remediation_confidence": 1,
      "stage6_prevention_quality": 0,
      "overall_confidence": 0.575
    },
    "learningSummary": {
      "what_happened": {
        "root_cause": "Pod restarts and memory pressure",
        "affected_services": [
          "bss-mc-pcm-product-offer-detail",
          "bss-mc-asset-management"
        ],
        "alert_count": 2,
        "severity": "critical",
        "duration": "NaNs"
      },
      "what_worked": [
        "Stage 3 strongly correlated alerts to root cause",
        "Stage 5 generated 1 actionable remediation steps"
      ],
      "what_didnt_work": [],
      "key_insights": [
        "Primary issue: Pod restarts and memory pressure"
      ]
    },
    "recommendationPriority": {
      "critical_immediate": [],
      "high_short_term": [],
      "medium_long_term": [
        {
          "action": "Fix memory leak in the application code and optimize memory usage.",
          "timeline": "1-2 weeks",
          "details": "Conduct a thorough code review and implement memory management best practices."
        }
      ],
      "preventive_ongoing": []
    },
    "summary": "üîç **Kubernetes Cluster Analizi**\n\nüìä **Cluster:** unknown\nüÜî **Context ID:** ctx-1766076687180-o6nlz1opk\n‚è±Ô∏è **S√ºre:** NaNs\n\n**üìà Genel Durum:**\n- Saƒülƒ±k Durumu: degraded\n- Aktif Alert: 6 (0 kritik)\n- √áalƒ±≈üan Stage: 7/6\n\n**üîß √ñnerilen Aksiyonlar:**\n1. Increase memory limits for the deployment to prevent OOMKilled events.\n   - Risk: medium\n   - S√ºre: 5-10 min\n   - Komut: `kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod`\n\n**üìä SLO Durumu:**\n- Mevcut: 100%\n- Hedef: 99.9%\n- Durum: green\n\n**üìà G√ºven Skoru ƒ∞lerlemesi:**\n- Stage 2 (K√∂k Neden): 50%\n- Stage 3 (Alert Korelasyon): 80%\n- Stage 4 (Remediation): 100%\n- Stage 6 (Prevention Kalitesi): 0%\n- **Genel G√ºven: 57%**\n\n**üîÑ Karar Yolculuƒüu:**\n- Stage 1‚Üí2: ‚ùå Dur\n- Stage 2‚Üí3: ‚úÖ Devam\n- Stage 3‚Üí4: ‚úÖ Devam\n- Stage 4‚Üí5: ‚úÖ Devam\n\n**üí° √ñnemli Bulgular:**\n- Primary issue: Pod restarts and memory pressure\n\n**‚úÖ ƒ∞≈üe Yarayan:**\n- Stage 3 strongly correlated alerts to root cause\n- Stage 5 generated 1 actionable remediation steps\n\n**üìã √ñzet:**\n7 a≈üama tamamlandƒ±, 0 karar takip edildi.\n",
    "markdownReport": "<div style=\"border: 2px solid #d32f2f; border-radius: 8px; padding: 20px; background-color: #ffebee; font-family: Arial, sans-serif; max-width: 800px;\"><h2 style=\"color: #d32f2f; margin-top: 0;\">üî¥ Unknown Alert</h2><p style=\"font-size: 14px; color: #666;\"><strong>Context ID:</strong> ctx-1766076687180-o6nlz1opk</p><hr style=\"border: none; border-top: 1px solid #ddd; margin: 15px 0;\"><h3 style=\"color: #333;\">üéØ Issue Summary</h3><p><strong>Component:</strong> bss-mc-pcm-product-offer-detail</p><p><strong>Issue:</strong> Pod restarts and memory pressure</p><p><strong>Confidence:</strong> 50%</p><p><strong>Severity:</strong> <span style=\"color: #d32f2f; font-weight: bold;\">CRITICAL</span></p><p><strong>Affected Services:</strong> bss-mc-pcm-product-offer-detail, bss-mc-asset-management</p><h3 style=\"color: #333;\">üìä SLO Impact</h3><p><strong>Availability SLO:</strong> 100% (Target: 99.9%) - Status: <strong>GREEN</strong></p><h3 style=\"color: #333;\">üîß Recommended Actions</h3><ol style=\"margin: 10px 0; padding-left: 20px;\"><li style=\"margin-bottom: 10px;\"><strong>Increase memory limits for the deployment to prevent OOMKilled events.</strong><br><span style=\"font-size: 12px; color: #666;\">Risk: medium | Time: 5-10 min</span><br><code style=\"background: #f4f4f4; padding: 2px 6px; border-radius: 3px; font-size: 12px;\">kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod</code></li></ol><hr style=\"border: none; border-top: 1px solid #ddd; margin: 15px 0;\"><p style=\"font-size: 12px; color: #999;\">Generated at 2025-12-18T16:53:43.087Z</p></div>",
    "oncallTicket": {
      "title": "üî¥ CRITICAL Unknown Alert: bss-mc-pcm-product-offer-detail",
      "description": "<div style=\"font-family: Arial, sans-serif; max-width: 700px;\"><h3 style=\"color: #d32f2f;\">üî¥ Alert: Unknown Alert</h3><p><strong>Component:</strong> bss-mc-pcm-product-offer-detail</p><p><strong>Namespace:</strong> bss-mc-pcm-product-offer-detail</p><p><strong>Root Cause:</strong> Pod restarts and memory pressure</p><p><strong>Affected Services:</strong> bss-mc-pcm-product-offer-detail, bss-mc-asset-management</p><h4>Recommended Actions:</h4><ul><li><strong>Increase memory limits for the deployment to prevent OOMKilled events.</strong> (Risk: medium)</li></ul><p style=\"font-size: 12px; color: #999;\">Context ID: ctx-1766076687180-o6nlz1opk</p></div>",
      "priority": "Critical",
      "customFields": {
        "contextId": "ctx-1766076687180-o6nlz1opk",
        "oncallFriendly": true,
        "symptoms": 6,
        "rootCause": "Diagnosis: Pod restarts and memory pressure"
      }
    },
    "jiraTicket": {
      "title": "bss-mc-pcm-product-offer-detail - Pod restarts and memory pressure (KB-Available)",
      "description": "\n<div style=\"font-family: Arial, sans-serif; max-width: 800px;\">\n  <div style=\"background: linear-gradient(135deg, #ff9800 0%, #f57c00 100%); color: white; padding: 15px; border-radius: 8px; margin-bottom: 20px;\">\n    <h1 style=\"margin: 0; font-size: 24px;\">üî¥ CRITICAL: Pod restarts and memory pressure</h1>\n  </div>\n\n  <div style=\"border: 2px solid #0288d1; border-radius: 8px; margin: 15px 0; background: #e1f5fe;\">\n    <div style=\"background: #0288d1; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      ‚ö° QUICK FINDINGS\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ Active alerts detected: KubeHpaMaxedOut, KubeCPUOvercommit</div>\n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #d32f2f; border-radius: 8px; margin: 15px 0; background: #ffebee;\">\n    <div style=\"background: #d32f2f; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üî• SYMPTOMS (What's Happening)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ kube-prometheus-stack service experiencing issues</div><div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ Pod status: Running</div><div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ Pod restarting (Restart count: 5)</div><div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ Memory: 1.2Gi/1Gi</div><div style=\"margin: 8px 0; padding-left: 10px;\">‚Ä¢ Latest event: Pod was killed due to out of memory (Warning)</div>\n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #ff9800; border-radius: 8px; margin: 15px 0; background: #fff3e0;\">\n    <div style=\"background: #ff9800; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üîç ROOT CAUSE (Why It's Happening)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <p style=\"margin: 0 0 10px 0;\"><strong>Root Cause:</strong> Pod restarts and memory pressure</p>\n\n      <div style=\"background: #f5f5f5; padding: 10px; border-radius: 4px; margin-top: 10px;\">\n        <strong>Evidence:</strong>\n        <div style=\"margin-top: 8px;\">\n          ‚Ä¢ <strong>Pod Status:</strong> <code>Running</code><br/>\n          ‚Ä¢ <strong>Last Termination:</strong> OOMKilled (Exit Code: 137)<br/>\n          ‚Ä¢ <strong>Memory Usage:</strong> 1.2Gi / 1Gi<br/>\n          ‚Ä¢ <strong>CPU Usage:</strong> 250m<br/>\n          ‚Ä¢ <strong>Latest Error:</strong> Out of memory error<br/>\n          ‚Ä¢ <strong>Latest Event:</strong> Pod was killed due to out of memory (Warning)<br/>\n        </div>\n        \n      </div>\n\n      \n        <div style=\"margin-top: 15px; padding: 12px; background: #fff3e0; border-radius: 6px; border-left: 4px solid #ff9800;\">\n          <strong>üìä Impact Analysis:</strong>\n          <div style=\"margin-top: 8px;\">\n            ‚Ä¢ <strong>Primary Issue Chain:</strong> Pod restarts and memory pressure observed in critical pods<br/>\n            ‚Ä¢ <strong>Blast Radius:</strong> Limited to specific pods<br/>\n            ‚Ä¢ <strong>Affected Services:</strong> bss-mc-pcm-product-offer-detail, bss-mc-asset-management<br/>\n            ‚Ä¢ <strong>SLO Status:</strong> green (Current: 100%, Target: 99.9%, Error Budget Used: 0%)<br/>\n          </div>\n        </div>\n      \n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #4caf50; border-radius: 8px; margin: 15px 0; background: #e8f5e8;\">\n    <div style=\"background: #4caf50; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      ‚úÖ SOLUTION (What To Do)\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <h3 style=\"margin: 10px 0 15px 0; color: #d32f2f; font-size: 18px;\">üö® IMMEDIATE ACTIONS</h3>\n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 15px 0; padding: 15px; background: #fafafa;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #d32f2f;\">1. Increase memory limits for the deployment to prevent OOMKilled events.</h4>\n          <p style=\"margin: 10px 0;\"><strong>Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>kubectl set resources deployment/kube-prometheus-stack --limits=memory=2Gi -n em-control-plane-prod</code>\n          </div>\n          <div style=\"margin-top: 10px;\">\n            <span style=\"margin-right: 15px;\">‚è±Ô∏è <strong>Duration:</strong> 5-10 min</span>\n            <span style=\"margin-right: 15px;\">‚ö†Ô∏è <strong>Risk:</strong> medium</span>\n            <div style=\"margin-top: 5px;\">üéØ <strong>Expected Result:</strong> Pod should stabilize with increased memory limits, reducing OOMKilled events.</div>\n          </div>\n        </div>\n      \n\n      \n        <h3 style=\"margin: 25px 0 15px 0; color: #ff9800; font-size: 18px;\">‚è±Ô∏è SHORT-TERM FIXES (1-2 days)</h3>\n        \n          <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 12px; background: #fffaf0;\">\n            <p style=\"margin: 0;\"><strong>1. Analyze memory usage patterns to identify potential memory leaks.</strong></p>\n            <p style=\"margin: 8px 0 0 0; color: #666;\">Review application logs and memory profiling data to detect abnormal memory consumption.</p>\n          </div>\n        \n      \n\n      \n        <h3 style=\"margin: 25px 0 15px 0; color: #2196f3; font-size: 18px;\">üîß LONG-TERM SOLUTIONS (1-2 weeks)</h3>\n        \n          <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 12px; background: #f0f8ff;\">\n            <p style=\"margin: 0;\"><strong>1. Fix memory leak in the application code and optimize memory usage.</strong></p>\n            <p style=\"margin: 8px 0 0 0; color: #666;\">Conduct a thorough code review and implement memory management best practices.</p>\n          </div>\n        \n      \n\n      \n        <h3 style=\"margin: 25px 0 15px 0; color: #4caf50; font-size: 18px;\">üõ°Ô∏è PREVENTIVE MEASURES</h3>\n        <div style=\"border: 1px solid #4caf50; border-radius: 6px; padding: 12px; background: #f1f8e9;\">\n          <div style=\"margin: 6px 0; padding-left: 10px;\">‚Ä¢ Implement CI/CD improvements to include memory profiling in testing.</div><div style=\"margin: 6px 0; padding-left: 10px;\">‚Ä¢ Enhance monitoring with alerts for memory usage thresholds.</div><div style=\"margin: 6px 0; padding-left: 10px;\">‚Ä¢ Develop runbooks for handling OOMKilled events.</div>\n        </div>\n      \n\n      \n        <div style=\"margin-top: 20px; border: 1px solid #ff9800; border-radius: 6px; padding: 12px; background: #fff3e0;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #ff9800;\">‚ö†Ô∏è RISK ASSESSMENT</h4>\n          <p style=\"margin: 5px 0;\"><strong>Overall Risk:</strong> HIGH</p>\n          \n            <p style=\"margin: 10px 0 5px 0;\"><strong>Risk Factors:</strong></p>\n            <div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Service criticality: High impact on metrics collection.</div><div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Remediation safety: Medium risk due to resource changes.</div><div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Issue containment: Limited to specific deployment.</div>\n          \n          \n            <p style=\"margin: 10px 0 5px 0;\"><strong>Mitigation Steps:</strong></p>\n            <div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Monitor pod status and memory usage during remediation.</div><div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Coordinate with the development team for code fixes.</div><div style=\"margin: 4px 0; padding-left: 10px;\">‚Ä¢ Prepare rollback procedures if memory increase does not resolve the issue.</div>\n          \n        </div>\n      \n\n      \n        <div style=\"margin-top: 20px; border: 1px solid #2196f3; border-radius: 6px; padding: 12px; background: #e3f2fd;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #2196f3;\">üî¢ IMPLEMENTATION ORDER</h4>\n          \n            <div style=\"margin: 8px 0; padding: 10px; background: white; border-radius: 4px;\">\n              <strong>Step 1:</strong> Increase memory limits for the deployment.\n              <div style=\"margin-top: 5px; color: #666; font-size: 13px;\">‚úì Validation: Verify pod stability and absence of OOMKilled events.</div>\n            </div>\n          \n            <div style=\"margin: 8px 0; padding: 10px; background: white; border-radius: 4px;\">\n              <strong>Step 2:</strong> Monitor memory usage and application logs.\n              <div style=\"margin-top: 5px; color: #666; font-size: 13px;\">‚úì Validation: Ensure memory usage remains within new limits and no further OOMKilled events occur.</div>\n            </div>\n          \n        </div>\n      \n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #2196f3; border-radius: 8px; margin: 15px 0; background: #e3f2fd;\">\n    <div style=\"background: #2196f3; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üìã VERIFY SOLUTION EFFECTIVENESS\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      \n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 15px; background: #f9f9f9;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #2196f3;\">1. Check pod status</h4>\n          <p style=\"margin: 10px 0;\"><strong>Run Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>kubectl get pods -n bss-mc-pcm-product-offer-detail | grep kube-prometheus-stack</code>\n          </div>\n          <p style=\"margin: 10px 0 0 0;\"><strong>Expected Result:</strong> STATUS: Running (all pods in running state)</p>\n        </div>\n      \n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 15px; background: white;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #2196f3;\">2. Check service response</h4>\n          <p style=\"margin: 10px 0;\"><strong>Run Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>kubectl get svc -n bss-mc-pcm-product-offer-detail | grep kube-prometheus-stack</code>\n          </div>\n          <p style=\"margin: 10px 0 0 0;\"><strong>Expected Result:</strong> Service available and responding</p>\n        </div>\n      \n        <div style=\"border: 1px solid #ddd; border-radius: 6px; margin: 10px 0; padding: 15px; background: #f9f9f9;\">\n          <h4 style=\"margin: 0 0 10px 0; color: #2196f3;\">3. Check for restarts</h4>\n          <p style=\"margin: 10px 0;\"><strong>Run Command:</strong></p>\n          <div style=\"background: #2d2d2d; color: #f8f8f2; padding: 10px; border-radius: 4px; font-family: 'Courier New', monospace; overflow-x: auto;\">\n            <code>kubectl describe pod -l app=kube-prometheus-stack -n bss-mc-pcm-product-offer-detail | grep \"Restart Count\"</code>\n          </div>\n          <p style=\"margin: 10px 0 0 0;\"><strong>Expected Result:</strong> Restart Count: 0 (should not increase, no new restarts)</p>\n        </div>\n      \n    </div>\n  </div>\n\n  <div style=\"border: 2px solid #607d8b; border-radius: 8px; margin: 15px 0; background: #eceff1;\">\n    <div style=\"background: #607d8b; color: white; padding: 12px; font-weight: bold; border-radius: 6px 6px 0 0;\">\n      üîß SUPPORT INFORMATION\n    </div>\n    <div style=\"padding: 15px; background: white; border-radius: 0 0 6px 6px;\">\n      <table style=\"width: 100%; border-collapse: collapse; font-family: Arial, sans-serif;\">\n        <tr><td style=\"font-weight: bold; width: 150px; padding: 5px;\">Incident ID:</td><td style=\"padding: 5px; font-family: monospace;\">ctx-1766076687180-o6nlz1opk</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Timestamp:</td><td style=\"padding: 5px;\">12/18/2025, 7:53:43 PM</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Namespace:</td><td style=\"padding: 5px; font-family: monospace;\">bss-mc-pcm-product-offer-detail</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Pod:</td><td style=\"padding: 5px; font-family: monospace;\">kube-prometheus-stack-kube-state-metrics-84c7c44c96-ppvqf</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Deployment:</td><td style=\"padding: 5px; font-family: monospace;\">kube-prometheus-stack</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Cluster Status:</td><td style=\"padding: 5px;\">degraded</td></tr>\n        <tr><td style=\"font-weight: bold; padding: 5px;\">Total Alerts:</td><td style=\"padding: 5px;\">6 (0 critical)</td></tr>\n      </table>\n      <div style=\"margin-top: 15px; padding: 10px; background: #fff3e0; border-radius: 4px; border-left: 4px solid #ff9800;\">\n        <strong>If issue persists:</strong> Escalate to Development Team\n      </div>\n    </div>\n  </div>\n\n  <div style=\"text-align: center; margin-top: 20px; padding: 10px; background: #f5f5f5; border-radius: 6px; font-size: 12px; color: #666;\">\n    <div>This report was auto-generated by FreePrometheus | 12/18/2025, 7:53:43 PM</div>\n    <div>KB Integration: 42 alerts loaded | Generic Analysis</div>\n  </div>\n</div>\n",
      "priority": "Critical",
      "labels": [
        "Unknown Alert",
        "critical",
        "bss-mc-pcm-product-offer-detail",
        "bss-mc-pcm-product-offer-detail",
        "Auto-Detected",
        "FreePrometheus-Analysis",
        "KB-Aware-Analysis",
        "KB-Integration-Enabled"
      ],
      "components": [
        "bss-mc-pcm-product-offer-detail"
      ],
      "issueType": "Incident",
      "customFields": {
        "contextId": "ctx-1766076687180-o6nlz1opk",
        "analysisTime": null,
        "automationConfidence": 0.5,
        "analysisEngine": "FreePrometheus Analysis Engine",
        "engineVersion": "2.0",
        "stagesExecuted": 7,
        "rootCauseConfidence": 0.5,
        "affectedServices": 2,
        "sloImpact": "green",
        "kbIntegrationEnabled": true,
        "kbEnhanced": false,
        "kbEntriesLoaded": 42
      }
    },
    "knowledgeBaseInsights": {
      "kbIntegrationEnabled": true,
      "kbEnhanced": false,
      "alertCategory": "UNKNOWN",
      "urgencyLevel": "CRITICAL",
      "cascadeRisk": "LOW",
      "kbUtilization": {
        "utilizationRate": "0.0%",
        "matchedEntries": 0,
        "totalEntries": 42,
        "lastUpdated": "2025-12-18T16:53:43.091Z"
      },
      "categoryAnalysis": {
        "category": "UNKNOWN",
        "typicalResolutionTime": "Unknown",
        "commonCauses": [],
        "recommendedRunbooks": []
      },
      "kbEntryDetails": null
    },
    "_debug": {
      "contextId": "ctx-1766076687180-o6nlz1opk",
      "executionFlow": {
        "stagesExecuted": 7,
        "stageCompletions": {
          "stage1": true,
          "stage2": true,
          "stage3": true,
          "stage4": true,
          "stage5": true,
          "stage6": false
        }
      },
      "kbAwareCorrelation": {
        "engine": "KB-Aware Universal Correlation Engine",
        "version": "1.0-HYBRID",
        "kbIntegration": false,
        "fallbackMode": "NATIVE_ANALYSIS"
      },
      "dataQuality": {
        "mockDataDetected": false,
        "contextPreserved": true,
        "allStagesHaveData": true
      },
      "timestamp": "2025-12-18T16:53:43.091Z"
    }
  }
]