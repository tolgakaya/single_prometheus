# Stage 2: Deep Analysis

## TIME:
Start: {{ $json._context.initialParams.startTime }}
End: {{ $json._context.initialParams.endTime }}

## CONTEXT:
ID: {{ $json._context.contextId }}
Alert: {{ $json._context.alertContext.alertName }}
Pod: {{ $json._context.kubernetesFilters.pod }}
Namespaces: {{ $json._context.initialParams.namespaces.join(', ') }} (Total: {{ $json._context.initialParams.namespaces.length }})
Priority: {{ $json._context.priority }}

## STAGE 1 KEY FINDINGS:
Status: {{ $json.stage1Results.overall_status }}
Alerts: {{ $json.stage1Results.alerts.critical }} critical
Issue: {{ $json.stage1Results.quick_findings[0] }}

## EXECUTE ANALYSIS:

Phase 1 (Pod Analysis):
- Pod Status Check
- Container Restarts  
- Pod Resource Usage

Phase 2 (Trends):
- Historical Comparison 24h

Phase 3 (Anomaly):
- Resource Exhaustion Prediction
- Anomaly Patterns

## OUTPUT JSON (NO MARKDOWN):
{
  "stage": "deep_analysis",
  "investigation_id": "{{ $json._context.contextId }}-s2",
  "execution_phases": {
    "instant": {
      "tools_used": [],
      "findings": {
        "critical_pods": [],
        "resource_pressure": []
      }
    },
    "trend": {
      "tools_used": [],
      "findings": {
        "memory_growth": "",
        "restart_pattern": ""
      }
    },
    "anomaly": {
      "tools_used": [],
      "findings": {
        "predictions": [],
        "anomalies": []
      }
    }
  },
  "correlation_matrix": {
    "primary_chain": "",
    "affected_services": [],
    "blast_radius": "",
    "kubernetes_impact": {
      "evicted_pods": 0,
      "pending_pods": 0
    }
  },
  "root_cause": {
    "identified": false,
    "component": "",
    "issue": "",
    "evidence": [],
    "confidence": 0.0
  },
  "proceed_to_stage3": false,
  "_context": {
    "contextId": "{{ $json._context.contextId }}",
    "priority": "{{ $json._context.priority }}"
  }
}

Return ONLY JSON, no text before/after.